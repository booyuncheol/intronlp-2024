Search.setIndex({"alltitles": {"1. Advanced N-gram Techniques": [[16, "advanced-n-gram-techniques"]], "1. Advanced Text Cleaning Techniques": [[12, "advanced-text-cleaning-techniques"]], "1. Characteristics of Korean Language": [[13, "characteristics-of-korean-language"]], "1. Importance of Text Preprocessing": [[11, "importance-of-text-preprocessing"]], "1. Introduction to BERT": [[22, "introduction-to-bert"]], "1. Introduction to GloVe (Global Vectors for Word Representation)": [[19, "introduction-to-glove-global-vectors-for-word-representation"]], "1. Introduction to Language Models": [[14, "introduction-to-language-models"], [15, "introduction-to-language-models"]], "1. Introduction to NLP Basics": [[9, "introduction-to-nlp-basics"]], "1. Introduction to Natural Language Processing (NLP)": [[7, "introduction-to-natural-language-processing-nlp"]], "1. Introduction to Word Embeddings": [[17, "introduction-to-word-embeddings"], [18, "introduction-to-word-embeddings"]], "1. Positional Encoding": [[23, "positional-encoding"]], "1. Project Overview": [[2, "project-overview"], [3, "project-overview"]], "1. Tokenization": [[10, "tokenization"]], "1.1 Definition of NLP": [[7, "definition-of-nlp"]], "1.1 Formal Definition": [[15, "formal-definition"]], "1.1 Interpolation and Backoff": [[16, "interpolation-and-backoff"]], "1.1 Key Concepts of GloVe": [[19, "key-concepts-of-glove"]], "1.1 Limitations of Traditional Word Representations": [[18, "limitations-of-traditional-word-representations"]], "1.2 Applications of Language Models": [[15, "applications-of-language-models"]], "1.2 Basic Concepts": [[7, "basic-concepts"]], "1.2 GloVe Algorithm": [[19, "glove-algorithm"]], "1.2 Skip-gram Models": [[16, "skip-gram-models"]], "1.2 The Idea Behind Word Embeddings": [[18, "the-idea-behind-word-embeddings"]], "1.3 Implementing GloVe with Python": [[19, "implementing-glove-with-python"]], "2. Challenges in Korean Text Preprocessing": [[13, "challenges-in-korean-text-preprocessing"]], "2. Class-based Language Models": [[16, "class-based-language-models"]], "2. FastText: Subword-based Word Embeddings": [[19, "fasttext-subword-based-word-embeddings"]], "2. Handling Contractions and Special Cases": [[12, "handling-contractions-and-special-cases"]], "2. Historical Perspective of NLP": [[7, "historical-perspective-of-nlp"]], "2. Multi-Head Attention Module": [[23, "multi-head-attention-module"]], "2. N-gram Models": [[14, "n-gram-models"], [15, "n-gram-models"]], "2. Normalization": [[10, "normalization"]], "2. Project Background and Objectives": [[3, "project-background-and-objectives"]], "2. Project Objectives": [[2, "project-objectives"]], "2. Text Cleaning": [[11, "text-cleaning"]], "2. The Architecture of BERT": [[22, "the-architecture-of-bert"]], "2. Tokenization Example using NLTK": [[9, "tokenization-example-using-nltk"]], "2. Word2Vec": [[17, "word2vec"], [18, "word2vec"]], "2.1 Attention Mechanism": [[22, "attention-mechanism"]], "2.1 CBOW Architecture": [[18, "cbow-architecture"]], "2.1 Early Approaches (1950s-1980s)": [[7, "early-approaches-1950s-1980s"]], "2.1 Key Features of FastText": [[19, "key-features-of-fasttext"]], "2.1 Types of N-grams": [[15, "types-of-n-grams"]], "2.2 FastText Architecture": [[19, "fasttext-architecture"]], "2.2 Skip-gram Architecture": [[18, "skip-gram-architecture"]], "2.2 Statistical Revolution (1980s-2000s)": [[7, "statistical-revolution-1980s-2000s"]], "2.2 The Markov Assumption": [[15, "the-markov-assumption"]], "2.2 Word Embeddings in BERT": [[22, "word-embeddings-in-bert"]], "2.3 Attention Mechanism Simplified": [[22, "attention-mechanism-simplified"]], "2.3 Calculating N-gram Probabilities": [[15, "calculating-n-gram-probabilities"]], "2.3 Implementing FastText with Gensim": [[19, "implementing-fasttext-with-gensim"]], "2.3 Training Process": [[18, "training-process"]], "2.4 Advantages and Limitations of N-gram Models": [[15, "advantages-and-limitations-of-n-gram-models"]], "2.4 Implementing Word2Vec with Gensim": [[18, "implementing-word2vec-with-gensim"]], "2.5 Visualizing Word Embeddings": [[18, "visualizing-word-embeddings"]], "3. Advantages of Word2Vec": [[18, "advantages-of-word2vec"]], "3. Comparing Word2Vec, GloVe, and FastText": [[19, "comparing-word2vec-glove-and-fasttext"]], "3. Deconstructing Attention": [[22, "deconstructing-attention"]], "3. Feed-Forward Network": [[23, "feed-forward-network"]], "3. GloVe (Global Vectors for Word Representation)": [[17, "glove-global-vectors-for-word-representation"]], "3. Handling Unseen N-grams: Smoothing Techniques": [[15, "handling-unseen-n-grams-smoothing-techniques"]], "3. Korean Sentence Tokenization": [[13, "korean-sentence-tokenization"]], "3. Lowercase Conversion": [[11, "lowercase-conversion"]], "3. Maximum Entropy Language Models": [[16, "maximum-entropy-language-models"]], "3. Modern NLP and Deep Learning (2010s-Present)": [[7, "modern-nlp-and-deep-learning-2010s-present"]], "3. Named Entity Recognition (NER)": [[12, "named-entity-recognition-ner"]], "3. Part-of-Speech Tagging Demonstration": [[9, "part-of-speech-tagging-demonstration"]], "3. Project Description": [[3, "project-description"]], "3. Statistical Language Models": [[14, "statistical-language-models"]], "3. Stop Word Removal": [[10, "stop-word-removal"]], "3. Team Composition and Roles": [[2, "team-composition-and-roles"]], "3.1 Key Features and Characteristics": [[3, "key-features-and-characteristics"]], "3.1 Laplace (Add-1) Smoothing": [[15, "laplace-add-1-smoothing"]], "3.1 Queries and Keys": [[22, "queries-and-keys"]], "3.2 Neuron View of Attention": [[22, "neuron-view-of-attention"]], "3.2 Other Smoothing Techniques": [[15, "other-smoothing-techniques"]], "3.2 Technologies": [[3, "technologies"]], "3.3 Dataset": [[3, "dataset"]], "4. Development Plan": [[3, "development-plan"]], "4. Encoder Layer": [[23, "encoder-layer"]], "4. Evaluating Language Models: Perplexity": [[15, "evaluating-language-models-perplexity"]], "4. FastText": [[17, "fasttext"]], "4. Implementation of N-gram Models": [[14, "implementation-of-n-gram-models"]], "4. Introduction to Neural Language Models": [[16, "introduction-to-neural-language-models"]], "4. Korean Morphological Analysis": [[13, "korean-morphological-analysis"]], "4. Limitations and Considerations": [[18, "limitations-and-considerations"]], "4. Multi-head Attention": [[22, "multi-head-attention"]], "4. NLTK Library for Text Preprocessing": [[10, "nltk-library-for-text-preprocessing"]], "4. Part-of-Speech (POS) Tagging": [[12, "part-of-speech-pos-tagging"]], "4. Practical Applications of Word Embeddings": [[19, "practical-applications-of-word-embeddings"]], "4. Project Progression": [[2, "project-progression"]], "4. Simple Word Embedding Visualization using Gensim\u2019s Word2Vec": [[9, "simple-word-embedding-visualization-using-gensim-s-word2vec"]], "4. Tokenization": [[11, "tokenization"]], "4. Traditional NLP Pipeline": [[7, "traditional-nlp-pipeline"]], "4.1 Detailed Plan by Development Phase": [[3, "detailed-plan-by-development-phase"]], "4.1 Text Classification": [[19, "text-classification"]], "4.1 Text Preprocessing": [[7, "text-preprocessing"]], "4.1 Weekly Learning and Team Meetings": [[2, "weekly-learning-and-team-meetings"]], "4.1 Word Embeddings": [[16, "word-embeddings"]], "4.2 Feature Extraction": [[7, "feature-extraction"]], "4.2 Named Entity Recognition (NER)": [[19, "named-entity-recognition-ner"]], "4.2 Project Phases": [[2, "project-phases"]], "4.2 Role Distribution": [[3, "role-distribution"]], "4.2 Simple Feed-forward Neural Language Model": [[16, "simple-feed-forward-neural-language-model"]], "4.3 Model Training and Evaluation": [[7, "model-training-and-evaluation"]], "5. Basic Text Generation using OpenAI\u2019s GPT-4o API (Optional)": [[9, "basic-text-generation-using-openai-s-gpt-4o-api-optional"]], "5. Challenges in Traditional NLP": [[7, "challenges-in-traditional-nlp"]], "5. Comparing Statistical and Neural Language Models": [[16, "comparing-statistical-and-neural-language-models"]], "5. Decoder Layer": [[23, "decoder-layer"]], "5. Evaluating Word Embeddings": [[19, "evaluating-word-embeddings"]], "5. Evaluation of Language Models": [[14, "evaluation-of-language-models"]], "5. Expected Deliverables": [[3, "expected-deliverables"]], "5. Final Outputs": [[2, "final-outputs"]], "5. Part-of-Speech Tagging in Korean": [[13, "part-of-speech-tagging-in-korean"]], "5. Practical Applications of Word Embeddings": [[17, "practical-applications-of-word-embeddings"]], "5. Pre-training and Fine-tuning": [[22, "pre-training-and-fine-tuning"]], "5. Stop Word Removal": [[11, "stop-word-removal"]], "5. Text Representation Methods": [[12, "text-representation-methods"]], "5. Visualizing N-gram Models": [[15, "visualizing-n-gram-models"]], "5.1 Intrinsic Evaluation: Word Similarity and Analogy Tasks": [[19, "intrinsic-evaluation-word-similarity-and-analogy-tasks"]], "5.1 Pre-training": [[22, "pre-training"]], "5.2 Extrinsic Evaluation: Performance on Downstream Tasks": [[19, "extrinsic-evaluation-performance-on-downstream-tasks"]], "5.2 Fine-tuning": [[22, "fine-tuning"]], "6. Assembling the Transformer": [[23, "assembling-the-transformer"]], "6. Challenges and Future Directions": [[19, "challenges-and-future-directions"]], "6. Evaluation Method": [[2, "evaluation-method"]], "6. Evaluation Plan": [[3, "evaluation-plan"]], "6. Evolution Towards Modern NLP": [[8, "evolution-towards-modern-nlp"]], "6. Korean Word Embeddings": [[13, "korean-word-embeddings"]], "6. Stemming and Lemmatization": [[11, "stemming-and-lemmatization"]], "6. Word Embeddings": [[12, "word-embeddings"]], "6.1. Introduction of Word Embeddings": [[8, "introduction-of-word-embeddings"]], "6.2. Rise of Deep Learning in NLP": [[8, "rise-of-deep-learning-in-nlp"]], "6.3. Emergence of Transformer Models": [[8, "emergence-of-transformer-models"]], "7. Conclusion and Best Practices": [[12, "conclusion-and-best-practices"], [13, "conclusion-and-best-practices"]], "7. Future Development Potential": [[3, "future-development-potential"]], "7. Generating Masks": [[23, "generating-masks"]], "7. Key Dates": [[2, "key-dates"]], "7. Large Language Models (LLMs)": [[8, "large-language-models-llms"]], "7. Putting It All Together": [[11, "putting-it-all-together"]], "7.1. Definition and Capabilities": [[8, "definition-and-capabilities"]], "7.2. Examples and Their Impact": [[8, "examples-and-their-impact"]], "8. Conclusion and Best Practices": [[11, "conclusion-and-best-practices"]], "8. Paradigm Shift in NLP Tasks": [[8, "paradigm-shift-in-nlp-tasks"]], "8. References and Resources": [[3, "references-and-resources"]], "8. Required Tools and Environment": [[2, "required-tools-and-environment"]], "8.1. From Task-Specific to General-Purpose Models": [[8, "from-task-specific-to-general-purpose-models"]], "8.2. Few-Shot and Zero-Shot Learning": [[8, "few-shot-and-zero-shot-learning"]], "9. Appendices": [[3, "appendices"]], "9. Current State and Future Directions": [[8, "current-state-and-future-directions"]], "9. Important Notes": [[2, "important-notes"]], "9.1. Ongoing Developments in LLMs": [[8, "ongoing-developments-in-llms"]], "9.2. Emerging Challenges and Opportunities": [[8, "emerging-challenges-and-opportunities"]], "About": [[1, null]], "Additional Notes": [[1, "additional-notes"], [5, "additional-notes"]], "Additional Resources": [[14, "additional-resources"]], "Advanced Topics": [[23, "advanced-topics"]], "Advantages of Transformers Over Previous Architectures": [[21, "advantages-of-transformers-over-previous-architectures"]], "Applications of Transformers": [[23, "applications-of-transformers"]], "Assignment": [[10, "assignment"], [14, "assignment"], [17, "assignment"], [20, "assignment"]], "Attachments": [[4, "attachments"]], "Attention Mechanism": [[20, "attention-mechanism"]], "BERT (Bidirectional Encoder Representations from Transformers)": [[23, "bert-bidirectional-encoder-representations-from-transformers"]], "Bag of Words (BoW)": [[12, "bag-of-words-bow"]], "Basic Information": [[4, "basic-information"]], "Building a Simple Transformer from Scratch": [[23, "building-a-simple-transformer-from-scratch"]], "Changelog": [[1, "changelog"]], "Code Example: Positional Encoding": [[21, "code-example-positional-encoding"]], "Code Example: Scaled Dot-Product Attention": [[21, "code-example-scaled-dot-product-attention"]], "Code Walkthrough": [[23, "code-walkthrough"]], "Conclusion": [[7, "conclusion"], [8, "conclusion"], [9, "conclusion"], [15, "conclusion"], [16, "conclusion"], [18, "conclusion"], [19, "conclusion"], [21, "conclusion"], [22, "conclusion"], [23, "conclusion"]], "Contributing": [[1, "contributing"]], "Course Materials": [[1, "course-materials"], [5, "course-materials"]], "Course Outline": [[5, "course-outline"]], "Diagram: Attention Heatmap Matrix": [[23, "diagram-attention-heatmap-matrix"]], "Diagram: Cross-Attention Map": [[23, "diagram-cross-attention-map"]], "Diagram: Multi-Head Attention": [[21, "diagram-multi-head-attention"]], "Diagram: Scaled Dot-Product Attention": [[21, "diagram-scaled-dot-product-attention"]], "Diagram: Transformer Architecture": [[21, "diagram-transformer-architecture"]], "Dissection of Transformer Components": [[21, "dissection-of-transformer-components"]], "Encoder and Decoder Architecture": [[21, "encoder-and-decoder-architecture"]], "Evaluation": [[1, "evaluation"], [5, "evaluation"]], "Example Usage": [[23, "example-usage"]], "Example: Attention Heatmap": [[23, "example-attention-heatmap"]], "Example: Translation Task": [[23, "example-translation-task"]], "Exercise": [[11, "exercise"], [12, "exercise"], [13, "exercise"], [16, "exercise"], [18, "exercise"], [19, "exercise"]], "Feed-Forward Networks": [[21, "feed-forward-networks"]], "Future Directions": [[16, "future-directions"]], "GPT (Generative Pre-trained Transformer)": [[23, "gpt-generative-pre-trained-transformer"]], "Handling Emoji and Emoticons": [[12, "handling-emoji-and-emoticons"]], "Handling Non-ASCII Characters": [[12, "handling-non-ascii-characters"]], "Home": [[1, null]], "Implementing a Simple Attention Mechanism": [[23, "implementing-a-simple-attention-mechanism"]], "Implementing with PyTorch": [[23, "implementing-with-pytorch"]], "Instructor": [[0, "instructor"]], "Interpretation": [[23, "interpretation"], [23, "id1"]], "Interpreting Attention Maps": [[23, "interpreting-attention-maps"]], "Introduction": [[11, "introduction"], [12, "introduction"], [13, "introduction"], [20, "introduction"], [21, "introduction"], [23, "introduction"]], "Katz Backoff": [[16, "katz-backoff"]], "Key Achievements and Deliverables": [[4, "key-achievements-and-deliverables"]], "Key Contributions": [[21, "key-contributions"]], "Key Learning Content": [[20, "key-learning-content"]], "Key Takeaways": [[16, "key-takeaways"]], "Key Topics": [[10, "key-topics"], [14, "key-topics"], [17, "key-topics"]], "Learning Objectives": [[1, "learning-objectives"], [5, "learning-objectives"], [10, "learning-objectives"], [14, "learning-objectives"], [17, "learning-objectives"], [20, "learning-objectives"]], "Learning Outcomes": [[4, "learning-outcomes"]], "Lecture Details": [[20, "lecture-details"]], "Lecture Notes": [[1, null]], "Lemmatization": [[11, "lemmatization"]], "Libraries Needed": [[23, "libraries-needed"]], "License": [[1, "license"]], "Limitations of Traditional RNNs": [[21, "limitations-of-traditional-rnns"]], "Linear Interpolation": [[16, "linear-interpolation"]], "Looking Ahead": [[10, "looking-ahead"], [14, "looking-ahead"], [20, "looking-ahead"]], "Mathematical Formulation": [[21, "mathematical-formulation"], [21, "id1"], [21, "id2"], [21, "id3"]], "Multi-Head Attention": [[21, "multi-head-attention"]], "NLP Project Proposal": [[3, null]], "Next Week\u2019s Plan": [[4, "next-week-s-plan"]], "Notes": [[20, "notes"]], "Objectives": [[9, "objectives"]], "Optional Coding Task Walkthrough": [[23, "optional-coding-task-walkthrough"]], "Optional Exercises": [[9, "optional-exercises"]], "Other Notable Items": [[4, "other-notable-items"]], "Overview": [[10, "overview"], [14, "overview"], [17, "overview"]], "Overview of the \u201cAttention is All You Need\u201d Paper": [[21, "overview-of-the-attention-is-all-you-need-paper"]], "Positional Encoding": [[21, "positional-encoding"]], "Practical Component": [[10, "practical-component"], [14, "practical-component"], [17, "practical-component"]], "Practical Considerations": [[16, "practical-considerations"]], "Practical Implementation of a Transformer": [[23, "practical-implementation-of-a-transformer"]], "Practice Activities": [[20, "practice-activities"]], "Prerequisites": [[1, "prerequisites"], [5, "prerequisites"]], "Projects": [[1, null]], "Recommended Readings": [[17, "recommended-readings"]], "References": [[21, "references"], [23, "references"]], "Resources": [[20, "resources"]], "Scaled Dot-Product Attention": [[21, "scaled-dot-product-attention"]], "Self-Attention Function": [[23, "self-attention-function"]], "Self-Attention Mechanism": [[21, "self-attention-mechanism"]], "Stemming": [[11, "stemming"]], "Students": [[0, "students"]], "Syllabus": [[5, null]], "TF-IDF (Term Frequency-Inverse Document Frequency)": [[12, "tf-idf-term-frequency-inverse-document-frequency"]], "Table of Contents": [[1, "table-of-contents"]], "Team Meeting Summary": [[4, "team-meeting-summary"]], "Team Member Activity Summary": [[4, "team-member-activity-summary"]], "Team Project": [[2, null]], "Technical Challenges and Solutions": [[4, "technical-challenges-and-solutions"]], "The Need for Attention Mechanisms": [[21, "the-need-for-attention-mechanisms"]], "Transformer Structure": [[20, "transformer-structure"]], "Transformer Variants": [[23, "transformer-variants"]], "Visualization of Attention Mechanisms": [[23, "visualization-of-attention-mechanisms"]], "Visualizing Attention Scores": [[23, "visualizing-attention-scores"]], "Week 1 - Introduction": [[6, null]], "Week 1 Lab - Introduction to NLP Basics": [[9, null]], "Week 1 Session 1 - Foundations and Evolution of NLP": [[7, null]], "Week 1 Session 2 - The Revolution in Modern NLP": [[8, null]], "Week 2 - Basics of Text Preprocessing": [[10, null]], "Week 2 Session 1 - Text Preprocessing Fundamentals": [[11, null]], "Week 2 Session 2 - Advanced Text Preprocessing and Representation": [[12, null]], "Week 2 Session 3 - Korean Text Preprocessing and Tokenization": [[13, null]], "Week 3 - Fundamentals of Language Models": [[14, null]], "Week 3 Session 1 - Introduction to Language Models and N-grams": [[15, null]], "Week 3 Session 2 - Advanced Statistical Language Models": [[16, null]], "Week 4 - Word Embeddings": [[17, null]], "Week 4 Session 1 - Introduction to Word Embeddings and Word2Vec": [[18, null]], "Week 4 Session 2 -  Advanced Word Embeddings": [[19, null]], "Week 5 - Transformers": [[20, null]], "Week 5 Session 1 - Introduction to Transformers": [[21, null]], "Week 5 Session 2 - BERT": [[22, null]], "Week 5 Session 3 - Practical Implementation and Visualization of Transformers": [[23, null]], "Week [n] Project Research Note": [[4, null]], "Weekly Goal Achievement": [[4, "weekly-goal-achievement"]], "Who made this book?": [[0, null]], "Young Joon Lee": [[0, "young-joon-lee"]]}, "docnames": ["about/index", "index", "projects/index", "projects/proposal", "projects/research-note", "syllabus/index", "week01/index", "week01/session1", "week01/session2", "week01/wk1-lab1", "week02/index", "week02/session1", "week02/session2", "week02/session3", "week03/index", "week03/session1", "week03/session2", "week04/index", "week04/session1", "week04/session2", "week05/index", "week05/session1", "week05/session2", "week05/session3"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["about/index.md", "index.md", "projects/index.md", "projects/proposal.md", "projects/research-note.md", "syllabus/index.md", "week01/index.md", "week01/session1.md", "week01/session2.md", "week01/wk1-lab1.ipynb", "week02/index.md", "week02/session1.md", "week02/session2.md", "week02/session3.md", "week03/index.md", "week03/session1.md", "week03/session2.md", "week04/index.md", "week04/session1.md", "week04/session2.md", "week05/index.md", "week05/session1.md", "week05/session2.md", "week05/session3.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [2, 3, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "0": [1, 7, 8, 9, 11, 12, 13, 15, 16, 18, 19, 21, 23], "002": [8, 16], "01": 16, "05": [12, 13, 19], "1": [1, 4, 5, 20], "10": [1, 2, 5, 9, 11, 13, 15, 16, 18, 19], "100": [8, 12, 13, 16, 18, 19], "1000": 16, "10000": [8, 21, 23], "11": 5, "110": 22, "12": [2, 3, 5, 11, 12, 13, 15, 22], "128": 16, "13": [2, 3, 5], "14": [2, 3, 5, 9], "15": [2, 3, 5], "16": 22, "1966": 7, "1970": 7, "1980": 6, "1e": [15, 16], "1e9": 23, "2": [1, 4, 5, 6, 20, 21], "20": 2, "200": 8, "2000": 6, "2013": [8, 17, 18], "2014": [8, 17, 19], "2016": [8, 19], "2017": [8, 17, 21], "2018": 22, "2024": [1, 5, 9], "2048": 23, "24": 22, "25": [1, 2, 5], "256": 8, "2d": 18, "2f": [12, 15, 16], "2i": 21, "3": [1, 4, 5, 20, 21], "30": [1, 2, 5, 9, 11, 19], "300": [9, 18], "3000": [11, 13, 15], "33": 11, "35": [1, 5], "3rd": 14, "4": [1, 5, 8], "400": 11, "40824829": 7, "42": [7, 9, 12, 13, 16, 18, 19], "45": [11, 13], "4f": [7, 8, 15, 16], "5": [1, 5, 8], "50": [11, 16, 19], "500": 19, "5000": 23, "512": [7, 8, 23], "6": [5, 16, 20], "64": 23, "66": 11, "7": [5, 18, 19], "8": [5, 9, 12, 13, 15, 16, 18, 19, 23], "800": 11, "9": [5, 19], "A": [2, 5, 6, 7, 9, 14, 16, 19, 20], "And": 11, "As": [6, 7, 8, 11, 16], "BY": 1, "Be": [11, 12, 13, 16], "By": [6, 10, 14, 16, 17, 20, 23], "For": [8, 12, 15, 18, 21], "IN": [7, 9], "If": [2, 9, 16], "In": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23], "It": [7, 9, 13, 15, 18, 22], "Its": 22, "No": [9, 13, 15, 18, 22], "Not": 19, "Of": 9, "One": [7, 15], "The": [1, 2, 5, 6, 7, 9, 10, 11, 12, 14, 17, 19, 20, 23], "There": 7, "These": [7, 8, 9, 16, 19], "To": [7, 13, 15, 16, 18, 21], "With": 11, "_": [15, 21, 23], "_1": 21, "___": 22, "__class__": 13, "__init__": [8, 23], "__name__": 13, "_h": 21, "_i": 21, "abil": [2, 8, 20, 21], "abl": [10, 14, 17, 20], "about": [6, 7, 8, 9, 11, 20, 21, 22], "absolut": [7, 21], "abstract": 2, "ac": 0, "acceler": 8, "access": [8, 9], "account": [13, 18], "accuraci": 8, "achiev": [3, 21, 22], "acl": 2, "across": [2, 7, 8, 9, 11, 19, 22], "act": 7, "activ": [0, 2, 16, 21], "activity1": 4, "activity2": 4, "actual": 2, "ad": 21, "adam": 16, "adapt": [7, 8, 16, 22], "add": 12, "add_dictionari": 19, "add_edg": [13, 15], "add_edges_from": 11, "addit": [2, 4, 7, 10, 13, 22], "addition": 14, "address": [6, 7, 8, 11, 15, 16, 19, 21], "adher": 2, "adjac": 7, "adject": [9, 12], "adjust": [5, 9], "adopt": 8, "advanc": [1, 2, 5, 6, 7, 8, 9, 10, 11, 14, 15, 17, 18, 20, 22], "advantag": [8, 14, 17, 19, 20], "advent": 8, "affect": [9, 11, 12], "affix": 13, "after": 22, "ag": 8, "agglutin": 13, "ai": [0, 1, 5, 7, 8], "aim": [1, 5, 7, 19], "ain": 12, "al": [8, 17, 18, 19, 20, 21, 23], "alammar": [20, 21, 23], "algebra": [1, 5], "algorithm": [7, 11, 12], "align": [8, 11, 13, 23], "all": [2, 7, 8, 9, 12, 15, 18, 20, 22, 23], "all_word": 9, "allow": [16, 17, 20, 21, 22], "alpha": 16, "alphabet": 7, "alreadi": 9, "also": [0, 7, 10, 16], "alwai": [2, 11, 13], "am": [7, 12], "ambigu": 7, "amount": [8, 18], "an": [2, 5, 6, 7, 8, 9, 11, 13, 14, 19, 20, 21, 22, 23], "analogi": [17, 18], "analysi": [2, 5, 6, 7, 8, 10, 11, 12, 15, 19, 20, 22, 23], "analyt": 11, "analyz": [7, 8, 11, 13, 14, 17, 18, 19, 20], "analyze_senti": 7, "analyzer_nam": 13, "ani": [8, 10, 11, 13, 21], "anim": [18, 19], "annot": [8, 9, 12, 13, 16, 18], "anoth": [11, 19], "answer": [8, 22, 23], "anticip": [3, 22], "apart": 21, "api": [1, 2, 3, 5, 8, 20, 23], "api_kei": [8, 9], "apolog": 7, "app": [2, 5], "appear": 15, "append": [16, 19], "appl": 12, "appli": [1, 2, 4, 5, 7, 10, 11, 12, 17, 21], "applic": [1, 2, 3, 4, 5, 8, 9, 14, 16, 18, 20], "appreci": [16, 20, 23], "approach": [3, 6, 8, 10, 12, 14, 15, 16, 18, 22, 23], "appropri": [11, 16], "ar": [1, 2, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "arang": [16, 21, 23], "architectur": [1, 2, 5, 7, 8, 16, 17, 20, 23], "area": [0, 2, 5, 8], "aren": 12, "argmax": [7, 8], "arithmet": [8, 22], "arrai": [9, 16, 19], "arrow": [11, 13], "art": [8, 14, 16, 21, 22], "articl": [9, 12, 13, 16, 18], "artifici": [0, 6, 7, 9], "aspect": [1, 5, 22, 23], "assert": 23, "assign": [1, 2, 5, 7, 9, 15, 16, 19, 22], "assist": [2, 8, 9], "assum": [8, 23], "attach": 13, "attend": [0, 1, 5, 22, 23], "attende": 4, "attent": [5, 7, 8, 16], "attention_weight": [21, 23], "attn_output": 23, "au": 12, "audio": 8, "augment": [5, 8], "automat": 8, "automobil": 19, "automodelforsequenceclassif": 7, "autotoken": 7, "avail": [7, 16], "averag": 19, "averaged_perceptron_tagg": [7, 12, 19], "averaged_perceptron_tagger_eng": 9, "awar": [13, 16], "ax": [11, 13], "ax1": 11, "ax2": 11, "axhlin": 18, "axi": [11, 13, 15, 16, 19], "axvlin": 18, "b": [7, 12, 16, 19, 23], "b_1": 21, "b_2": 21, "back": 16, "backbon": 21, "backend": 2, "background_color": 11, "bag": [7, 8, 17, 18, 19], "balanc": 8, "bank": 7, "bar": [11, 13], "bark": 16, "barplot": [12, 13], "base": [1, 2, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 18, 22, 23], "basic": [1, 2, 5, 6, 11, 12, 14, 16, 19], "batch_siz": 23, "bay": 7, "bbox_to_anchor": [12, 13], "becom": [7, 19], "been": [8, 21], "befor": 20, "begin": [6, 9, 15, 16, 20], "behind": [14, 17], "being": [22, 23], "beispiel": 23, "believ": 12, "benefici": 11, "benefit": 17, "bert": [1, 3, 5, 6, 7, 8, 16, 19, 20], "bertforsequenceclassif": 8, "berttoken": 8, "better": [12, 15, 16, 19, 21, 22], "between": [7, 8, 9, 11, 12, 13, 15, 16, 17, 21, 22, 23], "beyond": 7, "bfg": 16, "bia": [5, 8, 18, 19], "bias": [8, 16, 19], "bias_analysi": 8, "bidirect": [8, 22], "big": 0, "bigram": [14, 15, 16], "bigram_count": [15, 16], "bigram_prob": [15, 16], "bigscienc": 8, "bilinear": 11, "billion": 8, "binari": 8, "bird": [9, 14], "black": 23, "block": [7, 19], "blog": [1, 5], "bloom": 8, "bo": 11, "bojanowski": 17, "bold": [11, 13, 15], "book": [1, 16, 19], "boom": 19, "both": [7, 8, 12, 19], "bottom": [11, 12, 13], "bought": 7, "boundari": [7, 8, 13], "bow_matrix": [7, 12], "box": 23, "break": [7, 9, 11, 13, 20, 22], "bridg": 7, "brief": [4, 8, 10, 14], "bring": 20, "broke": 7, "broken": 11, "brought": 6, "brown": [9, 11, 12, 16, 18, 19], "bui": 19, "build": [5, 9, 10, 12, 14, 19, 22], "built": 10, "butter": 12, "b\u1d62": 19, "c": [7, 19], "c1": 16, "c2": 16, "caf\u00e9": 12, "calcul": [7, 14, 16, 22], "calculate_bigram_prob": 15, "calculate_neural_perplex": 16, "calculate_perplex": 15, "calculate_trigram_perplex": 16, "california": 12, "call": 5, "can": [2, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 18, 19, 21, 22, 23], "canin": 7, "cannot": [12, 18, 19], "canonic": 10, "capabl": 6, "captur": [7, 8, 9, 12, 13, 16, 17, 18, 19, 20, 21, 22], "car": [7, 18, 19], "care": [8, 11], "carri": 12, "case": [5, 10, 11, 17], "cat": [7, 9, 15, 16, 18, 19, 22, 23], "categori": [7, 8, 9, 12], "cautiou": 11, "cbow": 17, "cc": 1, "center": [11, 13, 18], "chain": [5, 15], "challeng": [6, 10, 14], "chang": [8, 13], "chapter": [14, 16], "charact": [7, 10, 11, 19], "character": [7, 8], "characterist": [8, 17], "chart": 3, "chase": [7, 18, 19], "chat": 9, "chatbot": [7, 15], "check": 11, "cheju": 0, "children": 11, "choic": [8, 9, 11, 12], "chomski": 7, "choos": [12, 13, 16], "chu": [0, 1], "chunk": [7, 12, 19], "cite": 2, "clariti": 20, "class": [8, 23], "class_": 16, "class_count": 16, "class_transit": 16, "class_transition_prob": 16, "classif": [5, 7, 8, 9], "classifi": [7, 8, 9, 12, 19], "classification_report": [7, 19], "clean": [7, 10], "clean_text": 11, "cleaned_text": 11, "clear": [2, 13], "clearli": 11, "clf": [7, 19], "client": 9, "climb": 9, "close": [8, 18], "closer": 18, "cloud": 11, "cluster": 16, "cmap": 12, "cnn": 8, "co": [17, 19, 21, 23], "code": [2, 8, 11, 12, 13, 16, 18, 19, 20], "coffe": 7, "colab": 2, "cold": 13, "collabor": [2, 3, 8], "collect": [3, 7, 12, 15, 16, 18], "color": [11, 18], "com": 11, "combin": [6, 7, 11, 13, 16, 19], "come": [6, 9, 10, 14, 18, 21, 23], "comfort": [16, 20], "command": 7, "comment": 2, "commerci": 3, "common": [7, 10, 11, 15, 23], "commun": 7, "compar": [8, 9, 10, 11, 13, 14, 17, 18, 22], "compare_morphological_analyz": 13, "compare_pos_tag": 13, "compare_stem_lemma": 11, "comparison": [11, 13, 16, 17], "compil": 16, "complet": [4, 7, 8, 9, 13, 16, 20, 22], "complex": [7, 8, 13, 16, 22], "compon": [2, 8, 20, 22, 23], "compos": [21, 22], "compound": 13, "comprehend": 14, "comprehens": [6, 10, 11], "comput": [6, 7, 8, 9, 12, 15, 16, 19, 21, 22, 23], "computation": [15, 16], "concat": 21, "concaten": [21, 22, 23], "concept": [1, 2, 5, 6, 8, 9, 12, 14, 15, 16, 17, 18, 20], "conceptu": 7, "concern": 8, "concis": 23, "conclus": 2, "condit": 14, "conflict": 2, "conlltags2tre": 19, "connect": [20, 21], "consid": [6, 7, 11, 12, 13, 15, 16], "consider": [5, 8, 10, 11], "consist": [2, 7, 11, 21], "constitu": 20, "constitut": 8, "construct": 19, "contain": 12, "content": [0, 5, 9, 11, 15], "context": [7, 8, 9, 13, 14, 15, 16, 18, 19, 21, 22, 23], "context_count": 16, "context_s": 16, "contextu": [7, 19, 22], "contigu": 23, "continu": [7, 8, 13, 17, 18], "contract": 10, "contraction_map": 12, "contrast": 8, "contribut": [0, 11, 20, 22], "control": [2, 5, 8], "convei": 7, "convent": 7, "converg": [18, 21], "convert": [7, 9, 11], "convolut": [8, 21], "coordin": 2, "core": [1, 2, 3, 5, 21, 22], "corefer": 7, "corpora": [7, 8, 14, 16, 18], "corpu": [7, 8, 11, 12, 14, 15, 16, 17, 18, 19, 22], "corrcoef": 19, "correct": [10, 15], "correl": 19, "cosin": 7, "cosine_similar": 7, "cost": [7, 9], "could": [7, 9], "count": [15, 16], "countvector": [7, 12], "cours": [0, 6, 9, 17, 20], "cover": [2, 6, 7, 11, 12, 15, 16, 20], "craft": 7, "creat": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 19], "create_bow": 12, "create_class_based_model": 16, "create_ffnn_lm": 16, "create_preprocessing_pipeline_graph": 11, "create_skipgram_model": 16, "create_tfidf": 12, "creation": 0, "creativ": [8, 23], "criteria": [3, 20], "cross": 7, "cross_attent": 23, "cross_attn_output": 23, "crucial": [7, 8, 9, 10, 11, 12, 13, 15, 17, 21, 23], "cumul": 11, "cupertino": 12, "current": [6, 7], "cut": [1, 5, 6], "d": [12, 19, 22], "d_": 21, "d_ff": 23, "d_k": [21, 23], "d_model": [21, 23], "da": 23, "dai": [7, 12], "dan": 14, "data": [0, 2, 3, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22], "databas": 5, "dataset": [7, 8, 10, 11, 12, 13, 16, 17, 21, 22], "date": [4, 9, 11], "davinci": 8, "dd": 4, "deal": [7, 11, 12], "debug": 8, "decid": 11, "decis": [4, 7, 8], "decod": [12, 20], "decoder_lay": 23, "decoderlay": 23, "decompos": 15, "deep": [6, 11, 13, 17, 22], "deepen": [18, 23], "deeper": 23, "deeplearningai": 20, "def": [7, 8, 9, 11, 12, 13, 15, 16, 18, 19, 21, 23], "default": 9, "defaultdict": [15, 16], "defin": [9, 19], "definit": [10, 14], "degre": 13, "delai": 4, "deliver": 2, "delv": [6, 10, 12, 14, 15, 21], "demo": 2, "democrat": 8, "demograph": 8, "demographic_group": 8, "demoj": 12, "demonstr": [7, 8, 19, 22], "demonstrate_korean_challeng": 13, "demystifi": 23, "dens": [7, 8, 9, 12, 16, 17, 18], "depart": [0, 1], "depend": [7, 8, 15, 16, 19, 21, 22], "depth": 20, "descent": 19, "describ": 7, "descript": [4, 12], "design": [1, 2, 5, 16, 22], "despit": 7, "detail": [11, 22], "detect": 5, "determin": [7, 13], "develop": [1, 2, 5, 6, 7, 11, 13, 19], "devic": 23, "devop": 0, "diagon": 23, "diagram": [20, 22], "dictionari": 19, "differ": [2, 7, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23], "difficulti": [7, 8, 21], "digit": [7, 11], "digraph": [11, 13, 15], "dim": [7, 8, 21, 23], "dimens": [18, 19, 21, 22], "dimension": [7, 8, 17, 18], "direct": [5, 6, 21], "directli": 0, "disambigu": [7, 23], "discours": 7, "discov": 6, "discuss": [4, 5, 6, 10, 13, 14, 16, 18, 20], "displaci": 12, "disregard": 12, "dissect": 20, "distant": 21, "distinct": [13, 22], "distinguish": 15, "distribut": [2, 7, 15, 16, 17, 18], "div_term": [21, 23], "dive": [7, 10, 11, 17, 23], "divers": [2, 8, 20], "divis": 23, "do": [7, 12], "doc": [7, 12], "document": [1, 2, 5, 7, 11, 19, 23], "dodg": [12, 13], "dog": [7, 9, 11, 12, 15, 16, 18, 19, 22], "dog_vector": [18, 19], "doggi": 19, "domain": [6, 7, 8, 10, 16, 17, 18], "domin": 7, "don": [9, 11, 12, 15, 18], "dot": [16, 22, 23], "down": [7, 9, 11, 13, 20, 22], "download": [7, 9, 11, 12, 15, 18, 19], "downstream": [11, 12, 17, 18, 22], "draft": [3, 14], "dramat": [6, 8], "draw": [11, 13, 15], "draw_networkx_edge_label": 15, "drink": 12, "driven": [7, 8], "dt": 9, "dtype": 21, "due": [7, 13, 20, 21, 23], "dure": [2, 7, 22, 23], "dynam": 21, "d\u00e9liciou": 12, "e": [0, 3, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19], "each": [2, 3, 7, 8, 9, 10, 11, 14, 17, 18, 19, 20, 21, 22, 23], "earli": 6, "easier": 11, "easili": [11, 21], "econom": 8, "ed": 14, "edg": [1, 5, 6, 15], "edge_color": [11, 13], "edge_label": 15, "edward": 14, "effect": [8, 10, 11, 12, 13, 16, 18, 19, 20, 21, 23], "effici": [8, 15, 17, 18, 19, 21], "ein": 23, "either": 12, "elabor": 7, "element": [11, 20, 22], "elementwis": 22, "eleph": 9, "elif": [11, 16], "elimin": [7, 21], "eliza": 7, "eliza_respons": 7, "els": [15, 16], "email": 11, "embark": 6, "embed": [1, 2, 3, 5, 6, 7, 21, 23], "embedding_dim": [8, 16], "embedding_model": 19, "embeddings_2d": [9, 16, 18], "emerg": [6, 7], "emot": 7, "emphas": [1, 5, 7], "emploi": 21, "en_core_web_sm": 12, "enabl": [6, 7, 8, 21, 22], "enc_output": 23, "encod": [8, 12, 17, 18, 19, 20, 22], "encoder_lay": 23, "encoderlay": 23, "end": [6, 10, 14, 17, 20], "enemi": [18, 19], "engin": [1, 2, 5, 8], "english": [7, 10, 11, 13], "enhanc": [2, 8, 21], "enjoi": 8, "enjoy": 2, "enrich": 17, "ensur": [8, 9, 11, 15, 20], "ent": 12, "entelecheia": [1, 5], "enter": 4, "entir": [13, 21], "entiti": [7, 9, 11, 22], "entri": 4, "entropi": 7, "enumer": [7, 9, 11, 12, 13, 16, 18], "env": 9, "environ": 9, "environment": 8, "epoch": [16, 19, 22], "equidist": 18, "era": 7, "error": 18, "especi": [8, 12, 16, 19], "essenti": [10, 11, 14, 22, 23], "estim": [14, 15, 17], "et": [8, 17, 18, 19, 20, 21, 23], "etc": [2, 14], "ethic": [1, 5, 8, 16], "evalu": [8, 12, 17, 20], "evaluate_word_similar": 19, "even": [7, 8], "evenli": 2, "event": 7, "eventu": 7, "ever": 7, "evolut": [1, 6, 14], "evolv": [7, 8], "ewan": 14, "examin": [6, 13], "exampl": [7, 11, 12, 13, 15, 16, 18, 19, 22], "excel": 23, "exchang": 7, "excit": [6, 8], "execut": 2, "exercis": 20, "exp": [16, 21, 23], "expand": 12, "expand_contract": 12, "expanded_text": 12, "expans": [3, 12], "expens": 16, "experi": [0, 2, 9, 10, 11, 12, 13, 14, 16, 18, 19, 23], "experiment": [2, 13], "expert": 7, "explain": [8, 14, 17, 20], "explan": [4, 20], "explod": 21, "explor": [6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20], "extend": 19, "extens": 8, "extract": 5, "f": [7, 8, 9, 13, 15, 16, 19, 21], "face": [1, 5, 6, 7, 8, 13], "facebook": 19, "factor": 19, "factual": 8, "fail": 7, "fairli": 2, "fals": [11, 12, 13], "fantast": [7, 8], "fascin": [6, 9, 17], "fast": 19, "faster": [19, 21], "fasttext": [5, 8, 18], "fc": 8, "fc_out": 23, "featur": [2, 8, 12, 13, 16], "feature_extract": [7, 12], "feature_nam": [7, 12], "fed": 22, "feed": [8, 20, 22], "feedback": 5, "feedforwardnetwork": 23, "felin": 7, "few": [5, 6, 22], "ffn": [21, 23], "ffn_output": 23, "field": [6, 7, 8, 9, 20], "fig": [11, 13], "figsiz": [9, 11, 12, 13, 15, 16, 18], "figur": [9, 11, 12, 13, 15, 16, 18, 21, 22, 23], "file": 8, "film": 7, "filter": [5, 9], "filtered_text": 11, "filtered_word": 11, "final": [1, 3, 5, 6], "financ": 19, "financi": 7, "find": [8, 18, 19], "fine": [5, 8, 16, 17], "first": [7, 9, 11, 18, 19, 22], "fish": 9, "fit": [7, 13, 16, 19], "fit_transform": [7, 9, 12, 13, 16, 18], "fix": 21, "flag": [11, 12], "flask": 5, "flatten": 16, "flavor": 18, "flexibl": [8, 16, 22], "fli": 9, "float": [19, 23], "float32": 21, "floor": 15, "fluent": 15, "fmt": 12, "focu": [6, 11, 14, 20, 21, 22, 23], "focus": [2, 8, 9, 15, 20, 22, 23], "follow": [2, 7, 8, 16, 22], "font": 11, "font_siz": [11, 13, 15], "font_weight": [11, 13, 15], "forc": 22, "forest": 7, "form": [7, 9, 10, 11, 13, 20], "formal": 7, "format": [2, 7, 11, 12, 20], "forward": [8, 20, 22], "found": [9, 12], "foundat": [1, 6, 9, 10, 12, 14, 20], "fox": [9, 11, 12, 16, 18, 19], "frac": 21, "framework": [3, 16], "free": 7, "freqdist": 11, "frequenc": [7, 11, 15], "frequent": 13, "friendli": 2, "from": [0, 1, 2, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22], "from_pretrain": [7, 8], "frontend": 2, "fulli": 20, "function": [3, 7, 9, 11, 12, 13, 15, 19, 20, 21, 22], "fundament": [1, 2, 5, 6, 7, 8, 9, 10, 18, 19, 20], "further": 10, "futur": [5, 6, 23], "g": [3, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18], "gain": [0, 2, 8, 16, 17, 18, 19], "gallop": 9, "gantt": 3, "gap": [7, 16], "gender": 8, "gener": [0, 5, 6, 7, 11, 14, 15, 19, 20], "generate_square_subsequent_mask": 23, "generate_text": 8, "generated_text": 8, "gensim": [5, 8, 12, 13, 16, 17], "gentl": 14, "get": [7, 9, 16, 18, 19], "get_doc_embed": 19, "get_feature_names_out": [7, 12], "git": 2, "github": [0, 1, 2, 5], "give": [12, 13, 22], "given": [10, 14, 15, 18, 21, 22], "global": 8, "glove": [5, 7, 8, 18], "glove_python": 19, "go": 11, "goal": [3, 7, 11, 15], "goal1": 4, "goal2": 4, "goal3": 4, "good": [15, 19], "googl": [2, 7, 8, 9, 19], "gpe": 7, "gpt": [3, 6, 8, 16, 19], "gpu": 21, "gradient": [16, 19, 21], "grai": [11, 13], "gram": [1, 5, 7, 17, 19], "grammar": [7, 12], "grammat": [7, 9, 12, 13, 15], "graph": 19, "grasp": [7, 21], "grassland": 9, "great": [7, 8], "green": 11, "grew": 7, "groundbreak": 21, "group": [7, 8, 11, 16], "grow": 7, "growth": 7, "gru": 21, "guidelin": 1, "h": 14, "ha": [6, 7, 8, 11, 12, 13, 20, 21], "halla": [0, 1, 5], "hallucin": 8, "hand": [1, 2, 5, 7, 9, 12, 13, 16, 23], "handl": [7, 10, 11, 13, 14, 16, 17, 18, 19, 20, 23], "handle_emoji": 12, "hannanum": 13, "hard": 21, "hasattr": 7, "hate": 7, "have": [2, 6, 7, 8, 9, 16, 18, 19, 20, 21, 23], "he": 7, "head": [8, 20], "heatmap": 12, "height": 11, "hello": [7, 9], "help": [7, 9, 11, 12, 13, 18, 19, 22, 23], "here": [8, 11, 12, 13, 16, 18, 19], "hh": 4, "hidden": [7, 8, 16], "hidden_dim": 8, "hidden_layer_s": 19, "high": [7, 13, 23], "higher": [2, 16], "highli": 7, "hill": 7, "histor": [6, 14], "hmm": 7, "hold": [7, 8], "homepag": 0, "homework": 9, "homonym": 13, "homonymi": 13, "hop": 9, "hope": 2, "hors": 9, "hot": [8, 17, 18], "how": [4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23], "howev": [11, 21], "html": 11, "http": [1, 5, 11], "hue": [12, 13], "hug": [1, 5], "human": [6, 7, 8, 9, 14, 15, 19], "human_scor": 19, "hunt": 9, "hyperparamet": 18, "hyphen": 10, "hypothesi": 18, "i": [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 22, 23], "ibm": 7, "ic": 9, "id_to_word": 16, "idea": [2, 17, 22], "ident": 21, "identifi": [7, 9, 10, 12, 23], "idf": 7, "ieee": 2, "ignor": 12, "ignorecas": 12, "illustr": [7, 11, 20, 21, 22, 23], "imag": 8, "immens": 8, "impact": [3, 6, 10, 11, 12, 13, 20], "implement": [1, 2, 5, 9, 10, 11, 13, 15, 16, 17, 20], "impli": 7, "implic": [8, 12], "import": [7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23], "improv": [2, 3, 8, 11, 15, 16, 19], "imshow": 11, "inabl": 7, "inc": 12, "includ": [2, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 20, 21], "incorpor": [16, 19, 21], "increas": [7, 18], "increasingli": 7, "incur": 9, "independ": 7, "indic": [15, 23], "individu": [2, 7, 9, 11, 22], "industri": 8, "inf": 23, "influenc": [7, 23], "info": 11, "inform": [1, 7, 8, 9, 11, 12, 15, 17, 18, 19, 21, 23], "initi": [9, 13, 18], "initial_weight": 16, "inject": [5, 21, 23], "innov": 3, "input": [7, 8, 9, 16, 19, 20, 21, 22, 23], "input_text": 7, "insight": 17, "instal": [2, 9, 10, 17, 19], "instead": 21, "institut": 7, "int": [15, 16], "intellig": [0, 6, 7, 9], "intent": 15, "interact": [8, 9, 20], "interdisciplinari": [6, 7], "interest": [0, 12, 13], "interfac": [2, 3, 8], "intern": 23, "interpol": 11, "interpolated_prob": 16, "interpret": [6, 7, 8, 13, 14, 16], "intersect": 9, "intra": 21, "introduc": [1, 5, 8, 12, 15, 16, 18, 19, 20, 21, 22], "introduct": [1, 2, 5, 10], "intronlp": [1, 5], "intuit": [11, 13, 19], "invalu": 23, "invers": 7, "investor": 19, "involv": [7, 8, 11, 12, 13, 17], "iob_tag": 19, "ironi": 7, "irrelev": [7, 11], "isalpha": 7, "isn": 12, "isol": 13, "issu": [2, 7, 15], "ist": 23, "item": [7, 8, 12, 15, 16], "its": [6, 7, 13, 16, 18, 20], "j": [7, 16, 17, 19], "jai": [20, 21, 23], "jame": 14, "jj": 9, "job": [8, 12], "jog": 19, "john": [7, 19], "join": [7, 8, 11, 16], "joint": 15, "journei": 6, "json": 5, "jump": [9, 11, 12, 16, 18, 19], "jungl": 9, "jupyt": [2, 12], "jurafski": 14, "just": [7, 11], "k": [15, 16, 18, 21, 22, 23], "k_linear": 23, "katz_backoff": 16, "keep": [11, 12, 13], "keepdim": 16, "kei": [1, 5, 6, 7, 8, 9, 18, 23], "kera": 16, "key_to_index": [9, 16], "keyboard": [15, 19], "king": 8, "kitten": 22, "kkma": 13, "klein": 14, "kmean": 16, "kneser": 15, "knowledg": [6, 7, 22], "known": [15, 16], "konlpi": 13, "korean": [1, 10], "korean_sent": 13, "korean_sent_token": 13, "kr": 0, "kw_i": 21, "l": 16, "lab": [1, 6], "label": [7, 8, 11, 12, 16, 18, 19, 22], "label_": 12, "lack": [7, 13], "lait": 12, "lambda1": 16, "lambda2": 16, "lambda3": 16, "languag": [0, 1, 2, 3, 5, 6, 9, 10, 11, 17, 18, 19, 20, 21, 22, 23], "laplace_smoothed_bigram_prob": 15, "laptop": [1, 2, 5], "larg": [1, 2, 5, 6, 7, 9, 12, 16, 17, 18, 21, 22, 23], "larger": [8, 18, 21], "last": 7, "latest": [1, 5], "layer": [16, 20, 21, 22], "layernorm": 23, "lazi": [9, 11, 12, 16, 18, 19], "lead": [7, 8, 16], "learn": [0, 6, 9, 11, 12, 15, 16, 18, 22], "learning_r": 19, "least": 2, "lectur": [0, 2, 5, 6, 11, 12, 13], "led": 8, "lee": 9, "left": [12, 13, 21], "legal": 7, "legend": [11, 12, 13], "lemma": 11, "lemma_word": 11, "lemmat": 7, "lemmatize_word": 11, "lemmatized_text": 11, "lemmatized_token": 7, "lemmatized_word": 11, "len": [9, 11, 12, 13, 15, 16], "length": [2, 22], "less": [9, 16], "let": [6, 7, 9, 11, 12, 13, 15, 16, 18, 23], "level": 7, "leverag": [17, 21, 22], "lexic": 7, "librari": [2, 3, 5, 9, 11, 12, 13, 17, 19, 20], "lightblu": [11, 13, 15], "like": [6, 7, 13, 14, 15, 16, 18, 19, 20, 21, 23], "likelihood": [14, 15], "limit": [6, 7, 8, 14, 16, 17, 20], "line": 8, "linear": [1, 5, 8, 21, 23], "linear1": 23, "linear2": 23, "linesent": 8, "linestyl": 18, "lingual": 7, "linguist": [6, 7, 9, 16, 22], "link": [4, 20, 21, 23], "linkedin": 0, "lion": 9, "list": [3, 4, 9, 10, 12, 13, 15, 16], "liter": 7, "ll": [6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 23], "llama": 8, "llm": [1, 2, 5, 6, 9, 17, 20], "load": [7, 8, 9, 12], "loc": [12, 13], "local": 19, "locat": 12, "log": [4, 16, 19, 21, 23], "log2": [15, 16], "log_prob": [15, 16], "logger": 4, "logist": 7, "logit": [7, 8], "long": [7, 8, 16, 21, 22], "longer": [9, 16], "look": [7, 15, 22], "lookup": 19, "loper": 14, "lora": 8, "lose": [7, 12], "loss": 16, "love": [7, 12], "lower": [7, 8, 9, 11, 12, 15, 16, 18, 19, 23], "lowercas": [7, 10], "lowercased_text": 11, "lstm": [7, 8, 16, 21], "m": [7, 12], "machin": [7, 8, 11, 12, 14, 15, 17, 19, 21, 23], "made": [1, 4], "mai": [1, 5, 9, 12, 16, 22, 23], "mail": 0, "main": [0, 3, 15], "maintain": 2, "major": [5, 15], "make": [7, 8, 10, 11, 12, 13, 15, 20, 21], "man": [7, 8], "manag": 2, "mandatori": 2, "mani": [7, 8, 9, 11, 14, 15, 18, 19, 21], "manifold": [9, 12, 16, 18], "mark": [8, 13, 22], "market": [8, 19], "markov": 7, "martin": 14, "mask": [21, 22], "masked_fil": 23, "massiv": 8, "master": [1, 2, 5], "mat": [7, 9, 15, 23], "match": 7, "materi": [2, 3, 20], "math": [9, 15, 21, 23], "matmul": [21, 23], "matplotlib": [9, 11, 12, 13, 15, 16, 18], "matric": 21, "matrix": [7, 12, 17, 19, 21], "max": 21, "max_it": 19, "max_len": 23, "max_length": [7, 8], "max_token": 8, "maxent": 16, "maxent_model": 16, "maxent_ne_chunk": [7, 12, 19], "maxim": 20, "maximum": [7, 14, 15], "me": [7, 9, 13, 22], "meadow": 9, "mean": [7, 8, 9, 11, 13, 17, 18, 19, 22], "meaning": [11, 13], "measur": 15, "mechan": [5, 8], "media": [7, 11, 13], "medic": 7, "meet": 7, "member": [2, 3], "memori": [7, 8, 16], "messag": 9, "meta": 8, "method": [1, 3, 5, 7, 8, 9, 10, 11, 16, 18, 19], "methodologi": 2, "metric": [3, 7, 14, 15, 19], "midterm": [1, 2, 5], "might": [7, 11, 12], "mikolov": [17, 18], "mileston": [8, 22], "milk": 7, "million": 22, "min": 9, "min_count": [8, 12, 13, 16, 18, 19], "mind": [11, 12, 13], "mini": 9, "miniatur": 20, "minim": [16, 19, 23], "misinform": 8, "mismatch": 7, "miss": 7, "misus": 8, "mitig": 19, "mle": [14, 15], "mlm": [22, 23], "mlop": 0, "mlpclassifi": 19, "mm": 4, "mockup": 3, "model": [1, 2, 3, 5, 6, 9, 10, 12, 13, 17, 18, 19, 20, 21, 22, 23], "model_nam": [7, 8], "model_scor": 19, "model_select": [7, 19], "modern": [1, 6, 17, 18, 20, 21], "modifi": [1, 5], "modul": [8, 9, 20], "modulelist": 23, "monkei": 9, "more": [1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23], "morph": 13, "morphem": 13, "morpholog": [17, 19], "morphologi": [13, 19], "most": [8, 11, 18, 19], "most_similar": [8, 18, 19], "motiv": [3, 7], "mous": 18, "move": [8, 16, 23], "movi": [7, 8, 12], "much": [11, 23], "multi": [8, 20], "multihead": 21, "multiheadattent": 23, "multilin": 11, "multilingu": [7, 11, 19], "multimod": [0, 8], "multinomialnb": 7, "multipl": [8, 18, 19, 20, 21, 22], "must": 23, "my": [7, 9], "n": [1, 5, 7, 8, 19], "n_cluster": 16, "n_compon": [9, 12, 13, 16, 18], "n_head": 23, "n_sampl": 9, "naiv": 7, "naive_bay": 7, "name": [3, 4, 7, 9, 11, 13, 22], "name1": 4, "name2": 4, "name3": 4, "name4": 4, "natur": [0, 1, 2, 5, 6, 8, 9, 10, 11, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23], "ncategori": 8, "ne": 19, "ne_chunk": [7, 12, 19], "ne_tre": 19, "necessari": [9, 11, 12, 13], "need": [7, 8, 10, 12, 13, 14, 16, 20], "neg": [7, 8, 18, 19], "neg_log_likelihood": 16, "nei": 15, "neolog": 7, "ner": 7, "ner_tre": 7, "ner_with_embed": 19, "network": [7, 8, 14, 16, 18, 20, 22], "networkx": [11, 13, 15], "neural": [7, 8, 10, 14, 15, 18, 20, 21, 22, 23], "neural_network": 19, "neural_perplex": 16, "neutral": 7, "never": 15, "new": [7, 8, 9, 12, 13, 16, 18, 19, 21], "next": [7, 10, 11, 15, 18, 20, 22, 23], "nfkd": 12, "ngram": 16, "nking": 8, "nlp": [1, 2, 5, 6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], "nlp2024": [1, 5], "nlptown": 7, "nltk": [2, 5, 7, 11, 12, 13, 14, 15, 16, 18, 19], "nltk_data": 9, "nn": [7, 8, 9, 21, 23], "nnp": [7, 9], "no_compon": 19, "no_grad": 8, "no_thread": 19, "noam": 7, "node_color": [11, 13, 15], "node_s": [11, 13, 15], "nois": [7, 11], "non": 7, "none": [8, 23], "norm1": 23, "norm2": 23, "norm3": 23, "normal": [5, 12, 22], "normalize_unicod": 12, "normalized_text": 12, "note": 9, "notebook": 2, "noth": 7, "noun": [7, 9, 12, 13], "novel": 22, "now": [11, 12, 23], "np": [9, 12, 13, 16, 18, 19], "nsome": 16, "nsp": [22, 23], "ntext": 8, "nuanc": [7, 13], "num_class": 16, "num_lay": 23, "number": [9, 10, 11, 16, 19], "numer": 7, "numpi": [9, 12, 13, 16, 18, 19], "nvocabulari": 7, "nx": [11, 13, 15], "o": [9, 21], "object": [13, 19, 22, 23], "observ": [9, 11, 13, 14, 16, 18], "occur": [15, 18], "occurr": [17, 19], "ocean": 9, "off": [11, 12, 13, 15, 16], "offer": [6, 8, 11, 16, 18, 19, 22], "offici": 19, "offset": [12, 13, 16], "often": [7, 8, 11, 16, 23], "oh": 7, "okai": 7, "okt": 13, "onc": [2, 7, 15], "one": [8, 11, 13, 17, 18], "one_hot_cat": 18, "one_hot_dog": 18, "one_hot_mous": 18, "ones": 23, "ongo": 6, "onli": [0, 8, 9, 15, 23], "oov": 19, "oov_vector": 19, "open": [3, 7, 8], "openai": [1, 5, 8], "openai_api_kei": 9, "oper": [3, 11, 20, 21, 22], "opinion": 7, "opportun": [3, 6], "optim": [16, 17], "option": [16, 20], "order": [7, 12, 13, 14, 16, 21, 23], "organ": [7, 12], "orient": [1, 2, 5], "orig": 11, "origin": [7, 11, 12, 22], "other": [2, 8, 17, 18], "our": [6, 7, 9, 11, 12, 15, 16, 17, 18, 23], "out": [7, 11, 14, 17, 18, 19], "out_proj": 23, "outcom": 3, "outperform": 22, "output": [5, 7, 8, 11, 16, 20, 21, 22, 23], "output_dim": 8, "over": [8, 9, 11, 12, 16, 18, 19, 20], "overal": [2, 21], "overcom": 21, "overview": 5, "p": [11, 15, 16, 17], "packag": [9, 19], "pad": [7, 8], "page": [2, 20], "pai": 22, "pair": [19, 23], "pairwis": 7, "palm": 8, "panda": [12, 13], "paper": [1, 2, 5, 19, 20, 22, 23], "paradigm": 6, "paragraph": 11, "parallel": [8, 20, 21], "paralleliz": 8, "paramet": [8, 9, 11, 16, 21, 22], "park": 9, "pars": [5, 6, 7], "part": [7, 20, 21, 22, 23], "partial": [1, 5], "particip": [0, 1, 2, 5], "particl": 13, "particularli": [7, 8, 11, 15, 18, 19], "pattern": [7, 8, 16, 22], "pcfg": 7, "pd": [12, 13], "pe": [21, 23], "peer": 2, "penguin": 9, "pennington": [17, 19], "per": 8, "perform": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 21, 22], "perform_n": 12, "period": 2, "perplex": [9, 14, 16], "person": [1, 2, 5, 7, 12], "perspect": 6, "phrase": [7, 15], "piec": [7, 9], "pioneer": 7, "pip": [9, 19], "pipelin": [6, 10, 11, 12, 13], "place": 23, "plai": [11, 15, 19], "plan": 2, "plan1": 4, "plan2": 4, "pleas": [1, 2], "plot": [7, 11], "plot_embed": 18, "plot_korean_word_embed": 13, "plot_language_comparison": 13, "plot_pos_tag": 12, "plot_vector": 18, "plot_word_cloud": 11, "plot_word_embed": 12, "plot_word_frequ": 11, "plt": [9, 11, 12, 13, 15, 16, 18], "po": [7, 9, 11, 13, 15, 19, 21], "point": [4, 12, 13, 16, 22], "polit": 8, "polysemi": [18, 19], "poorli": 7, "popular": [8, 12, 18, 19], "porterstemm": [7, 11], "portion": 6, "pos_encod": 23, "pos_tag": [7, 9, 12, 13, 19], "pos_tag_text": [9, 12], "posit": [7, 8, 18, 19, 20], "positional_encod": 21, "positionalencod": 23, "possibl": [3, 6, 7, 8, 15], "post": [1, 5, 7, 13], "potenti": [6, 8, 16, 19], "power": [7, 8, 9, 22], "pp": 15, "practic": [1, 2, 5, 18], "practition": 8, "pragmat": 7, "pre": [7, 8, 9, 12, 16, 17], "predict": [7, 8, 14, 15, 16, 18, 19, 22, 23], "predicted_class": 8, "prefix": 8, "prepar": [2, 3, 12, 19], "preprocess": [1, 2, 3, 5, 8], "preprocess_text": [7, 11], "preprocessed_text": 11, "present": [2, 3, 5, 8, 9, 13, 19, 22], "preserv": 17, "prevent": [5, 23], "previou": [15, 16, 19, 20, 22], "primari": [2, 7], "primarili": 7, "print": [7, 8, 9, 11, 12, 13, 15, 16, 18, 19, 23], "privaci": 8, "prob": [15, 16], "probabilist": [7, 14, 15], "probabl": [7, 14, 16, 19, 22], "probe": 8, "probe_model_bia": 8, "problem": [1, 2, 3, 5, 8, 15, 16, 18], "problemat": 12, "process": [0, 1, 2, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 20, 21, 22, 23], "processed_text": 12, "produc": 19, "product": [2, 7, 12, 13, 22, 23], "professor": [0, 2], "profici": 6, "program": [1, 5, 7], "progress": 4, "project": [5, 23], "promin": 8, "promis": 8, "prompt": [1, 2, 5, 8, 9], "proper": 7, "properli": 13, "properti": [17, 18], "propos": [1, 2, 7], "prototyp": 5, "provid": [2, 8, 9, 10, 14, 16, 17, 18, 22, 23], "psychotherapist": 7, "pt": [7, 8], "publish": 2, "punctuat": [10, 13], "punkt": [7, 11, 15, 18], "punkt_tab": 9, "puppi": 22, "purpos": [6, 10, 14], "pursu": 7, "push": [7, 8], "put": 20, "pyplot": [9, 11, 12, 13, 15, 16, 18], "python": [1, 2, 5, 7, 14, 20, 23], "pytorch": [2, 8, 20], "q": [2, 5, 21, 22, 23], "q_linear": 23, "qualiti": [17, 23], "quantum": 8, "queri": [15, 21], "question": [8, 9, 11, 20, 22, 23], "quick": [9, 11, 12, 16, 18, 19], "quickli": [2, 7, 8, 11], "quit": 7, "qw_i": 21, "r": [7, 11, 12, 13], "rabbit": 9, "race": 8, "rag": 5, "rais": 8, "ralli": 8, "ran": 22, "rand": 23, "random": 7, "random_st": [7, 9, 12, 13, 16, 18, 19], "randomli": [18, 22], "rang": [2, 6, 7, 8, 11, 13, 15, 16, 21, 22, 23], "rare": [7, 17, 19], "ratio": 19, "raw": [7, 10, 11], "re": [7, 11, 12, 13, 16], "read": 20, "real": [1, 2, 3, 5, 7, 8, 12, 13, 16], "realli": 8, "reason": [7, 11], "recent": 6, "recogn": 7, "recognit": [7, 9, 11, 15, 22], "recommend": 7, "record": 2, "recurr": [7, 8, 16, 20, 21], "red": 11, "reduc": [7, 8, 11, 16, 21], "reduct": [17, 18], "refer": 7, "referenc": 2, "reflect": [1, 5, 11, 12, 18], "register_buff": 23, "regress": 7, "regular": 2, "regularli": 12, "reinforc": 16, "rel": [12, 21], "relat": [1, 2, 5, 8, 18, 21], "relationship": [7, 8, 9, 12, 13, 16, 17, 18, 20, 21, 22], "releas": 1, "relev": [3, 11, 21], "reli": [7, 21], "relianc": 8, "relu": [16, 21, 23], "remain": 13, "remark": [6, 8], "rememb": [11, 12, 13], "remov": [5, 7, 12, 13], "remove_stopword": 11, "render": 12, "repeat": 18, "rephras": 7, "replac": [11, 12], "report": [2, 10, 14, 17, 20], "repositori": 2, "repres": [7, 8, 12, 15, 16, 17, 18, 19, 22], "represent": [1, 7, 8, 9, 10, 11, 16, 20, 21, 22], "requir": [1, 5, 7, 8, 9, 11, 12, 13, 16, 18, 20, 23], "research": [1, 2, 3, 8, 11, 19], "resolut": 7, "resolv": 7, "resourc": [8, 12, 16], "respond": 7, "respons": [0, 3, 7, 8, 9], "result": [2, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 21], "retriev": [5, 8, 15], "return": [7, 8, 9, 11, 12, 13, 15, 16, 19, 21, 23], "return_tensor": [7, 8], "review": [7, 12, 13], "revolut": [1, 6], "revolution": [6, 7, 8, 16, 17, 18, 21], "revolutionari": 20, "rich": [17, 18, 19], "right": [11, 12, 13, 21], "rise": 6, "river": 7, "rnn": [7, 8, 16, 20], "ro": 11, "robot": 0, "robust": 16, "roger": 7, "role": [4, 9, 15, 20], "root": [7, 11, 13], "rotat": [11, 13], "rstrip": 7, "rule": [3, 6, 7, 10, 13, 15], "run": [7, 9, 11, 19], "runner": 11, "safe": [1, 5], "safeti": [5, 8], "sai": 7, "same": [7, 19, 21, 22], "sampl": [5, 7, 9, 10, 11, 15, 18, 19, 23], "sample_text": [9, 11, 12, 13], "sarcasm": 7, "sat": [7, 15, 16, 23], "savanna": 9, "saw": [7, 8], "scalabl": [7, 21], "scale": [8, 23], "scaled_dot_product_attent": 21, "scatter": [9, 12, 13, 16, 18], "scenario": 19, "schank": 7, "schedul": 2, "scienc": [6, 7, 9], "scientist": 2, "scikit": [2, 7, 9], "scipi": 16, "score": [7, 8, 14, 16, 19, 20, 21, 22], "scrape": 11, "scratch": [14, 20], "seaborn": [11, 12, 13], "search": [5, 15], "second": 22, "section": 9, "see": [1, 7, 11, 13, 20], "seen": 7, "select": [2, 18], "self": [8, 20], "self_attent": 23, "self_attn_output": 23, "semant": [6, 7, 8, 9, 12, 13, 15, 16, 17, 18], "sensit": 16, "sent": 13, "sent_token": 11, "sentenc": [7, 8, 9, 10, 11, 12, 15, 16, 18, 19, 22, 23], "sentiment": [5, 7, 8, 12, 15, 19, 22, 23], "sentiment_scor": 7, "separ": [7, 8, 21], "seq_len": 21, "sequenc": [7, 8, 15, 16, 20, 21, 22, 23], "sequence_length": 23, "sequenti": [16, 20, 21], "serv": [6, 14], "servic": 2, "session": [1, 2, 6, 9, 10, 14, 17, 20], "set": [6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 21], "set_titl": [11, 13], "set_xtick": [11, 13], "set_xticklabel": [11, 13], "set_ylabel": [11, 13], "set_ytick": 11, "setup": 9, "sever": [7, 8, 11, 13, 18, 21], "shape": [9, 12, 16, 23], "share": [2, 5, 22], "shift": [6, 7], "shirt": 7, "short": [7, 8, 9, 16, 17], "shot": [5, 6], "should": [2, 10, 20, 23], "show": [9, 11, 12, 13, 15, 16, 18, 19, 22, 23], "showcas": 11, "shrdlu": 7, "signific": [6, 7, 8, 22], "significantli": [8, 11, 12, 19, 20], "similar": [7, 8, 11, 15, 18, 22], "similar_word": [8, 18, 19], "similarity_matrix": 7, "similarity_scor": 19, "simpl": [5, 7, 8, 12, 13, 14, 15, 17, 18, 19, 20], "simple_self_attent": 23, "simplernn": 8, "simplifi": [7, 15, 16], "simul": 7, "simultan": [21, 22], "sin": [21, 23], "sinc": 21, "singl": [8, 21], "sit": 9, "size": [8, 11, 15, 16, 18, 21, 23], "skill": [1, 2, 5, 10], "skip": [9, 17], "skipgram": 16, "skipgram_count": 16, "skipgram_prob": 16, "sklearn": [7, 9, 12, 16, 18, 19], "sky": 9, "slack": 2, "sleep": 12, "slide": 18, "slower": 19, "small": [12, 15, 16], "smaller": 11, "smallest": 13, "smartphon": 15, "smooth": [14, 16], "smoothed_prob": 15, "sn": [11, 12, 13], "sne": [9, 12, 13, 16, 17, 18], "snippet": 16, "social": [7, 11, 13], "socioeconom": 8, "softmax": [7, 16, 21, 22, 23], "solid": [6, 14], "solidifi": 23, "solut": 10, "solv": [1, 2, 5, 8, 9], "some": [7, 9, 11, 12, 13, 15, 16, 22], "sophist": [6, 8, 9, 12, 14, 19], "sorri": 7, "sound": 15, "sourc": [2, 3, 23], "space": [7, 8, 13, 17, 18], "spaci": 12, "spars": [7, 18], "sparse_categorical_crossentropi": 16, "sparsiti": [14, 15, 16], "speaker": 7, "special": [7, 10, 11, 13], "specif": [6, 7, 10, 11, 12, 15, 16, 17, 18, 19, 22], "specifi": 11, "speech": [7, 14, 15], "speed": 19, "spell": [10, 15], "spill": 7, "split": [7, 9, 13, 19], "sport": [8, 18], "spring_layout": [11, 13, 15], "sqrt": [21, 23], "squeez": 8, "src": 23, "src_embed": 23, "src_mask": 23, "src_vocab_s": 23, "stage": [6, 7], "stai": 11, "standard": [7, 10, 11, 21], "start": [1, 5, 9, 11, 12, 13, 16], "state": [6, 14, 16, 21, 22], "statement": [3, 9], "static": 18, "statist": [1, 5, 6, 10, 15, 17, 19], "statu": [4, 8], "steerabl": 8, "stem": 7, "stem_word": 11, "stemmed_text": 11, "stemmed_token": 7, "stemmed_word": 11, "stemmer": 7, "step": [7, 9, 10, 11, 12, 14, 21, 22], "steve": 12, "steven": 14, "stochast": 19, "stock": [8, 19], "stone": 14, "stop": [5, 8, 13], "stop_word": [7, 11], "stopword": [7, 11], "storag": 19, "store": 7, "stori": 9, "storytel": 8, "streamlit": 5, "street": 22, "strength": [14, 19], "strip": [8, 11], "strong": 23, "structur": [5, 7, 9, 13, 22], "struggl": 7, "student": [1, 2, 5], "studi": [7, 16, 20], "style": [7, 12], "sub": [11, 12, 21], "subject": [6, 13], "submiss": [2, 20], "subplot": [11, 13], "subsequ": [7, 22], "subspac": 21, "substitut": 7, "subword": [7, 9, 17, 18], "success": [3, 7], "suffici": 15, "suggest": 15, "suitabl": [10, 12], "sum": [16, 19, 22], "summar": [8, 23], "summari": [16, 23], "super": [8, 23], "superior": [21, 22], "supplementari": 20, "support": [7, 20], "suppos": 23, "suptitl": 13, "sure": [7, 20], "sustain": 0, "svm": 7, "swap": 2, "swim": 9, "syllabu": 1, "symmetr": 23, "symmetri": 23, "syntact": [7, 18], "syntax": 23, "system": [1, 5, 6, 7, 8, 9], "sz": 23, "t": [9, 11, 12, 13, 15, 16, 17, 18], "t5": 8, "tag": [7, 11, 19], "take": 22, "takeawai": [7, 8], "taken": 23, "target": [16, 18, 23], "target_nam": 7, "task": [1, 2, 3, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22], "taught": 0, "td": 19, "teach": 2, "team": [1, 3], "tech": 8, "technic": [7, 11], "techniqu": [1, 2, 3, 5, 7, 8, 9, 10, 11, 13, 14, 17, 18, 19], "technologi": [1, 2, 5, 6, 8, 18], "telescop": 7, "temperatur": [5, 8], "tend": 18, "tensor": [21, 23], "tensorflow": [2, 16, 20], "term": [7, 8, 16, 19, 21], "terribl": 7, "test": [2, 3, 7, 11, 15], "test_corpu": 15, "test_data": 16, "test_siz": [7, 19], "text": [1, 2, 3, 5, 8, 14, 15, 16, 17, 18, 21, 22, 23], "textcoord": [12, 13, 16], "textual": 12, "tf": [7, 16], "tfidf_matrix": [7, 12], "tfidfvector": [7, 12], "tgt": 23, "tgt_embed": 23, "tgt_mask": 23, "tgt_vocab_s": 23, "th": 21, "than": [9, 16, 20, 22], "thei": [7, 8, 9, 11, 12, 15, 16, 18, 20, 21], "them": [1, 2, 5, 8, 11, 12], "theori": [7, 14], "thi": [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "those": 9, "though": 7, "thought": 5, "three": [2, 19, 21], "through": [1, 2, 5, 6, 7, 8, 9, 11, 23], "tight_layout": [11, 12, 13, 15], "time": [2, 4, 7, 8, 21], "timelin": 3, "titl": [3, 9, 11, 12, 13, 15, 16, 18], "to_lowercas": 11, "toarrai": 12, "todai": [7, 8], "toi": 11, "token": [1, 5, 6, 7, 8, 12, 15, 16, 18, 21, 23], "tokenize_text": [9, 11], "tokenized_corpu": [12, 18], "tokenized_sent": 13, "tone": 7, "too": 11, "tool": [8, 13, 20], "toolkit": [7, 10, 14], "top": 21, "top_n": 15, "top_p": 5, "topic": [2, 4, 5, 6, 15, 20], "topn": [8, 18, 19], "torch": [7, 8, 21, 23], "toward": [7, 23], "trace": [6, 7], "track": 11, "trade": [11, 12, 16], "tradit": [6, 8, 16, 17, 20], "train": [8, 9, 10, 11, 12, 13, 15, 16, 17, 19, 21], "train_data": 16, "train_korean_word2vec": 13, "train_test_split": [7, 19], "train_word2vec": [12, 16], "transfer": 8, "transform": [1, 2, 3, 5, 6, 7, 11, 14, 16, 22], "transit": [8, 15, 16], "translat": [7, 8, 15, 19, 21], "transpos": [21, 23], "treat": 7, "tree": [7, 9, 18, 19], "tree2conlltag": 19, "trello": 2, "trend": [1, 5], "tricki": 13, "trigram": [14, 15, 16], "trigram_count": 16, "trigram_perplex": 16, "trigram_prob": 16, "triu": 23, "truck": 18, "true": [7, 8, 11, 12, 13, 15, 16, 19], "truncat": [7, 8], "try": [9, 11, 16], "tsne": [9, 12, 13, 16, 18], "tune": [5, 8, 11, 16, 17], "tupl": 16, "ture": 15, "tweet": 12, "two": [18, 21, 22], "txt": 8, "type": [11, 16, 19], "typic": [7, 8, 11, 15, 19], "typographi": 11, "u": [11, 17], "uncas": [7, 8], "unchang": 13, "under": 1, "undergradu": 0, "understand": [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "unicod": 12, "unicodedata": 12, "unigram": [14, 15, 16], "unigram_count": [15, 16], "unigram_prob": 16, "uniqu": [3, 9, 11, 13], "unit": [11, 13], "univers": 0, "unlabel": 22, "unlik": [8, 17], "unnorm": 22, "unpreced": 8, "unrel": 18, "unseen": [8, 14, 16], "unsqueez": [21, 23], "unsupervis": 22, "until": 18, "up": [5, 7, 8, 9, 10, 17, 18, 19, 22], "upcom": 20, "updat": [18, 22], "upon": [9, 10, 12, 22], "upper": [12, 13], "uppercas": 10, "url": 11, "us": [1, 2, 3, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "usabl": 2, "usag": [5, 7, 8, 11, 12, 13, 15, 16, 19], "user": [2, 3, 9], "user_input": 7, "usual": 11, "util": [1, 2, 3, 5, 10, 19, 23], "v": [10, 11, 13, 15, 16, 21, 23], "v_linear": 23, "va": [11, 12, 13], "valu": [16, 21, 22], "valuabl": 0, "vanish": [16, 21], "var": 9, "variant": [16, 21], "variat": 7, "varieti": 22, "variou": [1, 2, 5, 6, 7, 8, 10, 12, 13, 14, 16, 17, 18, 19, 22], "vast": [8, 22], "vaswani": [8, 20, 21, 23], "vbg": 9, "vbz": [7, 9], "ve": [7, 9, 11, 12, 13, 15, 16, 23], "vector": [5, 7, 8, 9, 12, 16, 18, 21, 22], "vector_s": [8, 9, 12, 13, 16, 18, 19], "verb": [9, 12], "verbos": [16, 19], "veri": [7, 11], "versatil": 8, "version": [2, 22], "video": 20, "view": 23, "visit": 11, "visual": [1, 5, 11, 12, 13, 16, 17, 20], "visualize_bigram": 15, "visualize_embed": [9, 16], "visualize_pos_tag": 13, "visualize_token": 11, "vocab": [16, 18], "vocab_s": [8, 16], "vocabulari": [7, 9, 11, 14, 15, 17, 18, 19], "vw_i": 21, "w": [15, 16, 19, 21], "w1": 15, "w2": 15, "w2v_model": [12, 13], "w_1": 21, "w_2": 21, "w_i": 21, "wa": [7, 12, 22], "waddl": 9, "wai": [7, 17], "walk": [9, 23], "walkthrough": 20, "want": 22, "wast": 7, "watch": 8, "we": [2, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "weak": [14, 19], "web": [1, 2, 3, 5, 11], "websit": 11, "week": [1, 2, 3, 5], "weekli": [1, 5, 20], "weight": [7, 15, 16, 19, 22], "welcom": [1, 6, 9, 17, 20], "well": [15, 19], "went": 7, "were": [7, 21], "what": [7, 11], "when": [7, 11, 12, 13, 16, 23], "where": [15, 16, 19, 22], "whether": 22, "which": [7, 9, 11, 13, 14, 16, 21, 22, 23], "while": [7, 13, 16, 19], "white": 11, "who": 1, "why": 7, "wide": [2, 6, 8, 22], "width": 11, "wind": 13, "window": [8, 9, 12, 13, 16, 18, 19, 21], "wise": 21, "with_label": [11, 13, 15], "within": [2, 7, 20, 21, 22], "without": [7, 8, 11, 16, 20, 21], "woman": 8, "won": 12, "word": [1, 2, 3, 5, 6, 7, 14, 15, 23], "word1": 19, "word2": 19, "word2vec": [1, 5, 7, 8, 12, 13, 16], "word_class": 16, "word_freq": 11, "word_pair": 19, "word_to_id": 16, "word_token": [7, 9, 11, 12, 15, 16, 18, 19], "word_vector": [9, 12, 13, 16, 18, 19], "wordcloud": 11, "wordnet": [7, 11], "wordnetlemmat": [7, 11], "words_to_plot": [9, 16, 18], "work": [2, 7, 11, 13, 15, 16, 19, 20, 23], "worker": [8, 16, 18, 19], "world": [1, 2, 3, 5, 6, 7, 8, 12, 16, 17], "worst": 7, "would": 19, "wrap": [5, 11], "write": [8, 14, 17, 23], "written": 20, "wv": [8, 12, 13, 16, 18, 19], "www": 11, "w\u1d62": [15, 16, 19], "w\u1d62\u1d40w": 19, "w\u2081": 15, "w\u2081w\u2082": 15, "w\u2082": 15, "w\u2083": 15, "w\u2099": 15, "x": [9, 11, 12, 13, 16, 18, 19, 21, 22, 23], "x_test": [7, 19], "x_test_tfidf": 7, "x_test_vec": 7, "x_train": [7, 19], "x_train_tfidf": 7, "x_train_vec": 7, "xi": 22, "xlabel": [12, 13, 16, 18], "xticklabel": 12, "xytext": [12, 13, 16], "x\u1d62\u2c7c": 19, "y": [9, 12, 13, 16, 18, 19, 22], "y_pred": [7, 19], "y_test": [7, 19], "y_train": [7, 19], "year": 6, "yj": [0, 9], "ylabel": [12, 13, 16, 18], "ylgnbu": 12, "york": [7, 19], "you": [2, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 23], "your": [3, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 23], "yyyi": 4, "z": 11, "za": 11, "zero": [5, 6, 7, 15, 16, 21, 23], "zero_shot_classif": 8, "zip": [11, 12, 13], "\u00b2": 19, "\u03bb\u2081": 16, "\u03bb\u2081p": 16, "\u03bb\u2082": 16, "\u03bb\u2082p": 16, "\u03bb\u2083": 16, "\u03bb\u2083p": 16, "\u03c3\u1d62\u2c7c": 19, "\u1d62": 15, "\u2081": [15, 16], "\u2082": 15, "\u2082w\u1d62": 16, "\u2083": 15, "\u2c7c": 19, "\uac00\uc2e4\ub798\uc694": 13, "\uac10\uae30": 13, "\uac10\uae30\uc5d0": 13, "\uac11\ub2c8\ub2e4": 13, "\uac78\ub838\ub2e4": 13, "\uacf5\ubd80": 13, "\uacf5\ubd80\ub97c": 13, "\uacf5\ubd80\ud569\ub2c8\ub2e4": 13, "\uadf8\ub140\ub294": 13, "\uadf8\ub294": 13, "\ub098": 13, "\ub098\ub294": 13, "\ub098\ub294\ud559\uad50\uc5d0\uac14\ub2e4": 13, "\ub0a0\uc528\uac00": 13, "\ub294": 13, "\ub97c": 13, "\ub9db\uc788\ub294": 13, "\uba39\uc5c8\ub2e4": 13, "\uba39\uc5c8\uc2b5\ub2c8\ub2e4": 13, "\ubc30\uc6c1\ub2c8\ub2e4": 13, "\uc0ac\uacfc\ub97c": 13, "\uc0b0\ucc45": 13, "\uc548\ub155\ud558\uc138\uc694": 13, "\uc5d0\uac8c": 13, "\uc5f4\uc2ec\ud788": 13, "\uc624\ub298\uc740": 13, "\uc6b0\ub9ac\ub294": 13, "\uc74c\uc2dd\uc744": 13, "\uc88b\uc2b5\ub2c8\ub2e4": 13, "\uc88b\uc544\ud558\ub2e4": 13, "\uc88b\uc544\ud569\ub2c8\ub2e4": 13, "\ucc45": 13, "\ucc45\uc744": 13, "\ud559\uad50": 13, "\ud559\uad50\uc5d0": 13, "\ud559\uad50\uc5d0\uc11c": 13, "\ud55c\uad6d": 13, "\ud55c\uad6d\uc5b4": 13, "\ud55c\uad6d\uc5b4\ub97c": 13, "\ud55c\uad6d\uc5b4\uc790\uc5f0\uc5b4\ucc98\ub9ac": 13, "\ud569\ub2c8\ub2e4": 13}, "titles": ["Who made this book?", "Home", "Team Project", "NLP Project Proposal", "Week [n] Project Research Note", "Syllabus", "Week 1 - Introduction", "Week 1 Session 1 - Foundations and Evolution of NLP", "Week 1 Session 2 - The Revolution in Modern NLP", "Week 1 Lab - Introduction to NLP Basics", "Week 2 - Basics of Text Preprocessing", "Week 2 Session 1 - Text Preprocessing Fundamentals", "Week 2 Session 2 - Advanced Text Preprocessing and Representation", "Week 2 Session 3 - Korean Text Preprocessing and Tokenization", "Week 3 - Fundamentals of Language Models", "Week 3 Session 1 - Introduction to Language Models and N-grams", "Week 3 Session 2 - Advanced Statistical Language Models", "Week 4 - Word Embeddings", "Week 4 Session 1 - Introduction to Word Embeddings and Word2Vec", "Week 4 Session 2 -  Advanced Word Embeddings", "Week 5 - Transformers", "Week 5 Session 1 - Introduction to Transformers", "Week 5 Session 2 - BERT", "Week 5 Session 3 - Practical Implementation and Visualization of Transformers"], "titleterms": {"": [4, 9], "1": [2, 3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23], "1950": 7, "1980": 7, "2": [2, 3, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23], "2000": 7, "2010": 7, "3": [2, 3, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23], "4": [2, 3, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23], "4o": 9, "5": [2, 3, 7, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "6": [2, 3, 8, 11, 12, 13, 19, 23], "7": [2, 3, 8, 11, 12, 13, 23], "8": [2, 3, 8, 11], "9": [2, 3, 8], "It": 11, "The": [8, 15, 18, 21, 22], "Their": 8, "about": 1, "achiev": 4, "activ": [4, 20], "add": 15, "addit": [1, 5, 14], "advanc": [12, 16, 19, 23], "advantag": [15, 18, 21], "ahead": [10, 14, 20], "algorithm": 19, "all": [11, 21], "analogi": 19, "analysi": 13, "api": 9, "appendic": 3, "applic": [15, 17, 19, 23], "approach": 7, "architectur": [18, 19, 21, 22], "ascii": 12, "assembl": 23, "assign": [10, 14, 17, 20], "assumpt": 15, "attach": 4, "attent": [20, 21, 22, 23], "background": 3, "backoff": 16, "bag": 12, "base": [16, 19], "basic": [4, 7, 9, 10], "behind": 18, "bert": [22, 23], "best": [11, 12, 13], "bidirect": 23, "book": 0, "bow": 12, "build": 23, "calcul": 15, "capabl": 8, "case": 12, "cbow": 18, "challeng": [4, 7, 8, 13, 19], "changelog": 1, "charact": 12, "characterist": [3, 13], "class": 16, "classif": 19, "clean": [11, 12], "code": [21, 23], "compar": [16, 19], "compon": [10, 14, 17, 21], "composit": 2, "concept": [7, 19], "conclus": [7, 8, 9, 11, 12, 13, 15, 16, 18, 19, 21, 22, 23], "consider": [16, 18], "content": [1, 20], "contract": 12, "contribut": [1, 21], "convers": 11, "cours": [1, 5], "cross": 23, "current": 8, "dataset": 3, "date": 2, "decod": [21, 23], "deconstruct": 22, "deep": [7, 8], "definit": [7, 8, 15], "deliver": [3, 4], "demonstr": 9, "descript": 3, "detail": [3, 20], "develop": [3, 8], "diagram": [21, 23], "direct": [8, 16, 19], "dissect": 21, "distribut": 3, "document": 12, "dot": 21, "downstream": 19, "earli": 7, "embed": [8, 9, 12, 13, 16, 17, 18, 19, 22], "emerg": 8, "emoji": 12, "emoticon": 12, "encod": [21, 23], "entiti": [12, 19], "entropi": 16, "environ": 2, "evalu": [1, 2, 3, 5, 7, 14, 15, 19], "evolut": [7, 8], "exampl": [8, 9, 21, 23], "exercis": [9, 11, 12, 13, 16, 18, 19], "expect": 3, "extract": 7, "extrins": 19, "fasttext": [17, 19], "featur": [3, 7, 19], "feed": [16, 21, 23], "few": 8, "final": 2, "fine": 22, "formal": 15, "formul": 21, "forward": [16, 21, 23], "foundat": 7, "frequenc": 12, "from": [8, 23], "function": 23, "fundament": [11, 14], "futur": [3, 8, 16, 19], "gener": [8, 9, 23], "gensim": [9, 18, 19], "global": [17, 19], "glove": [17, 19], "goal": 4, "gpt": [9, 23], "gram": [14, 15, 16, 18], "handl": [12, 15], "head": [21, 22, 23], "heatmap": 23, "histor": 7, "home": 1, "i": 21, "idea": 18, "idf": 12, "impact": 8, "implement": [14, 18, 19, 23], "import": [2, 11], "inform": 4, "instructor": 0, "interpol": 16, "interpret": 23, "intrins": 19, "introduct": [6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "invers": 12, "item": 4, "joon": 0, "katz": 16, "kei": [2, 3, 4, 10, 14, 16, 17, 19, 20, 21, 22], "korean": 13, "lab": 9, "languag": [7, 8, 13, 14, 15, 16], "laplac": 15, "larg": 8, "layer": 23, "learn": [1, 2, 4, 5, 7, 8, 10, 14, 17, 20], "lectur": [1, 20], "lee": 0, "lemmat": 11, "librari": [10, 23], "licens": 1, "limit": [15, 18, 21], "linear": 16, "llm": 8, "look": [10, 14, 20], "lowercas": 11, "made": 0, "map": 23, "markov": 15, "mask": 23, "materi": [1, 5], "mathemat": 21, "matrix": 23, "maximum": 16, "mechan": [20, 21, 22, 23], "meet": [2, 4], "member": 4, "method": [2, 12], "model": [7, 8, 14, 15, 16], "modern": [7, 8], "modul": 23, "morpholog": 13, "multi": [21, 22, 23], "n": [4, 14, 15, 16], "name": [12, 19], "natur": 7, "need": [21, 23], "ner": [12, 19], "network": [21, 23], "neural": 16, "neuron": 22, "next": 4, "nlp": [3, 7, 8, 9], "nltk": [9, 10], "non": 12, "normal": 10, "notabl": 4, "note": [1, 2, 4, 5, 20], "object": [1, 2, 3, 5, 9, 10, 14, 17, 20], "ongo": 8, "openai": 9, "opportun": 8, "option": [9, 23], "other": [4, 15], "outcom": 4, "outlin": 5, "output": 2, "over": 21, "overview": [2, 3, 10, 14, 17, 21], "paper": 21, "paradigm": 8, "part": [9, 12, 13], "perform": 19, "perplex": 15, "perspect": 7, "phase": [2, 3], "pipelin": 7, "plan": [3, 4], "po": 12, "posit": [21, 23], "potenti": 3, "practic": [10, 11, 12, 13, 14, 16, 17, 19, 20, 23], "pre": [22, 23], "preprocess": [7, 10, 11, 12, 13], "prerequisit": [1, 5], "present": 7, "previou": 21, "probabl": 15, "process": [7, 18], "product": 21, "progress": 2, "project": [1, 2, 3, 4], "propos": 3, "purpos": 8, "put": 11, "python": 19, "pytorch": 23, "queri": 22, "read": 17, "recognit": [12, 19], "recommend": 17, "refer": [3, 21, 23], "remov": [10, 11], "represent": [12, 17, 18, 19, 23], "requir": 2, "research": 4, "resourc": [3, 14, 20], "revolut": [7, 8], "rise": 8, "rnn": 21, "role": [2, 3], "scale": 21, "score": 23, "scratch": 23, "self": [21, 23], "sentenc": 13, "session": [7, 8, 11, 12, 13, 15, 16, 18, 19, 21, 22, 23], "shift": 8, "shot": 8, "similar": 19, "simpl": [9, 16, 23], "simplifi": 22, "skip": [16, 18], "smooth": 15, "solut": 4, "special": 12, "specif": 8, "speech": [9, 12, 13], "state": 8, "statist": [7, 14, 16], "stem": 11, "stop": [10, 11], "structur": 20, "student": 0, "subword": 19, "summari": 4, "syllabu": 5, "tabl": 1, "tag": [9, 12, 13], "takeawai": 16, "task": [8, 19, 23], "team": [2, 4], "technic": 4, "techniqu": [12, 15, 16], "technologi": 3, "term": 12, "text": [7, 9, 10, 11, 12, 13, 19], "tf": 12, "thi": 0, "togeth": 11, "token": [9, 10, 11, 13], "tool": 2, "topic": [10, 14, 17, 23], "toward": 8, "tradit": [7, 18, 21], "train": [7, 18, 22, 23], "transform": [8, 20, 21, 23], "translat": 23, "tune": 22, "type": 15, "unseen": 15, "us": 9, "usag": 23, "variant": 23, "vector": [17, 19], "view": 22, "visual": [9, 15, 18, 23], "walkthrough": 23, "week": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "weekli": [2, 4], "who": 0, "word": [8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 22], "word2vec": [9, 17, 18, 19], "you": 21, "young": 0, "zero": 8}})