Search.setIndex({"alltitles": {"1. Advanced N-gram Techniques": [[24, "advanced-n-gram-techniques"]], "1. Advanced Text Cleaning Techniques": [[20, "advanced-text-cleaning-techniques"]], "1. Characteristics of Korean Language": [[21, "characteristics-of-korean-language"]], "1. Importance of Text Preprocessing": [[19, "importance-of-text-preprocessing"]], "1. Introduction to BERT": [[30, "introduction-to-bert"]], "1. Introduction to GloVe (Global Vectors for Word Representation)": [[27, "introduction-to-glove-global-vectors-for-word-representation"]], "1. Introduction to Language Models": [[22, "introduction-to-language-models"], [23, "introduction-to-language-models"]], "1. Introduction to Large Language Model APIs": [[33, "introduction-to-large-language-model-apis"]], "1. Introduction to NLP Basics": [[17, "introduction-to-nlp-basics"]], "1. Introduction to Natural Language Processing (NLP)": [[15, "introduction-to-natural-language-processing-nlp"]], "1. Introduction to Word Embeddings": [[25, "introduction-to-word-embeddings"], [26, "introduction-to-word-embeddings"]], "1. Positional Encoding": [[31, "positional-encoding"]], "1. Project Overview": [[10, "project-overview"], [11, "project-overview"]], "1. Recap of Previous Session": [[34, "recap-of-previous-session"]], "1. Tokenization": [[18, "tokenization"]], "1.1 Definition of NLP": [[15, "definition-of-nlp"]], "1.1 Formal Definition": [[23, "formal-definition"]], "1.1 Interpolation and Backoff": [[24, "interpolation-and-backoff"]], "1.1 Key Concepts of GloVe": [[27, "key-concepts-of-glove"]], "1.1 Limitations of Traditional Word Representations": [[26, "limitations-of-traditional-word-representations"]], "1.2 Applications of Language Models": [[23, "applications-of-language-models"]], "1.2 Basic Concepts": [[15, "basic-concepts"]], "1.2 GloVe Algorithm": [[27, "glove-algorithm"]], "1.2 Skip-gram Models": [[24, "skip-gram-models"]], "1.2 The Idea Behind Word Embeddings": [[26, "the-idea-behind-word-embeddings"]], "1.3 Implementing GloVe with Python": [[27, "implementing-glove-with-python"]], "2. Challenges in Korean Text Preprocessing": [[21, "challenges-in-korean-text-preprocessing"]], "2. Class-based Language Models": [[24, "class-based-language-models"]], "2. FastText: Subword-based Word Embeddings": [[27, "fasttext-subword-based-word-embeddings"]], "2. Handling Contractions and Special Cases": [[20, "handling-contractions-and-special-cases"]], "2. Historical Perspective of NLP": [[15, "historical-perspective-of-nlp"]], "2. Multi-Head Attention Module": [[31, "multi-head-attention-module"]], "2. N-gram Models": [[22, "n-gram-models"], [23, "n-gram-models"]], "2. Normalization": [[18, "normalization"]], "2. OpenAI API Overview": [[33, "openai-api-overview"]], "2. Project Background and Objectives": [[11, "project-background-and-objectives"]], "2. Project Objectives": [[10, "project-objectives"]], "2. Text Cleaning": [[19, "text-cleaning"]], "2. The Architecture of BERT": [[30, "the-architecture-of-bert"]], "2. Tokenization Example using NLTK": [[17, "tokenization-example-using-nltk"]], "2. Understanding Sampling Methods": [[34, "understanding-sampling-methods"]], "2. Word2Vec": [[25, "word2vec"], [26, "word2vec"]], "2.1 Attention Mechanism": [[30, "attention-mechanism"]], "2.1 CBOW Architecture": [[26, "cbow-architecture"]], "2.1 Early Approaches (1950s-1980s)": [[15, "early-approaches-1950s-1980s"]], "2.1 Key Features of FastText": [[27, "key-features-of-fasttext"]], "2.1 Temperature Sampling": [[34, "temperature-sampling"]], "2.1 Types of N-grams": [[23, "types-of-n-grams"]], "2.2 FastText Architecture": [[27, "fasttext-architecture"]], "2.2 Skip-gram Architecture": [[26, "skip-gram-architecture"]], "2.2 Statistical Revolution (1980s-2000s)": [[15, "statistical-revolution-1980s-2000s"]], "2.2 The Markov Assumption": [[23, "the-markov-assumption"]], "2.2 Top-p (Nucleus) Sampling": [[34, "top-p-nucleus-sampling"]], "2.2 Word Embeddings in BERT": [[30, "word-embeddings-in-bert"]], "2.3 Attention Mechanism Simplified": [[30, "attention-mechanism-simplified"]], "2.3 Calculating N-gram Probabilities": [[23, "calculating-n-gram-probabilities"]], "2.3 Implementing FastText with Gensim": [[27, "implementing-fasttext-with-gensim"]], "2.3 Top-k Sampling": [[34, "top-k-sampling"]], "2.3 Training Process": [[26, "training-process"]], "2.4 Advantages and Limitations of N-gram Models": [[23, "advantages-and-limitations-of-n-gram-models"]], "2.4 Frequency and Presence Penalties": [[34, "frequency-and-presence-penalties"]], "2.4 Implementing Word2Vec with Gensim": [[26, "implementing-word2vec-with-gensim"]], "2.5 Visualizing Word Embeddings": [[26, "visualizing-word-embeddings"]], "3. Advantages of Word2Vec": [[26, "advantages-of-word2vec"]], "3. Comparing Word2Vec, GloVe, and FastText": [[27, "comparing-word2vec-glove-and-fasttext"]], "3. Deconstructing Attention": [[30, "deconstructing-attention"]], "3. Feed-Forward Network": [[31, "feed-forward-network"]], "3. GloVe (Global Vectors for Word Representation)": [[25, "glove-global-vectors-for-word-representation"]], "3. Handling Unseen N-grams: Smoothing Techniques": [[23, "handling-unseen-n-grams-smoothing-techniques"]], "3. Korean Sentence Tokenization": [[21, "korean-sentence-tokenization"]], "3. Lowercase Conversion": [[19, "lowercase-conversion"]], "3. Maximum Entropy Language Models": [[24, "maximum-entropy-language-models"]], "3. Modern NLP and Deep Learning (2010s-Present)": [[15, "modern-nlp-and-deep-learning-2010s-present"]], "3. Named Entity Recognition (NER)": [[20, "named-entity-recognition-ner"]], "3. Part-of-Speech Tagging Demonstration": [[17, "part-of-speech-tagging-demonstration"]], "3. Practical Examples with Code": [[34, "practical-examples-with-code"]], "3. Project Description": [[11, "project-description"]], "3. Setting Up the OpenAI API": [[33, "setting-up-the-openai-api"]], "3. Statistical Language Models": [[22, "statistical-language-models"]], "3. Stop Word Removal": [[18, "stop-word-removal"]], "3. Team Composition and Roles": [[10, "team-composition-and-roles"]], "3.1 Key Features and Characteristics": [[11, "key-features-and-characteristics"]], "3.1 Laplace (Add-1) Smoothing": [[23, "laplace-add-1-smoothing"]], "3.1 Queries and Keys": [[30, "queries-and-keys"]], "3.1 Setting Up the Environment": [[34, "setting-up-the-environment"]], "3.2 Experimenting with Temperature": [[34, "experimenting-with-temperature"]], "3.2 Neuron View of Attention": [[30, "neuron-view-of-attention"]], "3.2 Other Smoothing Techniques": [[23, "other-smoothing-techniques"]], "3.2 Technologies": [[11, "technologies"]], "3.3 Dataset": [[11, "dataset"]], "3.3 Exploring Top-p Sampling": [[34, "exploring-top-p-sampling"]], "3.4 Combining Temperature and Top-p": [[34, "combining-temperature-and-top-p"]], "4. Advanced Parameters in OpenAI API": [[34, "advanced-parameters-in-openai-api"]], "4. Development Plan": [[11, "development-plan"]], "4. Encoder Layer": [[31, "encoder-layer"]], "4. Evaluating Language Models: Perplexity": [[23, "evaluating-language-models-perplexity"]], "4. FastText": [[25, "fasttext"]], "4. Implementation of N-gram Models": [[22, "implementation-of-n-gram-models"]], "4. Introduction to Neural Language Models": [[24, "introduction-to-neural-language-models"]], "4. Korean Morphological Analysis": [[21, "korean-morphological-analysis"]], "4. Limitations and Considerations": [[26, "limitations-and-considerations"]], "4. Making Your First API Call": [[33, "making-your-first-api-call"]], "4. Multi-head Attention": [[30, "multi-head-attention"]], "4. NLTK Library for Text Preprocessing": [[18, "nltk-library-for-text-preprocessing"]], "4. Part-of-Speech (POS) Tagging": [[20, "part-of-speech-pos-tagging"]], "4. Practical Applications of Word Embeddings": [[27, "practical-applications-of-word-embeddings"]], "4. Project Progression": [[10, "project-progression"]], "4. Simple Word Embedding Visualization using Gensim\u2019s Word2Vec": [[17, "simple-word-embedding-visualization-using-gensim-s-word2vec"]], "4. Tokenization": [[19, "tokenization"]], "4. Traditional NLP Pipeline": [[15, "traditional-nlp-pipeline"]], "4.1 Controlling Output Length": [[34, "controlling-output-length"]], "4.1 Detailed Plan by Development Phase": [[11, "detailed-plan-by-development-phase"]], "4.1 Text Classification": [[27, "text-classification"]], "4.1 Text Preprocessing": [[15, "text-preprocessing"]], "4.1 Weekly Learning and Team Meetings": [[10, "weekly-learning-and-team-meetings"]], "4.1 Word Embeddings": [[24, "word-embeddings"]], "4.2 Feature Extraction": [[15, "feature-extraction"]], "4.2 Named Entity Recognition (NER)": [[27, "named-entity-recognition-ner"]], "4.2 Project Phases": [[10, "project-phases"]], "4.2 Role Distribution": [[11, "role-distribution"]], "4.2 Simple Feed-forward Neural Language Model": [[24, "simple-feed-forward-neural-language-model"]], "4.2 Using Stop Sequences": [[34, "using-stop-sequences"]], "4.3 Formatting Output": [[34, "formatting-output"]], "4.3 Model Training and Evaluation": [[15, "model-training-and-evaluation"]], "5. Basic Text Generation using OpenAI\u2019s GPT-4o API (Optional)": [[17, "basic-text-generation-using-openai-s-gpt-4o-api-optional"]], "5. Challenges in Traditional NLP": [[15, "challenges-in-traditional-nlp"]], "5. Comparing Statistical and Neural Language Models": [[24, "comparing-statistical-and-neural-language-models"]], "5. Decoder Layer": [[31, "decoder-layer"]], "5. Evaluating Word Embeddings": [[27, "evaluating-word-embeddings"]], "5. Evaluation of Language Models": [[22, "evaluation-of-language-models"]], "5. Expected Deliverables": [[11, "expected-deliverables"]], "5. Final Outputs": [[10, "final-outputs"]], "5. Hands-On Exercise": [[34, "hands-on-exercise"]], "5. Part-of-Speech Tagging in Korean": [[21, "part-of-speech-tagging-in-korean"]], "5. Practical Applications of Word Embeddings": [[25, "practical-applications-of-word-embeddings"]], "5. Pre-training and Fine-tuning": [[30, "pre-training-and-fine-tuning"]], "5. Stop Word Removal": [[19, "stop-word-removal"]], "5. Text Representation Methods": [[20, "text-representation-methods"]], "5. Understanding the API Response": [[33, "understanding-the-api-response"]], "5. Visualizing N-gram Models": [[23, "visualizing-n-gram-models"]], "5.1 Intrinsic Evaluation: Word Similarity and Analogy Tasks": [[27, "intrinsic-evaluation-word-similarity-and-analogy-tasks"]], "5.1 Pre-training": [[30, "pre-training"]], "5.2 Extrinsic Evaluation: Performance on Downstream Tasks": [[27, "extrinsic-evaluation-performance-on-downstream-tasks"]], "5.2 Fine-tuning": [[30, "fine-tuning"]], "6. API Parameters": [[33, "api-parameters"]], "6. Assembling the Transformer": [[31, "assembling-the-transformer"]], "6. Challenges and Future Directions": [[27, "challenges-and-future-directions"]], "6. Common Issues and Troubleshooting": [[34, "common-issues-and-troubleshooting"]], "6. Evaluation Method": [[10, "evaluation-method"]], "6. Evaluation Plan": [[11, "evaluation-plan"]], "6. Evolution Towards Modern NLP": [[16, "evolution-towards-modern-nlp"]], "6. Korean Word Embeddings": [[21, "korean-word-embeddings"]], "6. Stemming and Lemmatization": [[19, "stemming-and-lemmatization"]], "6. Word Embeddings": [[20, "word-embeddings"]], "6.1. Introduction of Word Embeddings": [[16, "introduction-of-word-embeddings"]], "6.2. Rise of Deep Learning in NLP": [[16, "rise-of-deep-learning-in-nlp"]], "6.3. Emergence of Transformer Models": [[16, "emergence-of-transformer-models"]], "7. Best Practices and Rate Limits": [[33, "best-practices-and-rate-limits"]], "7. Conclusion and Best Practices": [[20, "conclusion-and-best-practices"], [21, "conclusion-and-best-practices"]], "7. Future Development Potential": [[11, "future-development-potential"]], "7. Generating Masks": [[31, "generating-masks"]], "7. Key Dates": [[10, "key-dates"]], "7. Large Language Models (LLMs)": [[16, "large-language-models-llms"]], "7. Putting It All Together": [[19, "putting-it-all-together"]], "7. Summary and Key Takeaways": [[34, "summary-and-key-takeaways"]], "7.1. Definition and Capabilities": [[16, "definition-and-capabilities"]], "7.2. Examples and Their Impact": [[16, "examples-and-their-impact"]], "8. Assignments for Next Week": [[34, "assignments-for-next-week"]], "8. Conclusion and Best Practices": [[19, "conclusion-and-best-practices"]], "8. Paradigm Shift in NLP Tasks": [[16, "paradigm-shift-in-nlp-tasks"]], "8. References and Resources": [[11, "references-and-resources"]], "8. Required Tools and Environment": [[10, "required-tools-and-environment"]], "8. Tokenization Basics": [[33, "tokenization-basics"]], "8.1. From Task-Specific to General-Purpose Models": [[16, "from-task-specific-to-general-purpose-models"]], "8.2. Few-Shot and Zero-Shot Learning": [[16, "few-shot-and-zero-shot-learning"]], "9. Appendices": [[11, "appendices"]], "9. Current State and Future Directions": [[16, "current-state-and-future-directions"]], "9. Important Notes": [[10, "important-notes"]], "9.1. Ongoing Developments in LLMs": [[16, "ongoing-developments-in-llms"]], "9.2. Emerging Challenges and Opportunities": [[16, "emerging-challenges-and-opportunities"]], "API Errors": [[34, "api-errors"]], "About": [[1, null]], "Additional Notes": [[1, "additional-notes"], [13, "additional-notes"]], "Additional Resources": [[22, "additional-resources"], [32, "additional-resources"]], "Advanced Topics": [[31, "advanced-topics"]], "Advantages of Transformers Over Previous Architectures": [[29, "advantages-of-transformers-over-previous-architectures"]], "Applications and Broader Implications": [[7, "applications-and-broader-implications"]], "Applications and Future Directions": [[8, "applications-and-future-directions"]], "Applications of De Novo Proteins": [[4, "applications-of-de-novo-proteins"]], "Applications of Transformers": [[31, "applications-of-transformers"]], "Assignment": [[18, "assignment"], [22, "assignment"], [25, "assignment"], [28, "assignment"]], "Assignments": [[32, "assignments"]], "Attachments": [[12, "attachments"]], "Attention Mechanism": [[28, "attention-mechanism"]], "BERT (Bidirectional Encoder Representations from Transformers)": [[31, "bert-bidirectional-encoder-representations-from-transformers"]], "Bag of Words (BoW)": [[20, "bag-of-words-bow"]], "Basic Information": [[12, "basic-information"]], "Broader Implications and Challenges": [[4, "broader-implications-and-challenges"]], "Building a Simple Transformer from Scratch": [[31, "building-a-simple-transformer-from-scratch"]], "Changelog": [[1, "changelog"]], "Code Example": [[34, "code-example"]], "Code Example: Positional Encoding": [[29, "code-example-positional-encoding"]], "Code Example: Scaled Dot-Product Attention": [[29, "code-example-scaled-dot-product-attention"]], "Code Example: Varying Temperature": [[34, "code-example-varying-temperature"]], "Code Example: Varying Top-p": [[34, "code-example-varying-top-p"]], "Code Walkthrough": [[31, "code-walkthrough"]], "Concerns About AI and the Need for Safety Research": [[9, "concerns-about-ai-and-the-need-for-safety-research"]], "Conclusion": [[15, "conclusion"], [16, "conclusion"], [17, "conclusion"], [23, "conclusion"], [24, "conclusion"], [26, "conclusion"], [27, "conclusion"], [29, "conclusion"], [30, "conclusion"], [31, "conclusion"], [33, "conclusion"], [34, "conclusion"]], "Contributing": [[1, "contributing"]], "Convolutional Neural Networks (CNNs)": [[8, "convolutional-neural-networks-cnns"]], "Course Materials": [[1, "course-materials"], [13, "course-materials"]], "Course Outline": [[13, "course-outline"]], "Debate on AI Understanding and Linguistics": [[9, "debate-on-ai-understanding-and-linguistics"]], "Diagram: Attention Heatmap Matrix": [[31, "diagram-attention-heatmap-matrix"]], "Diagram: Cross-Attention Map": [[31, "diagram-cross-attention-map"]], "Diagram: Effect of Temperature on Probability Distribution": [[34, "diagram-effect-of-temperature-on-probability-distribution"]], "Diagram: Multi-Head Attention": [[29, "diagram-multi-head-attention"]], "Diagram: Scaled Dot-Product Attention": [[29, "diagram-scaled-dot-product-attention"]], "Diagram: Transformer Architecture": [[29, "diagram-transformer-architecture"]], "Dissection of Transformer Components": [[29, "dissection-of-transformer-components"]], "Encoder and Decoder Architecture": [[29, "encoder-and-decoder-architecture"]], "Ethical Considerations in AI Deployment": [[9, "ethical-considerations-in-ai-deployment"]], "Evaluation": [[1, "evaluation"], [13, "evaluation"]], "Example": [[34, "example"], [34, "id2"]], "Example Usage": [[31, "example-usage"]], "Example: Attention Heatmap": [[31, "example-attention-heatmap"]], "Example: Generating JSON": [[34, "example-generating-json"]], "Example: Translation Task": [[31, "example-translation-task"]], "Exercise": [[19, "exercise"], [20, "exercise"], [21, "exercise"], [24, "exercise"], [26, "exercise"], [27, "exercise"]], "Expected Output": [[34, "expected-output"], [34, "id1"], [34, "id3"], [34, "id4"]], "Explanation": [[34, "explanation"]], "Feed-Forward Networks": [[29, "feed-forward-networks"]], "Formatting Issues": [[34, "formatting-issues"]], "Future Directions": [[24, "future-directions"]], "GPT (Generative Pre-trained Transformer)": [[31, "gpt-generative-pre-trained-transformer"]], "Geoffrey Hinton and the Boltzmann Machine": [[7, "geoffrey-hinton-and-the-boltzmann-machine"]], "Handling Emoji and Emoticons": [[20, "handling-emoji-and-emoticons"]], "Handling Non-ASCII Characters": [[20, "handling-non-ascii-characters"]], "Home": [[1, null]], "How AlphaFold2 Works": [[3, "how-alphafold2-works"]], "Impact and Applications": [[3, "impact-and-applications"]], "Impact of Hopfield and Hinton\u2019s Work": [[7, "impact-of-hopfield-and-hinton-s-work"]], "Implementing a Simple Attention Mechanism": [[31, "implementing-a-simple-attention-mechanism"]], "Implementing with PyTorch": [[31, "implementing-with-pytorch"]], "Initial Reactions and Reflections on the Nobel Prize": [[9, "initial-reactions-and-reflections-on-the-nobel-prize"]], "Instructions": [[34, "instructions"]], "Instructor": [[0, "instructor"]], "Interpretation": [[31, "interpretation"], [31, "id1"]], "Interpreting Attention Maps": [[31, "interpreting-attention-maps"]], "Introduction": [[19, "introduction"], [20, "introduction"], [21, "introduction"], [28, "introduction"], [29, "introduction"], [31, "introduction"]], "Introduction to Artificial Neural Networks (ANNs)": [[7, "introduction-to-artificial-neural-networks-anns"]], "Introduction to Computational Protein Design": [[4, "introduction-to-computational-protein-design"]], "Introduction to Ethical and Societal Implications": [[5, "introduction-to-ethical-and-societal-implications"]], "Introduction to Protein Structure and Its Importance": [[3, "introduction-to-protein-structure-and-its-importance"]], "John J. Hopfield and the Hopfield Network": [[7, "john-j-hopfield-and-the-hopfield-network"]], "Katz Backoff": [[24, "katz-backoff"]], "Key Achievements and Deliverables": [[12, "key-achievements-and-deliverables"]], "Key Contributions": [[29, "key-contributions"]], "Key Learning Content": [[28, "key-learning-content"], [32, "key-learning-content"]], "Key Takeaway": [[3, "key-takeaway"]], "Key Takeaways": [[4, "key-takeaways"], [5, "key-takeaways"], [7, "key-takeaways"], [8, "key-takeaways"], [9, "key-takeaways"], [24, "key-takeaways"]], "Key Topics": [[18, "key-topics"], [22, "key-topics"], [25, "key-topics"]], "Learning Objectives": [[1, "learning-objectives"], [13, "learning-objectives"], [18, "learning-objectives"], [22, "learning-objectives"], [25, "learning-objectives"], [28, "learning-objectives"], [32, "learning-objectives"]], "Learning Outcomes": [[12, "learning-outcomes"]], "Lecture": [[32, "lecture"]], "Lecture Details": [[28, "lecture-details"]], "Lecture Notes": [[1, null]], "Lemmatization": [[19, "lemmatization"]], "Libraries Needed": [[31, "libraries-needed"]], "License": [[1, "license"]], "Limitations of Traditional RNNs": [[29, "limitations-of-traditional-rnns"]], "Linear Interpolation": [[24, "linear-interpolation"]], "Looking Ahead": [[18, "looking-ahead"], [22, "looking-ahead"], [28, "looking-ahead"]], "Mathematical Explanation": [[34, "mathematical-explanation"]], "Mathematical Formulation": [[29, "mathematical-formulation"], [29, "id1"], [29, "id2"], [29, "id3"]], "Multi-Head Attention": [[29, "multi-head-attention"]], "NLP Project Proposal": [[11, null]], "Next Week\u2019s Plan": [[12, "next-week-s-plan"]], "Notes": [[28, "notes"]], "Objectives": [[17, "objectives"]], "Optional Coding Task Walkthrough": [[31, "optional-coding-task-walkthrough"]], "Optional Exercises": [[17, "optional-exercises"]], "Other Notable Items": [[12, "other-notable-items"]], "Overview": [[18, "overview"], [22, "overview"], [25, "overview"], [34, "overview"]], "Overview of the \u201cAttention is All You Need\u201d Paper": [[29, "overview-of-the-attention-is-all-you-need-paper"]], "Personal Reflections on AI and Scientific Progress": [[9, "personal-reflections-on-ai-and-scientific-progress"]], "Positional Encoding": [[29, "positional-encoding"]], "Potential Benefits and Opportunities": [[5, "potential-benefits-and-opportunities"]], "Practical Component": [[18, "practical-component"], [22, "practical-component"], [25, "practical-component"]], "Practical Considerations": [[24, "practical-considerations"]], "Practical Implementation of a Transformer": [[31, "practical-implementation-of-a-transformer"]], "Practice": [[32, "practice"]], "Practice Activities": [[28, "practice-activities"]], "Prerequisites": [[1, "prerequisites"], [13, "prerequisites"]], "Projects": [[1, null]], "Prompt": [[34, "prompt"]], "Recommended Readings": [[25, "recommended-readings"]], "Recurrent Neural Networks and LSTMs": [[8, "recurrent-neural-networks-and-lstms"]], "References": [[29, "references"], [31, "references"], [33, "references"]], "Regulatory and Policy Considerations": [[5, "regulatory-and-policy-considerations"]], "Repetitive or Nonsensical Output": [[34, "repetitive-or-nonsensical-output"]], "Resources": [[28, "resources"]], "Risks and Ethical Challenges": [[5, "risks-and-ethical-challenges"]], "Sample Code": [[34, "sample-code"]], "Scaled Dot-Product Attention": [[29, "scaled-dot-product-attention"]], "Self-Attention Function": [[31, "self-attention-function"]], "Self-Attention Mechanism": [[29, "self-attention-mechanism"]], "Session 1 - Foundational Discoveries in Machine Learning with Artificial Neural Networks": [[7, null]], "Session 1 - Protein Structure Prediction Using Artificial Intelligence": [[3, null]], "Session 2 - Computational Protein Design and De Novo Protein Engineering": [[4, null]], "Session 2 - Deep Learning Evolution and Advanced Neural Network Architectures": [[8, null]], "Session 3 - Insights from Interviews": [[5, null], [9, null]], "Societal Impacts and Public Perception": [[5, "societal-impacts-and-public-perception"]], "Special Lecture - 2024 Nobel Prize in Chemistry": [[2, null]], "Special Lecture - 2024 Nobel Prize in Physics": [[6, null]], "Stemming": [[19, "stemming"]], "Students": [[0, "students"]], "Syllabus": [[13, null]], "TF-IDF (Term Frequency-Inverse Document Frequency)": [[20, "tf-idf-term-frequency-inverse-document-frequency"]], "Table of Contents": [[1, "table-of-contents"]], "Team Meeting Summary": [[12, "team-meeting-summary"]], "Team Member Activity Summary": [[12, "team-member-activity-summary"]], "Team Project": [[10, null]], "Technical Challenges and Solutions": [[12, "technical-challenges-and-solutions"]], "The Need for Attention Mechanisms": [[29, "the-need-for-attention-mechanisms"]], "The Rise of AlphaFold and AI in Protein Folding": [[3, "the-rise-of-alphafold-and-ai-in-protein-folding"]], "The Rise of Deep Learning": [[8, "the-rise-of-deep-learning"]], "The Rosetta Platform and Protein Design Process": [[4, "the-rosetta-platform-and-protein-design-process"]], "Transformer Networks": [[8, "transformer-networks"]], "Transformer Structure": [[28, "transformer-structure"]], "Transformer Variants": [[31, "transformer-variants"]], "Visual Explanation": [[34, "visual-explanation"]], "Visualization of Attention Mechanisms": [[31, "visualization-of-attention-mechanisms"]], "Visualizing Attention Scores": [[31, "visualizing-attention-scores"]], "Week 1 - Introduction": [[14, null]], "Week 1 Lab - Introduction to NLP Basics": [[17, null]], "Week 1 Session 1 - Foundations and Evolution of NLP": [[15, null]], "Week 1 Session 2 - The Revolution in Modern NLP": [[16, null]], "Week 2 - Basics of Text Preprocessing": [[18, null]], "Week 2 Session 1 - Text Preprocessing Fundamentals": [[19, null]], "Week 2 Session 2 - Advanced Text Preprocessing and Representation": [[20, null]], "Week 2 Session 3 - Korean Text Preprocessing and Tokenization": [[21, null]], "Week 3 - Fundamentals of Language Models": [[22, null]], "Week 3 Session 1 - Introduction to Language Models and N-grams": [[23, null]], "Week 3 Session 2 - Advanced Statistical Language Models": [[24, null]], "Week 4 - Word Embeddings": [[25, null]], "Week 4 Session 1 - Introduction to Word Embeddings and Word2Vec": [[26, null]], "Week 4 Session 2 -  Advanced Word Embeddings": [[27, null]], "Week 5 - Transformers": [[28, null]], "Week 5 Session 1 - Introduction to Transformers": [[29, null]], "Week 5 Session 2 - BERT": [[30, null]], "Week 5 Session 3 - Practical Implementation and Visualization of Transformers": [[31, null]], "Week 6 - Understanding LLM APIs": [[32, null]], "Week 6 Session 1 - Introduction to LLM APIs and OpenAI API Usage": [[33, null]], "Week 6 Session 2 - Sampling Methods and Text Generation": [[34, null]], "Week [n] Project Research Note": [[12, null]], "Weekly Goal Achievement": [[12, "weekly-goal-achievement"]], "Who made this book?": [[0, null]], "Young Joon Lee": [[0, "young-joon-lee"]]}, "docnames": ["about/index", "index", "nobel-chemistry/index", "nobel-chemistry/session1", "nobel-chemistry/session2", "nobel-chemistry/session3", "nobel-physics/index", "nobel-physics/session1", "nobel-physics/session2", "nobel-physics/session3", "projects/index", "projects/proposal", "projects/research-note", "syllabus/index", "week01/index", "week01/session1", "week01/session2", "week01/wk1-lab1", "week02/index", "week02/session1", "week02/session2", "week02/session3", "week03/index", "week03/session1", "week03/session2", "week04/index", "week04/session1", "week04/session2", "week05/index", "week05/session1", "week05/session2", "week05/session3", "week06/index", "week06/session1", "week06/session2"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["about/index.md", "index.md", "nobel-chemistry/index.md", "nobel-chemistry/session1.md", "nobel-chemistry/session2.md", "nobel-chemistry/session3.md", "nobel-physics/index.md", "nobel-physics/session1.md", "nobel-physics/session2.md", "nobel-physics/session3.md", "projects/index.md", "projects/proposal.md", "projects/research-note.md", "syllabus/index.md", "week01/index.md", "week01/session1.md", "week01/session2.md", "week01/wk1-lab1.ipynb", "week02/index.md", "week02/session1.md", "week02/session2.md", "week02/session3.md", "week03/index.md", "week03/session1.md", "week03/session2.md", "week04/index.md", "week04/session1.md", "week04/session2.md", "week05/index.md", "week05/session1.md", "week05/session2.md", "week05/session3.md", "week06/index.md", "week06/session1.md", "week06/session2.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [2, 3, 4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "0": [1, 15, 16, 17, 19, 20, 21, 23, 24, 26, 27, 29, 31, 33, 34], "002": [16, 24], "003": 34, "01": [24, 33], "05": [20, 21, 27, 33], "096": 34, "1": [1, 2, 6, 12, 13, 28, 32], "10": [1, 10, 13, 17, 19, 21, 23, 24, 26, 27, 33], "100": [16, 20, 21, 24, 26, 27, 34], "1000": 24, "10000": [16, 29, 31], "11": 13, "110": 30, "12": [10, 11, 13, 19, 20, 21, 23, 30], "128": 24, "13": [10, 11, 13], "14": [10, 11, 13, 17], "15": [10, 11, 13], "16": [30, 33], "1940": 7, "1943": 7, "1949": 7, "1950": [3, 7], "1960": 3, "1961": 2, "1966": 15, "1969": 7, "1970": [5, 15], "1980": [7, 14], "1982": 7, "1983": 7, "1985": 7, "1990": 8, "1994": 3, "1e": [23, 24], "1e9": 31, "2": [1, 2, 6, 12, 13, 14, 28, 29, 32], "20": [3, 10], "200": 16, "2000": [8, 14], "2006": 8, "2013": [16, 25, 26], "2014": [16, 25, 27], "2016": [16, 27], "2017": [8, 16, 25, 29], "2018": [3, 30], "2020": 3, "2023": 33, "2024": [1, 3, 4, 5, 13, 17, 33, 34], "2048": 31, "24": 30, "25": [1, 10, 13], "256": 16, "29": 34, "2d": 26, "2f": [20, 23, 24], "2i": 29, "3": [1, 2, 4, 6, 12, 13, 28, 29, 32], "30": [1, 10, 13, 17, 19, 27], "300": [17, 26], "3000": [19, 21, 23], "33": 19, "35": [1, 13], "3b1239274bc3": 33, "3d": [2, 3], "3rd": 22, "4": [1, 13, 16], "40": 34, "400": 19, "40824829": 15, "4096": 33, "42": [15, 17, 20, 21, 24, 26, 27], "45": [19, 21], "4f": [15, 16, 23, 24], "4o": [33, 34], "5": [1, 4, 13, 16], "50": [3, 19, 24, 27, 33, 34], "500": 27, "5000": 31, "512": [15, 16, 31], "6": [1, 13, 24, 28], "60": 34, "64": 31, "66": 19, "7": [13, 26, 27], "8": [13, 17, 20, 21, 23, 24, 26, 27, 31], "800": 19, "9": [13, 27, 34], "95ecfb79a8b8": 33, "A": [5, 7, 10, 13, 14, 15, 17, 22, 24, 27, 28, 33, 34], "And": 19, "As": [8, 14, 15, 16, 19, 24, 34], "BY": 1, "Be": [19, 20, 21, 24], "By": [14, 18, 22, 24, 25, 28, 31, 32, 34], "For": [3, 16, 20, 23, 26, 29, 34], "IN": [15, 17], "If": [10, 17, 24], "In": [2, 3, 7, 8, 9, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 33, 34], "It": [3, 4, 6, 15, 17, 21, 23, 26, 30], "Its": 30, "No": [17, 21, 23, 26, 30], "Not": 27, "Of": 17, "One": [15, 23, 33, 34], "The": [1, 2, 5, 6, 7, 9, 10, 13, 14, 15, 17, 18, 19, 20, 22, 25, 27, 28, 31, 33, 34], "Their": [2, 6, 9], "There": [5, 15], "These": [8, 15, 16, 17, 24, 27, 33], "To": [5, 8, 15, 21, 23, 24, 26, 29, 33], "With": [3, 19, 34], "_": [23, 29, 31], "_1": 29, "___": 30, "__class__": 21, "__init__": [16, 31], "__name__": 21, "_h": 29, "_i": 29, "abil": [2, 3, 4, 7, 10, 16, 28, 29, 33], "abl": [2, 18, 22, 25, 28, 32], "about": [5, 14, 15, 16, 17, 19, 28, 29, 30, 33, 34], "absolut": [15, 29], "abstract": 10, "ac": 0, "academ": 3, "acceler": [2, 3, 16], "accent": 9, "accept": [5, 34], "access": [3, 5, 16, 17, 33], "account": [21, 26, 33], "accur": 33, "accuraci": [2, 3, 16], "achiev": [2, 3, 4, 6, 11, 29, 30, 34], "acid": [2, 3, 4], "acl": 10, "across": [6, 10, 15, 16, 17, 19, 27, 30], "act": [4, 15], "action": 9, "activ": [0, 2, 7, 10, 24, 29], "activity1": 12, "activity2": 12, "actual": 10, "ad": 29, "adam": 24, "adapt": [15, 16, 24, 30], "add": 20, "add_dictionari": 27, "add_edg": [21, 23], "add_edges_from": 19, "addit": [10, 12, 15, 18, 21, 30, 33], "addition": 22, "address": [4, 5, 8, 9, 14, 15, 16, 19, 23, 24, 27, 29], "adher": [10, 32], "adjac": 15, "adject": [17, 20], "adjust": [13, 17, 34], "adopt": [3, 4, 16], "advanc": [1, 2, 3, 4, 5, 6, 7, 10, 13, 14, 15, 16, 17, 18, 19, 22, 23, 25, 26, 28, 30, 33], "advantag": [16, 22, 25, 27, 28], "advent": 16, "adventur": 34, "adversari": 7, "advic": 34, "advoc": [5, 9], "afar": 34, "affect": [17, 19, 20, 32, 34], "affix": 21, "after": [9, 30, 34], "afternoon": 34, "ag": [16, 34], "again": 34, "agent": 4, "agglutin": 21, "agricultur": 3, "ai": [0, 1, 2, 6, 7, 8, 13, 15, 16, 33], "aim": [1, 4, 13, 15, 27], "ain": 20, "akin": 6, "al": [8, 16, 25, 26, 27, 28, 29, 31], "alammar": [28, 29, 31], "algebra": [1, 13], "algorithm": [4, 15, 19, 20], "align": [3, 16, 19, 21, 31], "all": [2, 3, 5, 8, 10, 15, 16, 17, 20, 23, 26, 28, 30, 31, 34], "all_word": 17, "allenai": 33, "allennlp": 33, "alloc": 9, "allow": [2, 3, 7, 8, 24, 25, 28, 29, 30, 33, 34], "almost": 2, "alpha": 24, "alphabet": 15, "alphafold": 2, "alphafold2": [2, 13], "alreadi": [3, 17, 34], "also": [0, 5, 6, 9, 15, 18, 24], "altern": 33, "although": 9, "alwai": [9, 10, 19, 21], "am": [15, 20], "ambigu": 15, "amino": [2, 3, 4], "amount": [16, 26], "an": [2, 3, 7, 9, 10, 13, 14, 15, 16, 17, 19, 21, 22, 27, 28, 29, 30, 31, 33, 34], "analogi": [7, 25, 26], "analysi": [3, 10, 13, 14, 15, 16, 18, 19, 20, 23, 27, 28, 30, 31, 33], "analyt": 19, "analyz": [15, 16, 19, 21, 22, 25, 26, 27, 28], "analyze_senti": 15, "analyzer_nam": 21, "ancient": 34, "anfinsen": 2, "ani": [9, 16, 18, 19, 21, 29], "anim": [26, 27], "ann": 6, "annot": [16, 17, 20, 21, 24, 26], "anoth": [19, 27], "answer": [8, 16, 30, 31, 33], "antibiot": 2, "antibodi": 3, "anticip": [11, 30], "apart": 29, "api": [1, 10, 11, 13, 16, 28, 31], "api_kei": [16, 17], "apolog": 15, "app": [10, 13], "appear": [23, 34], "append": [24, 27], "appl": 20, "appli": [1, 8, 10, 12, 13, 15, 18, 19, 20, 25, 29, 34], "applic": [1, 2, 5, 6, 9, 10, 11, 12, 13, 16, 17, 22, 24, 26, 28, 32], "appreci": [24, 28, 31], "approach": [3, 5, 6, 7, 8, 11, 14, 16, 18, 20, 22, 23, 24, 26, 30, 31, 34], "appropri": [19, 24, 33], "ar": [1, 2, 3, 4, 5, 7, 8, 9, 10, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "arang": [24, 29, 31], "architectur": [1, 3, 6, 10, 13, 15, 16, 24, 25, 28, 31], "area": [0, 3, 5, 10, 13, 16], "aren": 20, "argmax": [15, 16], "argu": 9, "arithmet": [16, 30], "around": 9, "arrai": [17, 24, 27, 33], "arriv": 3, "arrow": [19, 21], "art": [8, 16, 22, 24, 29, 30], "articl": [17, 20, 21, 24, 26], "artifici": [0, 1, 2, 6, 13, 14, 15, 17, 33], "asilomar": [5, 9], "ask": 34, "aspect": [1, 7, 13, 30, 31, 33], "assert": [9, 31], "assess": [2, 3], "assign": [1, 10, 13, 15, 17, 23, 24, 27, 30], "assist": [10, 16, 17, 33, 34], "associ": [6, 7, 8], "assum": [16, 31], "attach": 21, "attend": [0, 1, 8, 13, 30, 31], "attende": 12, "attent": [8, 13, 15, 16, 24], "attention_weight": [29, 31], "attn_output": 31, "attractor": 7, "au": 20, "audio": 16, "augment": [13, 16], "authent": [32, 34], "autom": 7, "automat": [8, 16], "automobil": 27, "automodelforsequenceclassif": 15, "autotoken": 15, "avail": [2, 3, 15, 24], "averag": 27, "averaged_perceptron_tagg": [15, 20, 27], "averaged_perceptron_tagger_eng": 17, "avoid": 33, "awar": [21, 24], "award": [2, 3, 4, 6, 9], "ax": [19, 21], "ax1": 19, "ax2": 19, "axhlin": 26, "axi": [19, 21, 23, 24, 27], "axvlin": 26, "b": [15, 20, 24, 27, 31, 33, 34], "b_1": 29, "b_2": 29, "back": [7, 24], "backbon": [6, 8, 29], "backend": 10, "background": 7, "background_color": 19, "backoff": 34, "backpropag": 8, "bag": [15, 16, 25, 26, 27], "baker": [2, 4, 5, 13], "balanc": [5, 16, 34], "ball": [6, 7], "bank": 15, "bar": [19, 21], "bark": 24, "barplot": [20, 21], "barrier": [3, 4], "base": [1, 7, 10, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 26, 30, 31, 32, 33, 34], "basi": 7, "basic": [1, 10, 13, 14, 19, 20, 22, 24, 27, 34], "batch_siz": 31, "bay": 15, "bbox_to_anchor": [20, 21], "beauti": 34, "becam": [7, 8, 9], "becom": [8, 15, 27, 34], "been": [2, 3, 4, 6, 9, 16, 29], "befor": [28, 34], "began": 9, "begin": [4, 14, 17, 23, 24, 28, 34], "behavior": 9, "behind": [22, 25], "being": [2, 4, 9, 30, 31, 34], "beispiel": 31, "believ": 20, "benefici": 19, "benefit": [25, 34], "bert": [1, 8, 11, 13, 14, 15, 16, 24, 27, 28], "bertforsequenceclassif": 16, "berttoken": 16, "best": [4, 32, 34], "better": [9, 20, 23, 24, 27, 29, 30], "between": [5, 13, 15, 16, 17, 19, 20, 21, 23, 24, 25, 29, 30, 31, 34], "beyond": [3, 15, 34], "bfg": 24, "bia": [13, 16, 26, 27], "bias": [16, 24, 27], "bias_analysi": 16, "bidirect": [16, 30], "bifurc": 9, "big": 0, "bigram": [22, 23, 24], "bigram_count": [23, 24], "bigram_prob": [23, 24], "bigscienc": 16, "bilinear": 19, "bill": 33, "billion": 16, "binari": [7, 16], "bind": 4, "biochemistri": [2, 3], "biolog": [2, 3, 4, 5, 7], "biologi": [2, 4, 5, 9, 13], "biologist": 9, "biomolecul": 4, "bioremedi": 4, "biosecur": 5, "biotechnologi": [2, 3, 4, 5, 9], "biotechnologist": 9, "bird": [17, 22, 34], "black": 31, "block": [2, 3, 15, 27, 34], "blog": [1, 13, 33], "bloom": 16, "bo": 19, "bojanowski": 25, "bold": [19, 21, 23], "boltzmann": [6, 8, 13], "book": [1, 24, 27], "boom": 27, "both": [6, 7, 9, 15, 16, 20, 27, 33, 34], "bottom": [19, 20, 21], "bought": 15, "boundari": [15, 16, 21], "bow_matrix": [15, 20], "box": 31, "brain": [6, 9], "brave": 34, "break": [3, 4, 5, 15, 17, 19, 21, 28, 30, 33], "breakthrough": [2, 3, 6, 7, 8, 9, 13], "bridg": [6, 15], "brief": [12, 16, 18, 22], "bring": [28, 34], "broad": [3, 8], "broader": [2, 5, 9, 34], "broke": 15, "broken": [19, 34], "brought": [4, 5, 14], "brown": [17, 19, 20, 24, 26, 27], "bui": 27, "build": [2, 3, 13, 17, 18, 20, 22, 27, 30], "built": [7, 18, 33], "butter": 20, "b\u1d62": 27, "c": [15, 27, 33, 34], "c1": 24, "c2": 24, "caf\u00e9": 20, "calcul": [15, 22, 24, 30, 32, 34], "calculate_bigram_prob": 23, "calculate_neural_perplex": 24, "calculate_perplex": 23, "calculate_trigram_perplex": 24, "california": [9, 20], "call": [7, 8, 9, 13, 32, 34], "caller": 9, "can": [3, 4, 5, 6, 8, 10, 12, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34], "canin": 15, "cannot": [20, 26, 27], "canonic": 18, "capabl": [2, 7, 9, 14, 32, 33], "captur": [7, 8, 15, 16, 17, 20, 21, 24, 25, 26, 27, 28, 29, 30], "car": [8, 15, 26, 27], "carbon": 9, "cardiovascular": 34, "care": [5, 16, 19], "carri": 20, "case": [3, 5, 13, 18, 19, 25, 33], "casp": [2, 3], "cat": [15, 17, 23, 24, 26, 27, 30, 31], "catalyz": [4, 9], "categori": [15, 16, 17, 20], "caus": 34, "cautiou": 19, "cbow": 25, "cc": 1, "cellular": 2, "center": [19, 21, 26], "certain": 7, "chain": [13, 23], "challeng": [2, 3, 8, 9, 14, 18, 22], "chang": [9, 16, 21, 34], "chapter": [22, 24], "charact": [15, 18, 19, 27, 33], "character": [15, 16], "characterist": [16, 25], "charg": 33, "chart": 11, "chase": [15, 26, 27], "chat": [17, 33, 34], "chatbot": [8, 15, 23], "check": [19, 34], "cheju": 0, "chemic": [3, 4], "chemistri": [1, 3, 4, 5, 13], "children": 19, "choic": [16, 17, 19, 20, 33, 34], "chomski": [9, 15], "choos": [20, 21, 24, 34], "chosen": 4, "christian": 2, "chu": [0, 1], "chunk": [15, 20, 27], "cite": 10, "clariti": 28, "class": [8, 16, 31], "class_": 24, "class_count": 24, "class_transit": 24, "class_transition_prob": 24, "classif": [8, 13, 15, 16, 17], "classifi": [15, 16, 17, 20, 27], "classification_report": [15, 27], "clean": [15, 18], "clean_text": 19, "cleaned_text": 19, "clear": [8, 9, 10, 21, 34], "clearli": 19, "clf": [15, 27], "client": [17, 33, 34], "climat": 9, "climb": 17, "clinic": 6, "close": [3, 16, 26], "closer": [4, 26], "cloud": 19, "cluster": 24, "cmap": 20, "cnn": 16, "co": [3, 25, 27, 29, 31], "code": [3, 10, 16, 19, 20, 21, 24, 26, 27, 28], "coffe": 15, "coher": 34, "colab": 10, "cold": 21, "collabor": [3, 5, 9, 10, 11, 16], "collect": [9, 11, 15, 20, 23, 24, 26, 34], "color": [19, 26], "com": [19, 33], "combin": [14, 15, 19, 21, 24, 27], "come": [14, 17, 18, 22, 26, 29, 31, 34], "comfort": [24, 28], "command": 15, "comment": 10, "commerci": 11, "common": [15, 18, 19, 23, 31, 32], "commun": [2, 3, 5, 9, 15], "compani": [3, 9], "compar": [3, 16, 17, 18, 19, 21, 22, 25, 26, 30], "compare_morphological_analyz": 21, "compare_pos_tag": 21, "compare_stem_lemma": 19, "comparison": [9, 19, 21, 24, 25], "competit": [2, 3], "compil": 24, "complet": [2, 6, 12, 15, 16, 17, 21, 24, 28, 30, 33, 34], "complex": [5, 6, 7, 8, 9, 15, 16, 21, 24, 30, 33], "complianc": 33, "compon": [3, 10, 16, 28, 30, 31], "compos": [29, 30], "compound": 21, "comprehend": 22, "comprehens": [14, 18, 19], "comput": [1, 2, 3, 5, 6, 7, 9, 13, 14, 15, 16, 17, 20, 23, 24, 27, 29, 30, 31, 34], "computation": [2, 4, 7, 23, 24], "concat": 29, "concaten": [29, 30, 31], "concept": [1, 6, 7, 10, 13, 14, 16, 17, 20, 22, 23, 24, 25, 26, 28, 33], "conceptu": [7, 15], "concern": [5, 16], "concis": 31, "conclus": 10, "condit": 22, "conduct": 5, "confer": [5, 9], "confid": 3, "configur": [7, 32], "conflict": 10, "conform": [2, 3, 4], "conlltags2tre": 27, "connect": [7, 13, 28, 29], "conscious": 9, "consequ": 5, "conserv": 5, "consid": [14, 15, 19, 20, 21, 23, 24, 34], "consider": [13, 16, 18, 19], "consist": [10, 15, 19, 29], "constitu": 28, "constitut": 16, "construct": 27, "consum": [3, 33], "contain": [20, 33], "contemporari": 6, "content": [0, 13, 17, 19, 23, 33, 34], "context": [15, 16, 17, 21, 22, 23, 24, 26, 27, 29, 30, 31, 34], "context_count": 24, "context_s": 24, "contextu": [15, 27, 30], "contigu": 31, "continu": [4, 15, 16, 21, 25, 26, 34], "contract": 18, "contraction_map": 20, "contrast": 16, "contribut": [0, 2, 3, 6, 7, 8, 19, 28, 30], "control": [5, 9, 10, 13, 16, 32, 33], "convei": 15, "convent": 15, "converg": [26, 29], "convers": 33, "convert": [15, 17, 19], "convolut": [16, 29], "cooper": 5, "coordin": 10, "core": [1, 10, 11, 13, 29, 30], "corefer": 15, "corpora": [15, 16, 22, 24, 26], "corpu": [15, 16, 19, 20, 22, 23, 24, 25, 26, 27, 30], "corrcoef": 27, "correct": [7, 18, 23], "correctli": 34, "correl": 27, "correspond": [33, 34], "cosin": 15, "cosine_similar": 15, "cost": [15, 17, 33, 34], "could": [2, 3, 5, 15, 17, 34], "count": [23, 24, 32, 33], "countless": 6, "countri": 5, "countvector": [15, 20], "cours": [0, 14, 17, 25, 28], "cover": [3, 4, 5, 7, 10, 14, 15, 19, 20, 23, 24, 28, 33, 34], "craft": [15, 33], "creat": [2, 3, 4, 5, 7, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 27, 33, 34], "create_bow": 20, "create_class_based_model": 24, "create_ffnn_lm": 24, "create_preprocessing_pipeline_graph": 19, "create_skipgram_model": 24, "create_tfidf": 20, "creation": [0, 2, 4, 5], "creativ": [16, 31, 32, 34], "creatur": 34, "credibl": 9, "criteria": [11, 28], "critic": [2, 3, 9], "critiqu": 9, "cross": 15, "cross_attent": 31, "cross_attn_output": 31, "crucial": [6, 9, 15, 16, 17, 18, 19, 20, 21, 23, 25, 29, 31, 33, 34], "crystallographi": [2, 3, 4], "cumul": [19, 34], "cupertino": 20, "curios": 9, "curiou": 34, "current": [14, 15], "curv": 34, "custom": [4, 5, 33], "customiz": 33, "cut": [1, 9, 13, 14], "cycl": 3, "d": [20, 27, 30, 33, 34], "d_": 29, "d_ff": 31, "d_k": [29, 31], "d_model": [29, 31], "da": 31, "dai": [9, 15, 20, 34], "dan": 22, "data": [0, 3, 6, 7, 8, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 34], "databas": [3, 13], "dataset": [15, 16, 18, 19, 20, 21, 24, 25, 29, 30], "date": [7, 12, 17, 19], "david": [2, 4, 5, 13], "davinci": [16, 34], "dd": 12, "de": [1, 2, 5], "deal": [15, 19, 20], "debug": 16, "decad": 3, "decid": [9, 19], "decis": [6, 12, 15, 16], "decod": [20, 28], "decoder_lay": 31, "decoderlay": 31, "decompos": 23, "decomposit": 2, "deep": [1, 2, 3, 6, 7, 14, 19, 21, 25, 30, 32], "deepen": [26, 31], "deeper": [8, 31, 33, 34], "deeplearningai": 28, "deepli": 8, "deepmind": [2, 3], "def": [15, 16, 17, 19, 20, 21, 23, 24, 26, 27, 29, 31, 33, 34], "default": 17, "defaultdict": [23, 24], "defin": [3, 4, 17, 27], "definit": [18, 22, 34], "degre": 21, "delai": 12, "deliver": 10, "deliveri": 2, "delv": [14, 18, 20, 22, 23, 29, 34], "demi": [2, 3, 13], "demo": 10, "democrat": [3, 16], "demograph": 16, "demographic_group": 16, "demoj": 20, "demonstr": [2, 4, 7, 9, 15, 16, 27, 30], "demonstrate_korean_challeng": 21, "demystifi": 31, "dens": [15, 16, 17, 20, 24, 25, 26], "depart": [0, 1], "depend": [8, 15, 16, 23, 24, 27, 29, 30], "depict": 4, "deploi": 9, "depth": 28, "descent": 27, "describ": 15, "descript": [12, 20], "design": [1, 2, 5, 6, 7, 8, 10, 13, 24, 30], "desir": [4, 34], "despit": [4, 15], "detail": [19, 30, 32], "detect": [8, 13], "determin": [2, 3, 15, 21, 34], "determinist": [7, 33, 34], "develop": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 19, 21, 27, 33], "devic": 31, "devop": 0, "diagnosi": 7, "diagnost": [5, 7], "diagon": 31, "diagram": [28, 30], "dictionari": 27, "didn": 34, "differ": [3, 7, 10, 15, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "difficult": [5, 8], "difficulti": [9, 15, 16, 29], "digit": [8, 15, 19], "digraph": [19, 21, 23], "dim": [15, 16, 29, 31], "dimens": [26, 27, 29, 30], "dimension": [2, 3, 4, 15, 16, 25, 26], "direct": [2, 13, 14, 29], "directli": [0, 7], "disagre": 9, "disambigu": [15, 31], "disciplin": [3, 6, 9], "discours": 15, "discov": [14, 34], "discoveri": [1, 2, 3, 6, 13], "discuss": [5, 9, 12, 13, 14, 18, 21, 22, 24, 26, 28, 34], "diseas": [3, 4, 5], "displaci": 20, "disregard": 20, "disrupt": 5, "dissect": 28, "distanc": 3, "distant": [29, 34], "distinct": [21, 30], "distinguish": 23, "distort": 7, "distribut": [7, 10, 15, 23, 24, 25, 26], "div_term": [29, 31], "dive": [15, 18, 19, 25, 31, 32, 33], "divers": [10, 16, 28, 34], "divid": 34, "divis": 31, "dna": 5, "dnn": 8, "do": [2, 4, 9, 15, 20, 33], "doc": [15, 20, 33], "document": [1, 10, 13, 15, 19, 27, 31, 32, 34], "dodg": [20, 21], "doe": [33, 34], "dog": [15, 17, 19, 20, 23, 24, 26, 27, 30], "dog_vector": [26, 27], "doggi": 27, "domain": [14, 15, 16, 18, 24, 25, 26], "domin": 15, "don": [17, 19, 20, 23, 26], "donald": 7, "dot": [24, 30, 31], "doubl": 33, "down": [3, 4, 5, 15, 17, 19, 21, 28, 30, 33, 34], "download": [15, 17, 19, 20, 23, 26, 27], "downstream": [19, 20, 25, 26, 30], "draft": [11, 22], "dragon": 34, "dramat": [14, 16], "draw": [6, 19, 21, 23], "draw_networkx_edge_label": 23, "dream": 34, "drew": [5, 9], "drink": 20, "drive": 8, "driven": [6, 9, 13, 15, 16], "drug": [2, 3, 4], "dt": 17, "dtype": 29, "dual": 5, "due": [3, 7, 8, 9, 15, 21, 28, 29, 31], "dure": [8, 10, 15, 30, 31, 32, 34], "dynam": [4, 29], "d\u00e9liciou": 20, "e": [0, 6, 7, 11, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 33, 34], "each": [3, 7, 8, 10, 11, 15, 16, 17, 18, 19, 22, 25, 26, 27, 28, 29, 30, 31, 33, 34], "earli": [7, 8, 9, 14], "earlier": 8, "easier": 19, "easili": [19, 29], "ecolog": 5, "econom": 16, "ecosystem": 5, "ed": 22, "edg": [1, 8, 13, 14, 23], "edge_color": [19, 21], "edge_label": 23, "edit": 4, "educ": 5, "edward": 22, "effect": [3, 4, 5, 8, 16, 18, 19, 20, 21, 24, 26, 27, 28, 29, 31, 33], "effici": [6, 7, 8, 16, 23, 25, 26, 27, 29], "effort": 9, "ein": 31, "either": 20, "elabor": 15, "element": [3, 4, 7, 19, 28, 30], "elementwis": 30, "eleph": 17, "elicit": 4, "elif": [19, 24], "elimin": [15, 29], "eliza": 15, "eliza_respons": 15, "els": [23, 24], "email": [9, 19], "embark": [14, 34], "embed": [1, 10, 11, 13, 14, 15, 29, 31], "embedding_dim": [16, 24], "embedding_model": 27, "embeddings_2d": [17, 24, 26], "emerg": [7, 9, 14, 15], "emiss": 9, "emot": [15, 34], "emphas": [1, 5, 9, 13, 15], "emploi": [6, 29], "en_core_web_sm": 20, "enabl": [2, 3, 4, 6, 13, 14, 15, 16, 29, 30], "enc_output": 31, "enchant": 34, "encod": [16, 20, 25, 26, 27, 28, 30, 33], "encoder_lay": 31, "encoderlay": 31, "encoding_for_model": 33, "encourag": [3, 34], "end": [14, 18, 22, 25, 28, 32], "endpoint": 33, "endur": 3, "enemi": [26, 27], "energi": [4, 6, 7], "engag": 5, "engin": [1, 2, 5, 9, 10, 13, 16, 33, 34], "english": [15, 18, 19, 21, 33], "enhanc": [4, 10, 16, 29], "enjoi": 16, "enjoy": 10, "enorm": 2, "enrich": 25, "ensur": [5, 9, 16, 17, 19, 23, 28, 32, 34], "ent": 20, "entelecheia": [1, 13], "enter": [3, 12], "entir": [2, 4, 21, 29], "entiti": [15, 17, 19, 30], "entri": [3, 12], "entropi": 15, "enumer": [15, 17, 19, 20, 21, 24, 26], "env": 17, "environ": [4, 5, 17, 32, 33], "environment": [2, 3, 4, 5, 16], "enzym": [2, 3, 4], "epoch": [24, 27, 30], "equat": 7, "equidist": 26, "equit": 5, "era": [7, 15], "error": [7, 26, 32, 33], "especi": [16, 20, 24, 27], "essenti": [3, 5, 7, 18, 19, 22, 30, 31, 34], "establish": [3, 5], "estim": [22, 23, 25, 32, 33], "et": [8, 16, 25, 26, 27, 28, 29, 31], "etc": [10, 22], "ethic": [1, 13, 16, 24], "evalu": [16, 20, 25, 28], "evaluate_word_similar": 27, "even": [2, 9, 15, 16, 34], "evenli": 10, "event": 15, "eventu": 15, "ever": 15, "everi": [7, 34], "everyon": 5, "evolut": [1, 5, 6, 7, 14, 22], "evolv": [3, 4, 7, 15, 16], "ewan": 22, "examin": [14, 21], "exampl": [4, 15, 19, 20, 21, 23, 24, 26, 27, 30, 33], "exce": 34, "excel": 31, "exchang": 15, "excit": [9, 14, 16], "execut": 10, "exercis": [28, 32], "exhibit": 9, "exist": [2, 3, 4], "existenti": 9, "exp": [24, 29, 31, 34], "expand": 20, "expand_contract": 20, "expanded_text": 20, "expans": [7, 11, 20], "expect": 2, "expens": 24, "experi": [0, 10, 17, 18, 19, 20, 21, 22, 24, 26, 27, 31, 32], "experiment": [2, 3, 4, 5, 10, 21], "expert": 15, "explain": [7, 16, 22, 25, 28, 32, 34], "explan": [12, 28, 32], "explod": 29, "explor": [3, 4, 7, 8, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 32, 33], "exponenti": 34, "export": [33, 34], "expos": 33, "express": 9, "extend": 27, "extens": 16, "extract": [13, 34], "f": [15, 16, 17, 21, 23, 24, 27, 29, 33, 34], "face": [1, 4, 13, 14, 15, 16, 21], "facebook": 27, "factor": 27, "factual": 16, "fail": 15, "fairli": 10, "fals": [19, 20, 21], "fantast": [15, 16], "fascin": [14, 17, 25], "fast": 27, "faster": [27, 29], "fasttext": [13, 16, 26], "fc": 16, "fc_out": 31, "featur": [7, 8, 10, 16, 20, 21, 24, 32, 33], "feature_extract": [15, 20], "feature_nam": [15, 20], "fed": 30, "feed": [16, 28, 30], "feedback": 13, "feedforwardnetwork": 31, "feel": 9, "felin": 15, "fellow": 5, "few": [13, 14, 30], "ffn": [29, 31], "ffn_output": 31, "field": [2, 3, 4, 6, 7, 9, 14, 15, 16, 17, 28, 33], "fig": [19, 21], "figsiz": [17, 19, 20, 21, 23, 24, 26], "figur": [4, 17, 19, 20, 21, 23, 24, 26, 29, 30, 31], "file": 16, "fill": 34, "film": 15, "filter": [8, 13, 17, 33], "filtered_text": 19, "filtered_word": 19, "final": [1, 3, 11, 13, 14], "financ": 27, "financi": 15, "find": [3, 4, 6, 7, 9, 16, 26, 27, 34], "fine": [8, 13, 16, 24, 25, 33, 34], "first": [7, 9, 15, 17, 19, 26, 27, 30], "fish": 17, "fit": [15, 21, 24, 27], "fit_transform": [15, 17, 20, 21, 24, 26], "five": 34, "fix": 29, "flag": [19, 20], "flask": 13, "flatten": 24, "flavor": 26, "flexibl": [16, 24, 30], "fli": 17, "float": [27, 31], "float32": 29, "flood": 9, "floor": 23, "flow": 8, "flower": 34, "fluent": 23, "fmt": 20, "focu": [3, 14, 19, 22, 28, 29, 30, 31, 33], "focus": [5, 8, 9, 10, 16, 17, 23, 28, 30, 31, 33, 34], "fold": 4, "follow": [8, 10, 15, 16, 24, 30, 33, 34], "font": 19, "font_siz": [19, 21, 23], "font_weight": [19, 21, 23], "forc": [9, 30], "forest": [15, 34], "forev": 34, "forgotten": 34, "form": [6, 7, 9, 15, 17, 18, 19, 21, 28], "formal": 15, "format": [10, 15, 19, 20, 28], "forward": [4, 16, 28, 30], "foster": [5, 9], "found": [4, 17, 20], "foundat": [1, 4, 6, 8, 13, 14, 17, 18, 20, 22, 28], "founder": 3, "fox": [17, 19, 20, 24, 26, 27], "frac": [29, 34], "fraction": 2, "frame": 6, "framework": [5, 9, 11, 24], "francisco": 34, "free": 15, "freqdist": 19, "frequenc": [15, 19, 23], "frequent": 21, "friendli": [4, 10], "from": [0, 1, 2, 3, 4, 6, 7, 8, 10, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 33, 34], "from_pretrain": [15, 16], "frontend": 10, "full": 34, "fulli": [7, 9, 28], "function": [2, 3, 4, 5, 6, 7, 11, 15, 17, 19, 20, 21, 23, 27, 28, 29, 30, 33, 34], "fundament": [1, 2, 3, 10, 13, 14, 15, 16, 17, 18, 26, 27, 28], "further": [2, 18, 33], "futur": [2, 4, 7, 13, 14, 31], "g": [11, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 33, 34], "gain": [0, 5, 10, 16, 24, 25, 26, 27], "gallop": 17, "gan": 7, "gantt": 11, "gap": [5, 15, 24], "garden": 34, "gate": 8, "gender": 16, "gene": 4, "gener": [0, 1, 6, 7, 8, 13, 14, 15, 19, 22, 23, 27, 28, 32, 33], "generate_square_subsequent_mask": 31, "generate_text": [16, 34], "generated_text": 16, "genet": [3, 5, 9], "gensim": [13, 16, 20, 21, 24, 25], "gentl": 22, "geoffrei": [6, 8, 9], "get": [15, 17, 24, 26, 27, 33], "get_doc_embed": 27, "get_feature_names_out": [15, 20], "gi": 33, "girl": 34, "git": 10, "github": [0, 1, 10, 13], "give": [20, 21, 30], "given": [4, 7, 18, 22, 23, 26, 29, 30], "global": [4, 5, 9, 16], "glove": [13, 15, 16, 26], "glove_python": 27, "go": [3, 19, 34], "goal": [4, 11, 15, 19, 23], "goal1": 12, "goal2": 12, "goal3": 12, "gold": 34, "good": [5, 23, 27], "googl": [10, 15, 16, 17, 27], "govern": [2, 5, 9], "gpe": 15, "gpt": [6, 8, 11, 14, 16, 24, 27, 33, 34], "gpu": 29, "gradient": [8, 24, 27, 29], "grai": [19, 21], "gram": [1, 13, 15, 25, 27], "grammar": [15, 20], "grammat": [15, 17, 20, 21, 23], "graph": [27, 34], "grasp": [15, 29], "grassland": 17, "great": [15, 16], "greater": 5, "green": [4, 19], "grew": 15, "groundbreak": [3, 29], "groundwork": [6, 7], "group": [15, 16, 19, 24], "grow": 15, "growth": 15, "gru": 29, "guid": 33, "guidelin": [1, 5], "h": 22, "ha": [2, 3, 4, 6, 14, 15, 16, 19, 20, 21, 28, 29], "had": [3, 9], "halla": [0, 1, 13], "hallucin": 16, "hand": [1, 10, 13, 15, 17, 20, 21, 24, 31, 32], "handl": [8, 9, 15, 18, 19, 21, 22, 24, 25, 26, 27, 28, 31, 32, 33, 34], "handle_emoji": 20, "handwritten": 8, "hannanum": 21, "har": [4, 34], "hard": 29, "harm": [4, 5], "hasattr": 15, "hassabi": [2, 3, 13], "hate": 15, "have": [2, 3, 4, 5, 6, 8, 9, 10, 14, 15, 16, 17, 24, 26, 27, 28, 29, 31, 33, 34], "he": [9, 15, 34], "head": [16, 28], "health": [4, 5, 34], "healthcar": 5, "hear": 34, "heart": 34, "heatmap": 20, "heavili": 9, "hebb": 7, "hebbian": 7, "height": 19, "hello": [15, 17, 33], "help": [3, 7, 8, 15, 17, 19, 20, 21, 26, 27, 30, 31, 33, 34], "her": 34, "here": [16, 19, 20, 21, 24, 26, 27, 33, 34], "hh": 12, "hi": [3, 4, 9, 34], "hidden": [6, 7, 15, 16, 24, 34], "hidden_dim": 16, "hidden_layer_s": 27, "hierarchi": 8, "high": [3, 15, 21, 31, 34], "higher": [10, 24, 34], "highest": 34, "highli": [8, 9, 15, 34], "highlight": [2, 4, 5, 7, 9], "hill": 15, "him": [9, 34], "hinton": [6, 8, 9], "histor": [2, 3, 7, 14, 22], "histori": [3, 9, 33], "hmm": 15, "hochreit": 8, "hold": [15, 16], "homepag": 0, "homework": 17, "homonym": 21, "homonymi": 21, "hop": 17, "hope": [9, 10], "hopfield": [6, 9, 13], "hormon": 3, "hors": 17, "host": 33, "hot": [16, 25, 26], "hotel": 9, "hour": 9, "how": [4, 5, 6, 7, 9, 12, 14, 15, 16, 17, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "howev": [2, 19, 29], "html": [19, 33], "http": [1, 13, 19, 33], "hue": [20, 21], "hug": [1, 13], "human": [4, 6, 7, 8, 9, 14, 15, 16, 17, 22, 23, 27], "human_scor": 27, "humil": 9, "hunt": 17, "huyenchip": 33, "hyperparamet": 26, "hyphen": 18, "hypothesi": 26, "i": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34], "ibm": 15, "ic": 17, "id": 33, "id_to_word": 24, "idea": [9, 10, 25, 30], "ident": 29, "identifi": [3, 4, 15, 17, 18, 20, 31, 33], "idf": 15, "ieee": 10, "ignor": 20, "ignorecas": 20, "illustr": [4, 15, 19, 28, 29, 30, 31], "imag": [6, 7, 8, 16], "imbal": 5, "immedi": 9, "immens": [4, 16], "immun": 4, "immunogen": 4, "impact": [2, 4, 8, 9, 11, 13, 14, 18, 19, 20, 21, 28, 32], "imped": 8, "implement": [1, 5, 8, 10, 13, 17, 18, 19, 21, 23, 24, 25, 28, 33, 34], "impli": 15, "implic": [3, 9, 13, 16, 20, 34], "import": [5, 9, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34], "impos": 33, "improv": [2, 3, 5, 10, 11, 16, 19, 23, 24, 27, 34], "imshow": 19, "inabl": [9, 15], "inc": 20, "includ": [2, 4, 6, 7, 9, 10, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 28, 29, 32, 33, 34], "incomplet": [6, 7], "incorpor": [7, 24, 27, 29], "incorrect": 34, "increas": [15, 26, 34], "increasingli": 15, "increment": 3, "incur": 17, "independ": [6, 15], "indic": [23, 31], "individu": [10, 15, 17, 19, 30], "industri": [2, 4, 16], "inequ": 5, "inexpens": 5, "inf": 31, "influenc": [9, 15, 31, 34], "info": 19, "inform": [1, 6, 7, 8, 15, 16, 17, 19, 20, 23, 25, 26, 27, 29, 31, 33, 34], "initi": [7, 17, 21, 26, 33, 34], "initial_weight": 24, "inject": [13, 29, 31], "innov": [3, 4, 5, 11], "input": [3, 7, 8, 15, 16, 17, 24, 27, 28, 29, 30, 31, 32, 33], "input_text": 15, "insight": [1, 2, 3, 6, 25], "inspir": [6, 7], "instal": [10, 17, 18, 25, 27, 33, 34], "instead": [29, 34], "institut": 15, "instrument": 8, "int": [23, 24, 33], "integ": 34, "intellig": [0, 1, 2, 14, 15, 17, 33], "intens": [2, 3], "intent": 23, "interact": [4, 8, 16, 17, 28, 32], "interdisciplinari": [9, 14, 15], "interest": [0, 8, 20, 21], "interfac": [10, 11, 16], "intern": [5, 31], "interpol": 19, "interpolated_prob": 24, "interpret": [14, 15, 16, 21, 22, 24, 32], "intersect": [13, 17], "intervent": 9, "interview": [1, 2, 6], "intra": 29, "intrigu": 34, "introduc": [1, 5, 6, 7, 8, 13, 16, 20, 23, 24, 26, 27, 28, 29, 30, 33, 34], "introduct": [1, 8, 10, 13, 18, 32], "intronlp": [1, 13], "intuit": [19, 21, 27], "invalidrequesterror": 34, "invalu": 31, "invers": 15, "invest": 9, "investor": 27, "involv": [3, 4, 15, 16, 19, 20, 21, 25], "iob_tag": 27, "ironi": 15, "irrelev": [15, 19], "isalpha": 15, "isn": 20, "isol": 21, "issu": [2, 8, 10, 15, 23, 32, 33], "ist": 31, "item": [15, 16, 20, 23, 24, 34], "iter": 3, "its": [2, 3, 4, 6, 14, 15, 21, 24, 26, 28, 34], "j": [6, 15, 24, 25, 27], "jai": [28, 29, 31], "jame": 22, "jj": 17, "job": [16, 20], "jog": 27, "john": [2, 3, 6, 9, 13, 15, 27, 34], "join": [15, 16, 19, 24], "joint": 23, "journei": [14, 34], "json": [13, 33], "jump": [17, 19, 20, 24, 26, 27], "jumper": [2, 3, 13], "jungl": 17, "jupyt": [10, 20], "jurafski": 22, "just": [15, 19], "j\u00fcrgen": 8, "k": [23, 24, 26, 29, 30, 31, 32], "k_linear": 31, "katz_backoff": 24, "keep": [19, 20, 21, 33], "keepdim": 24, "kei": [1, 13, 14, 15, 16, 17, 26, 31, 33], "kera": 24, "key_to_index": [17, 24], "keyboard": [23, 27], "kind": 34, "king": 16, "kingdom": 34, "kitten": 30, "kkma": 21, "klein": 22, "kmean": 24, "kneser": 23, "know": 2, "knowledg": [14, 15, 30], "known": [2, 3, 6, 23, 24, 34], "konlpi": 21, "korean": [1, 18], "korean_sent": 21, "korean_sent_token": 21, "kr": 0, "kw_i": 29, "kwarg": 34, "l": 24, "lab": [1, 4, 14], "label": [15, 16, 19, 20, 24, 26, 27, 30], "label_": 20, "labor": [2, 3], "lack": [15, 21], "lai": 4, "laid": [6, 7], "lait": 20, "lambda1": 24, "lambda2": 24, "lambda3": 24, "land": 34, "landscap": [4, 6, 7], "languag": [0, 1, 6, 7, 8, 9, 10, 11, 13, 14, 17, 18, 19, 25, 26, 27, 28, 29, 30, 31, 32, 34], "laplace_smoothed_bigram_prob": 23, "laptop": [1, 10, 13], "larg": [1, 7, 9, 10, 13, 14, 15, 17, 20, 24, 25, 26, 29, 30, 31, 32, 34], "larger": [16, 26, 29], "last": [15, 34], "latest": [1, 13], "laureat": [5, 6], "layer": [6, 7, 8, 24, 28, 29, 30], "layernorm": 31, "lazi": [17, 19, 20, 24, 26, 27], "lead": [5, 6, 15, 16, 24], "leap": 4, "learn": [0, 2, 3, 6, 9, 14, 17, 19, 20, 23, 24, 26, 30, 34], "learning_r": 27, "least": [10, 34], "lectur": [0, 10, 13, 14, 19, 20, 21], "lecun": 8, "led": [3, 4, 7, 8, 9, 16, 34], "lee": 17, "left": [20, 21, 29, 34], "leftasexercis": 33, "legal": 15, "legend": [19, 20, 21], "legendari": 34, "lemma": 19, "lemma_word": 19, "lemmat": 15, "lemmatize_word": 19, "lemmatized_text": 19, "lemmatized_token": 15, "lemmatized_word": 19, "len": [17, 19, 20, 21, 23, 24, 33], "lend": 9, "length": [10, 30], "less": [17, 24, 34], "let": [14, 15, 17, 19, 20, 21, 23, 24, 26, 31, 33, 34], "level": [4, 15, 33], "leverag": [3, 8, 25, 29, 30, 32], "levinth": [2, 3], "lexic": 15, "li": 5, "librari": [10, 11, 13, 17, 19, 20, 21, 25, 27, 28, 33, 34], "life": [2, 4, 34], "lightblu": [19, 21, 23], "like": [2, 3, 5, 6, 7, 8, 9, 14, 15, 21, 22, 23, 24, 26, 27, 28, 29, 31, 32, 33, 34], "likelihood": [22, 23, 34], "limit": [7, 8, 14, 15, 16, 22, 24, 25, 28, 32, 34], "line": [16, 34], "linear": [1, 13, 16, 29, 31], "linear1": 31, "linear2": 31, "linesent": 16, "linestyl": 26, "lingual": 15, "linguist": [14, 15, 17, 24, 30], "link": [7, 12, 28, 29, 31], "linkedin": 0, "lion": 17, "list": [11, 12, 17, 18, 20, 21, 23, 24, 34], "listen": 34, "liter": 15, "live": 34, "ll": [14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 31, 33, 34], "llama": 16, "llm": [1, 9, 10, 13, 14, 17, 25, 28, 34], "load": [15, 16, 17, 20], "loc": [20, 21], "local": 27, "locat": 20, "log": [12, 24, 27, 29, 31], "log2": [23, 24], "log_prob": [23, 24], "logger": 12, "logist": 15, "logit": [15, 16, 34], "long": [4, 8, 15, 16, 24, 29, 30, 34], "longer": [8, 17, 24], "look": [15, 23, 30, 32], "lookup": 27, "loper": 22, "lora": 16, "lose": [15, 20], "loss": 24, "love": [15, 20, 34], "low": 34, "lower": [15, 16, 17, 19, 20, 23, 24, 26, 27, 31, 33], "lowercas": [15, 18], "lowercased_text": 19, "lowest": 4, "lr": 34, "lstm": [15, 16, 24, 29], "m": [15, 20], "machin": [1, 6, 8, 9, 13, 15, 16, 19, 20, 22, 23, 25, 27, 29, 31], "made": [1, 3, 8, 12, 34], "magic": 34, "magnet": [6, 7], "mai": [1, 9, 13, 17, 20, 24, 30, 31], "mail": 0, "main": [0, 11, 23], "maintain": 10, "major": [2, 3, 4, 7, 8, 9, 13, 23], "make": [2, 3, 5, 6, 7, 8, 9, 15, 16, 18, 19, 20, 21, 23, 28, 29, 32, 34], "man": [15, 16], "manag": [4, 8, 10, 33, 34], "mandatori": 10, "mani": [5, 6, 7, 8, 15, 16, 17, 19, 22, 23, 26, 27, 29], "manifold": [17, 20, 24, 26], "map": [3, 34], "mark": [2, 3, 4, 7, 8, 16, 21, 30], "market": [16, 27], "markov": 15, "martin": 22, "mask": [29, 30], "masked_fil": 31, "massiv": [3, 16], "master": [1, 10, 13, 33, 34], "mat": [15, 17, 23, 31], "match": 15, "materi": [10, 11, 28], "math": [17, 23, 29, 31], "mathemat": 7, "matmul": [29, 31], "matplotlib": [17, 19, 20, 21, 23, 24, 26], "matric": 29, "matrix": [15, 20, 25, 27, 29], "matter": 4, "max": [29, 33], "max_it": 27, "max_len": 31, "max_length": [15, 16], "max_token": [16, 33, 34], "maxent": 24, "maxent_model": 24, "maxent_ne_chunk": [15, 20, 27], "maxim": 28, "maximum": [15, 22, 23, 33, 34], "mcculloch": 7, "me": [15, 17, 21, 30], "meadow": 17, "mean": [15, 16, 17, 19, 21, 25, 26, 27, 30], "meaning": [19, 21], "measur": 23, "mechan": [6, 7, 8, 13, 16], "media": [15, 19, 21], "medic": [2, 4, 5, 7, 8, 15], "medicin": [2, 3, 4], "meet": [4, 15, 34], "member": [10, 11], "memori": [6, 7, 8, 15, 16, 24], "mention": 9, "messag": [17, 33, 34], "meta": 16, "metaphor": 7, "method": [1, 2, 3, 4, 6, 7, 11, 13, 15, 16, 17, 18, 19, 24, 26, 27, 32, 33], "methodologi": 10, "metric": [11, 15, 22, 23, 27], "midterm": [1, 10, 13], "might": [15, 19, 20], "mikolov": [25, 26], "mileston": [8, 16, 30], "milk": 15, "million": [3, 4, 30], "mimic": 4, "min": 17, "min_count": [16, 20, 21, 24, 26, 27], "mind": [9, 19, 20, 21, 33, 34], "mini": [17, 33, 34], "miniatur": 28, "minim": [4, 7, 24, 27, 31], "minski": 7, "minut": 3, "misinform": 16, "mismatch": 15, "miss": 15, "misus": [5, 16], "mitig": [5, 27], "mix": 9, "mle": [22, 23], "mlm": [30, 31], "mlop": 0, "mlpclassifi": 27, "mm": 12, "mockup": 11, "model": [1, 3, 6, 7, 8, 9, 10, 11, 13, 14, 17, 18, 20, 21, 25, 26, 27, 28, 29, 30, 31, 32, 34], "model_nam": [15, 16, 33], "model_scor": 27, "model_select": [15, 27], "moder": 33, "modern": [1, 6, 7, 8, 13, 14, 25, 26, 28, 29], "modifi": [1, 13, 32], "modul": [16, 17, 28], "modulelist": 31, "molecul": 4, "molecular": [2, 4], "moment": 3, "monitor": 33, "monkei": 17, "more": [1, 5, 7, 8, 9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34], "morn": 9, "morph": 21, "morphem": 21, "morpholog": [25, 27], "morphologi": [21, 27], "most": [3, 4, 5, 8, 16, 19, 26, 27, 33, 34], "most_similar": [16, 26, 27], "motiv": [9, 11, 15], "mous": 26, "move": [16, 24, 31], "movi": [15, 16, 20], "much": [7, 9, 19, 31], "multi": [16, 28], "multihead": 29, "multiheadattent": 31, "multilin": 19, "multilingu": [15, 19, 27], "multimod": [0, 16], "multinomialnb": 15, "multipl": [9, 16, 26, 27, 28, 29, 30, 33], "must": [5, 31, 34], "mutat": 5, "my": [15, 17], "mysteri": 34, "n": [1, 13, 15, 16, 27, 33, 34], "n1": 34, "n_cluster": 24, "n_compon": [17, 20, 21, 24, 26], "n_head": 31, "n_sampl": 17, "naiv": 15, "naive_bay": 15, "name": [11, 12, 15, 17, 19, 21, 30, 33, 34], "name1": 12, "name2": 12, "name3": 12, "name4": 12, "nanomateri": 2, "nanoparticl": [2, 4], "nation": 5, "natur": [0, 1, 2, 4, 5, 7, 8, 9, 10, 13, 14, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34], "navig": [6, 33], "ncategori": 16, "ne": 27, "ne_chunk": [15, 20, 27], "ne_tre": 27, "nearest": 7, "nearli": 3, "necessari": [17, 19, 20, 21], "need": [4, 5, 15, 16, 18, 20, 21, 22, 24, 28, 33], "neg": [15, 16, 26, 27], "neg_log_likelihood": 24, "nei": 23, "neolog": 15, "ner": 15, "ner_tre": 15, "ner_with_embed": 27, "network": [1, 2, 3, 6, 9, 13, 15, 16, 22, 24, 26, 28, 30, 33], "networkx": [19, 21, 23], "neural": [1, 2, 3, 6, 9, 13, 15, 16, 18, 22, 23, 26, 28, 29, 30, 31], "neural_network": 27, "neural_perplex": 24, "neuron": 7, "neutral": 15, "never": [23, 33], "new": [2, 3, 4, 5, 7, 9, 15, 16, 17, 20, 21, 24, 26, 27, 29, 33, 34], "newlin": 33, "next": [15, 18, 19, 23, 26, 28, 30, 31, 33], "nfkd": 20, "ngram": 24, "nking": 16, "nlp": [1, 8, 10, 13, 14, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32], "nlp2024": [1, 13], "nlptown": 15, "nltk": [10, 13, 15, 19, 20, 21, 22, 23, 24, 26, 27], "nltk_data": 17, "nmr": 4, "nn": [15, 16, 17, 29, 31], "nnp": [15, 17], "no_compon": 27, "no_grad": 16, "no_thread": 27, "noam": 15, "nobel": [1, 3, 4, 5, 13], "node": 7, "node_color": [19, 21, 23], "node_s": [19, 21, 23], "nois": [15, 19], "noisi": [6, 7], "nomin": 9, "non": 15, "none": [16, 31, 34], "norm1": 31, "norm2": 31, "norm3": 31, "normal": [13, 20, 30], "normalize_unicod": 20, "normalized_text": 20, "note": [9, 17, 34], "notebook": 10, "noth": 15, "noun": [15, 17, 20, 21], "novel": [2, 4, 5, 8, 30], "novo": [1, 2, 5], "now": [19, 20, 31], "np": [17, 20, 21, 24, 26, 27], "nsome": 24, "nsp": [30, 31], "ntext": 16, "nuanc": [15, 21], "nucleu": 33, "num_class": 24, "num_lay": 31, "num_token": 33, "num_tokens_from_str": 33, "number": [2, 3, 17, 18, 19, 24, 27, 32, 33, 34], "numer": 15, "numpi": [17, 20, 21, 24, 26, 27], "nvocabulari": 15, "nx": [19, 21, 23], "o": [17, 29], "object": [5, 8, 21, 27, 30, 31, 33, 34], "observ": [7, 17, 19, 21, 22, 24, 26, 34], "obtain": 32, "occup": 34, "occur": [23, 26], "occurr": [25, 27], "ocean": 17, "off": [19, 20, 21, 23, 24], "offer": [5, 14, 16, 19, 24, 26, 27, 30, 33, 34], "offici": 27, "offset": [20, 21, 24], "often": [15, 16, 19, 24, 31], "oh": 15, "okai": 15, "okt": 21, "old": 34, "onc": [4, 5, 10, 15, 23, 34], "one": [8, 16, 19, 21, 25, 26], "one_hot_cat": 26, "one_hot_dog": 26, "one_hot_mous": 26, "ones": 31, "ongo": [9, 14], "onli": [0, 2, 6, 9, 16, 17, 23, 31, 34], "oov": 27, "oov_vector": 27, "open": [2, 4, 11, 15, 16], "openai": [1, 13, 16, 32], "openai_api_kei": [17, 33, 34], "oper": [7, 11, 19, 28, 29, 30], "opinion": 15, "opportun": [4, 8, 11, 14], "optim": [4, 7, 24, 25, 33], "option": [24, 28], "order": [15, 20, 21, 22, 24, 29, 31], "org": 33, "organ": [4, 7, 15, 20], "orient": [1, 10, 13], "orig": 19, "origin": [2, 15, 19, 20, 30], "other": [3, 4, 5, 7, 8, 9, 10, 16, 25, 26, 34], "our": [14, 15, 17, 19, 20, 23, 24, 25, 26, 31, 34], "out": [9, 15, 19, 22, 25, 26, 27, 34], "out_proj": 31, "outcom": [5, 9, 11], "outperform": [3, 30], "output": [13, 15, 16, 19, 24, 28, 29, 30, 31, 32, 33], "output_dim": 16, "over": [3, 4, 8, 16, 17, 19, 20, 24, 26, 27, 28, 33, 34], "overal": [10, 29], "overcom": [4, 8, 29], "overview": [8, 13, 32], "overwhelm": 9, "p": [19, 23, 24, 25, 32], "p_i": 34, "packag": [17, 27, 33], "pad": [15, 16], "page": [10, 28], "pai": 30, "pair": [27, 31], "pairwis": 15, "palm": 16, "panda": [20, 21], "paper": [1, 10, 13, 27, 28, 30, 31], "papert": 7, "paradigm": 14, "paradox": [2, 3], "paragraph": 19, "parallel": [5, 8, 9, 16, 28, 29], "paralleliz": 16, "paramet": [16, 17, 19, 24, 29, 30, 32], "park": 17, "pars": [13, 14, 15], "part": [15, 28, 29, 30, 31, 33], "partial": [1, 7, 13], "particip": [0, 1, 10, 13], "particl": 21, "particularli": [5, 7, 9, 15, 16, 19, 23, 26, 27], "path": 34, "pathogen": 5, "pathwai": 4, "pattern": [3, 6, 7, 8, 15, 16, 24, 30, 33], "pave": [3, 4], "pcfg": 15, "pd": [20, 21], "pe": [29, 31], "peculiar": 34, "peer": 10, "penal": 34, "penguin": 17, "pennington": [25, 27], "peopl": 34, "per": [16, 33], "perceptron": 7, "perform": [1, 4, 6, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 29, 30, 33], "perform_n": 20, "period": 10, "perplex": [17, 22, 24], "persist": 3, "person": [1, 10, 13, 15, 20], "perspect": [9, 14], "pharmaceut": 3, "phrase": [15, 23], "physic": [1, 7, 9, 13], "physicist": 9, "piec": [15, 17], "pioneer": [2, 4, 7, 15], "pip": [17, 27, 33], "pipelin": [14, 18, 19, 20, 21], "pitt": 7, "pivot": 7, "place": 31, "plai": [8, 19, 23, 27], "plan": 10, "plan1": 12, "plan2": 12, "plastic": [2, 3, 4, 5], "platform": 33, "pleas": [1, 10], "plot": [15, 19, 34], "plot_embed": 26, "plot_korean_word_embed": 21, "plot_language_comparison": 21, "plot_pos_tag": 20, "plot_vector": 26, "plot_word_cloud": 19, "plot_word_embed": 20, "plot_word_frequ": 19, "plt": [17, 19, 20, 21, 23, 24, 26], "po": [15, 17, 19, 21, 23, 27, 29], "poem": 33, "point": [2, 9, 12, 20, 21, 24, 30, 34], "polit": 16, "pollut": [4, 5], "polysemi": [26, 27], "poor": 5, "poorli": 15, "popular": [16, 20, 26, 27], "porcelain": 34, "porterstemm": [15, 19], "portion": 14, "pos_encod": 31, "pos_tag": [15, 17, 20, 21, 27], "pos_tag_text": [17, 20], "pose": 9, "posit": [3, 8, 15, 16, 26, 27, 28], "positional_encod": 29, "positionalencod": 31, "possibl": [2, 3, 4, 11, 14, 15, 16, 23, 34], "possibli": 34, "post": [1, 13, 15, 21], "potenti": [4, 9, 14, 16, 24, 27, 34], "power": [3, 4, 5, 8, 9, 15, 16, 17, 30, 33, 34], "pp": 23, "practic": [1, 2, 5, 8, 10, 13, 26], "practition": 16, "pragmat": 15, "pre": [15, 16, 17, 20, 24, 25], "precis": 5, "predict": [1, 2, 4, 5, 9, 13, 15, 16, 22, 23, 24, 26, 27, 30, 31, 34], "predicted_class": 16, "prefix": 16, "prepar": [10, 11, 20, 27, 34], "preprocess": [1, 10, 11, 13, 16], "preprocess_text": [15, 19], "preprocessed_text": 19, "present": [4, 10, 11, 13, 16, 17, 21, 27, 30], "preserv": 25, "press": [2, 5, 9], "pretrain": [6, 7, 8], "prevent": [5, 13, 31, 34], "previou": [9, 23, 24, 27, 28, 30], "primari": [3, 10, 15], "primarili": 15, "princ": 34, "principl": 7, "print": [15, 16, 17, 19, 20, 21, 23, 24, 26, 27, 31, 33, 34], "prior": 3, "priorit": 9, "privaci": 16, "prize": [1, 3, 4, 5, 13], "prob": [23, 24], "probabilist": [6, 7, 15, 22, 23], "probabl": [7, 15, 22, 24, 27, 30], "probe": 16, "probe_model_bia": 16, "problem": [1, 3, 5, 7, 8, 10, 11, 13, 16, 23, 24, 26], "problemat": 20, "process": [0, 1, 2, 3, 7, 8, 9, 10, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 25, 28, 29, 30, 31, 33, 34], "processed_text": 20, "produc": [4, 27], "product": [4, 10, 15, 20, 21, 30, 31], "professor": [0, 10], "profici": 14, "program": [1, 13, 15, 34], "progress": [3, 5, 12], "project": [13, 31], "promin": [16, 33], "promis": 16, "promot": 4, "prompt": [1, 8, 10, 13, 16, 17, 32, 33], "proper": 15, "properli": 21, "properti": [6, 7, 25, 26], "propos": [1, 7, 10, 15], "prosper": 34, "protein": [1, 2, 5, 13], "prototyp": 13, "provid": [2, 3, 4, 7, 8, 10, 16, 17, 18, 22, 24, 25, 26, 30, 31, 32, 33, 34], "psychotherapist": 15, "pt": [15, 16], "publicli": [3, 33], "publish": 10, "punctuat": [18, 21], "punkt": [15, 19, 23, 26], "punkt_tab": 17, "puppi": 30, "purpos": [14, 18, 22, 34], "pursu": 15, "push": [15, 16], "put": 28, "pyplot": [17, 19, 20, 21, 23, 24, 26], "python": [1, 10, 13, 15, 22, 28, 31, 33], "pytorch": [10, 16, 28], "q": [10, 13, 29, 30, 31], "q_linear": 31, "qualiti": [25, 31], "quantum": [16, 34], "queri": [23, 29], "question": [8, 9, 16, 17, 19, 28, 30, 31, 33, 34], "quick": [17, 19, 20, 24, 26, 27], "quickli": [10, 15, 16, 19], "quickstart": 33, "quit": 15, "qw_i": 29, "r": [15, 19, 20, 21], "rabbit": 17, "race": 16, "rag": 13, "rai": [2, 3], "rais": [5, 9, 16], "ralli": 16, "ran": 30, "rand": 31, "random": [15, 32, 33, 34], "random_st": [15, 17, 20, 21, 24, 26, 27], "randomli": [26, 30], "rang": [4, 8, 10, 14, 15, 16, 19, 21, 23, 24, 29, 30, 31, 33, 34], "rapid": 5, "rapidli": [2, 3], "rare": [15, 25, 27, 34], "rate": [32, 34], "ratelimiterror": 34, "rather": 9, "ratio": 27, "raw": [15, 18, 19, 34], "rbm": [6, 7, 8], "re": [15, 19, 20, 21, 24], "reach": 5, "reaction": 4, "read": [28, 34], "real": [1, 10, 11, 13, 15, 16, 20, 21, 24], "realli": 16, "realm": 34, "reason": [15, 19], "reassur": 9, "recal": 6, "receiv": 9, "recent": 14, "recip": 9, "recogn": [8, 15], "recognit": [6, 7, 8, 9, 15, 17, 19, 23, 30], "recombin": 5, "recommend": 15, "reconstruct": [6, 7], "record": [10, 34], "recurr": [6, 7, 15, 16, 24, 28, 29], "recycl": [3, 5], "red": 19, "reduc": [4, 5, 8, 9, 15, 16, 19, 24, 29, 34], "reduct": [25, 26], "refer": [4, 15], "referenc": 10, "refin": [3, 34], "reflect": [1, 13, 19, 20, 26], "regard": [5, 9], "region": 3, "register_buff": 31, "regress": 15, "regul": [5, 9], "regular": 10, "regularli": 20, "reinforc": 24, "rel": [20, 29], "relat": [1, 10, 13, 16, 26, 29], "relationship": [3, 7, 15, 16, 17, 20, 21, 24, 25, 26, 28, 29, 30], "releas": 1, "relev": [11, 19, 29], "reli": [3, 15, 29], "reliabl": 4, "relianc": 16, "relu": [24, 29, 31], "remain": 21, "remark": [14, 16], "rememb": [19, 20, 21], "remov": [7, 13, 15, 20, 21], "remove_stopword": 19, "render": 20, "repeat": 26, "rephras": 15, "replac": [19, 20], "report": [10, 18, 22, 25, 28, 34], "repositori": 10, "repres": [15, 16, 20, 23, 24, 25, 26, 27, 30, 33], "represent": [1, 15, 16, 17, 18, 19, 24, 28, 29, 30], "request": 33, "requir": [1, 5, 9, 13, 15, 16, 17, 19, 20, 21, 24, 26, 28, 31, 34], "research": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 16, 19, 27], "resembl": [6, 7], "resist": 2, "resolut": 15, "resolv": 15, "resourc": [9, 16, 20, 24], "respond": 15, "respons": [0, 2, 4, 5, 9, 11, 15, 16, 17, 34], "responsibli": 5, "restrict": [6, 7, 8], "result": [10, 13, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 29, 32, 33, 34], "resurg": 8, "retain": 8, "retri": 34, "retriev": [7, 13, 16, 23], "return": [15, 16, 17, 19, 20, 21, 23, 24, 27, 29, 31, 33, 34], "return_tensor": [15, 16], "reveal": 34, "review": [15, 20, 21], "revit": 8, "revolut": [1, 8, 9, 14], "revolution": [2, 3, 4, 6, 7, 8, 14, 15, 16, 24, 25, 26, 29], "revolutionari": 28, "rich": [5, 25, 26, 27], "right": [19, 20, 21, 29, 34], "rise": 14, "risk": 9, "river": 15, "rnn": [8, 15, 16, 24, 28], "ro": 19, "robot": [0, 34], "robust": [24, 33], "roger": 15, "role": [8, 9, 12, 17, 23, 28, 33, 34], "roll": 7, "room": 9, "root": [7, 15, 19, 21], "rosetta": 2, "rotat": [19, 21], "rotor": 2, "roughli": 33, "rstrip": 15, "rule": [11, 14, 15, 18, 21, 23], "run": [15, 17, 19, 27], "runner": 19, "safe": [1, 5, 9, 13], "safeti": [5, 13, 16, 33], "sai": 15, "same": [9, 15, 27, 29, 30], "sampl": [1, 13, 15, 17, 18, 19, 23, 26, 27, 31, 32, 33], "sample_text": [17, 19, 20, 21], "san": 34, "sarcasm": 15, "sat": [15, 23, 24, 31], "savanna": 17, "saw": [15, 16], "scalabl": [8, 15, 29], "scale": [16, 31, 34], "scaled_dot_product_attent": 29, "scatter": [17, 20, 21, 24, 26], "scenario": 27, "scene": 3, "schank": 15, "schedul": 10, "schmidhub": 8, "school": 9, "scienc": [2, 3, 4, 6, 9, 14, 15, 17], "scientif": [2, 3, 5, 6, 7, 13], "scientist": [3, 4, 9, 10], "scikit": [10, 15, 17], "scipi": 24, "score": [15, 16, 22, 24, 27, 28, 29, 30], "scrape": 19, "scratch": [4, 22, 28], "script": [32, 33, 34], "scroll": 34, "seaborn": [19, 20, 21], "search": [3, 13, 23], "second": 30, "secret": [33, 34], "section": [17, 33], "secur": 33, "see": [1, 15, 19, 21, 28, 32, 34], "seek": 9, "seen": 15, "select": [4, 10, 26, 34], "self": [8, 16, 28], "self_attent": 31, "self_attn_output": 31, "semant": [14, 15, 16, 17, 20, 21, 23, 24, 25, 26], "sensit": 24, "sensor": 2, "sent": 21, "sent_token": 19, "sentenc": [15, 16, 17, 18, 19, 20, 23, 24, 26, 27, 30, 31], "sentiment": [13, 15, 16, 20, 23, 27, 30, 31, 33], "sentiment_scor": 15, "separ": [15, 16, 29], "sepp": 8, "seq_len": 29, "sequenc": [2, 3, 4, 8, 15, 16, 23, 24, 28, 29, 30, 31, 33], "sequence_length": 31, "sequenti": [8, 24, 28, 29], "serv": [7, 14, 22], "servic": 10, "session": [1, 2, 6, 10, 14, 17, 18, 22, 25, 28, 32], "set": [5, 14, 15, 16, 17, 18, 19, 23, 24, 25, 26, 29, 32], "set_titl": [19, 21], "set_xtick": [19, 21], "set_xticklabel": [19, 21], "set_ylabel": [19, 21], "set_ytick": 19, "setup": [17, 32, 33], "sever": [5, 15, 16, 19, 21, 26, 29], "shape": [17, 20, 24, 31], "share": [9, 10, 13, 30, 33, 34], "she": 34, "shift": [14, 15], "shirt": 15, "short": [8, 15, 16, 17, 24, 25, 33, 34], "shortcom": 7, "shot": [13, 14], "should": [2, 10, 18, 28, 31], "show": [3, 4, 17, 19, 20, 21, 23, 24, 26, 27, 30, 31], "showcas": 19, "shrdlu": 15, "shrink": 8, "side": 5, "sign": 33, "signal": 7, "signific": [2, 3, 5, 8, 9, 14, 15, 16, 30, 32], "significantli": [8, 16, 19, 20, 27, 28], "similar": [3, 5, 7, 8, 9, 15, 16, 19, 23, 26, 30, 34], "similar_word": [16, 26, 27], "similarity_matrix": 15, "similarity_scor": 27, "simpl": [7, 9, 13, 15, 16, 20, 21, 22, 23, 25, 26, 27, 28, 32, 33, 34], "simple_self_attent": 31, "simplernn": 16, "simplifi": [7, 15, 23, 24], "simul": 15, "simultan": [29, 30], "sin": [29, 31], "sinc": [3, 29], "sing": 34, "singl": [3, 16, 29, 34], "sip": 34, "sit": 17, "size": [16, 19, 23, 24, 26, 29, 31], "skill": [1, 10, 13, 18], "skip": [17, 25], "skipgram": 24, "skipgram_count": 24, "skipgram_prob": 24, "sklearn": [15, 17, 20, 24, 26, 27], "sky": 17, "slack": 10, "sleep": 20, "slide": 26, "slow": 7, "slower": 27, "small": [2, 20, 23, 24], "smaller": 19, "smallest": [21, 34], "smartphon": 23, "smooth": [22, 24], "smoothed_prob": 23, "sn": [19, 20, 21], "sne": [17, 20, 21, 24, 25, 26], "snippet": [24, 34], "social": [5, 15, 19, 21], "societ": 9, "societi": [5, 9], "socioeconom": 16, "softmax": [15, 24, 29, 30, 31, 34], "softwar": [2, 4, 34], "solid": [14, 22], "solidifi": [8, 31], "solut": [4, 5, 8, 9, 18, 34], "solv": [1, 2, 3, 7, 10, 13, 16, 17], "some": [5, 8, 15, 17, 19, 20, 21, 23, 24, 30, 33], "sophist": [14, 16, 17, 20, 22, 27], "sorri": 15, "sort": 34, "sought": 34, "sound": 23, "sourc": [10, 11, 31], "space": [15, 16, 21, 25, 26], "spaci": 20, "spars": [15, 26], "sparse_categorical_crossentropi": 24, "sparsiti": [22, 23, 24], "spatial": 8, "speaker": 15, "special": [1, 8, 13, 15, 18, 19, 21], "specif": [4, 5, 7, 8, 9, 14, 15, 18, 19, 20, 23, 24, 25, 26, 27, 30, 33, 34], "specifi": [19, 33], "speech": [7, 8, 15, 22, 23], "speed": 27, "spell": [18, 23], "spend": 9, "spill": 15, "spin": [6, 7], "split": [15, 17, 21, 27], "spoof": 9, "sport": [16, 26], "spring_layout": [19, 21, 23], "sqrt": [29, 31], "squeez": 16, "src": 31, "src_embed": 31, "src_mask": 31, "src_vocab_s": 31, "stabil": [4, 7], "stabl": 4, "stage": [14, 15], "stai": 19, "stanc": 9, "standard": [5, 8, 15, 18, 19, 29], "star": 34, "start": [1, 13, 17, 19, 20, 21, 24], "state": [6, 7, 8, 14, 22, 24, 29, 30], "statement": [11, 17], "static": 26, "statist": [1, 6, 7, 13, 14, 18, 23, 25, 27], "statu": [12, 16], "steerabl": 16, "stem": 15, "stem_word": 19, "stemmed_text": 19, "stemmed_token": 15, "stemmed_word": 19, "stemmer": 15, "step": [7, 15, 17, 18, 19, 20, 22, 29, 30, 33], "steve": 20, "steven": 22, "still": [4, 7], "stimul": 2, "stochast": [7, 27], "stock": [16, 27], "stone": 22, "stop": [13, 16, 21, 33], "stop_word": [15, 19], "stopword": [15, 19], "storag": 27, "store": [6, 7, 15, 33], "stori": [17, 34], "storytel": 16, "str": 33, "streamlit": 13, "street": 30, "strength": [22, 27], "strengthen": 7, "stress": 9, "string": [33, 34], "stringent": 5, "strip": [16, 19, 34], "strong": 31, "structur": [1, 2, 4, 7, 13, 15, 17, 21, 30, 34], "struggl": [7, 8, 15], "student": [1, 10, 13, 32], "studi": [3, 5, 15, 24, 28], "style": [15, 20], "sub": [19, 20, 29], "subject": [14, 21], "submiss": [10, 28], "subplot": [19, 21], "subsequ": [8, 15, 30], "subspac": 29, "substitut": 15, "subword": [15, 17, 25, 26], "success": [2, 4, 11, 15], "suffici": 23, "suggest": [2, 7, 23], "suitabl": [18, 20], "sum": [24, 27, 30], "sum_j": 34, "summar": [16, 31, 33, 34], "summari": [24, 31], "super": [16, 31], "superior": [29, 30], "supplementari": 28, "support": [2, 15, 28], "suppos": 31, "suptitl": 21, "sure": [15, 28], "surpris": 9, "sustain": [0, 4, 5], "svm": 15, "swap": 10, "swedish": 9, "swim": 17, "syllabu": 1, "symmetr": 31, "symmetri": 31, "syntact": [15, 26], "syntax": 31, "synthes": 4, "synthet": [2, 4, 5], "system": [1, 4, 5, 6, 7, 8, 9, 13, 14, 15, 16, 17, 33, 34], "sz": 31, "t": [17, 19, 20, 21, 23, 24, 25, 26, 34], "t5": 16, "tackl": [2, 5], "tag": [15, 19, 27], "take": [3, 30], "takeawai": [15, 16], "taken": 31, "tale": 34, "talk": 34, "target": [2, 3, 4, 5, 24, 26, 31], "target_nam": 15, "task": [1, 6, 7, 8, 10, 11, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34], "taught": 0, "td": 27, "tea": 34, "teach": 10, "teacup": 34, "team": [1, 3, 4, 11], "tech": 16, "technic": [15, 19], "techniqu": [1, 4, 6, 10, 11, 13, 15, 16, 17, 18, 19, 21, 22, 25, 26, 27, 32], "technolog": [2, 9], "technologi": [1, 5, 9, 10, 13, 14, 16, 26], "telescop": 15, "tell": 34, "temp": 34, "temperatur": [13, 16, 32, 33], "tend": [8, 26], "tensor": [29, 31], "tensorflow": [10, 24, 28], "term": [4, 8, 15, 16, 24, 27, 29, 34], "terrain": 6, "terribl": 15, "test": [10, 11, 15, 19, 23], "test_corpu": 23, "test_data": 24, "test_siz": [15, 27], "text": [1, 8, 10, 11, 13, 16, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33], "textcoord": [20, 21, 24], "textual": 20, "textur": 8, "tf": [15, 24], "tfidf_matrix": [15, 20], "tfidfvector": [15, 20], "tgt": 31, "tgt_embed": 31, "tgt_mask": 31, "tgt_vocab_s": 31, "th": 29, "than": [9, 17, 24, 28, 30, 34], "thei": [15, 16, 17, 19, 20, 23, 24, 26, 28, 29, 32], "them": [1, 8, 9, 10, 13, 16, 19, 20], "theme": 5, "themselv": 33, "theori": [15, 22], "therapeut": [2, 4, 5], "therebi": [2, 8], "thermodynam": 7, "thi": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34], "those": [17, 34], "though": 15, "thought": [9, 13, 34], "three": [2, 3, 4, 10, 27, 29, 34], "threshold": 34, "through": [1, 3, 4, 10, 13, 14, 15, 16, 17, 19, 31, 34], "tight_layout": [19, 20, 21, 23], "tiktoken": 33, "time": [3, 8, 10, 12, 15, 16, 29, 34], "timelin": 11, "timestamp": 33, "titl": [11, 17, 19, 20, 21, 23, 24, 26], "to_lowercas": 19, "toarrai": 20, "todai": [5, 6, 7, 8, 9, 15, 16, 33], "togeth": [3, 5, 7, 9, 34], "toi": 19, "token": [1, 8, 13, 14, 15, 16, 20, 23, 24, 26, 29, 31, 32, 34], "token_count": 33, "tokenize_text": [17, 19], "tokenized_corpu": [20, 26], "tokenized_sent": 21, "tone": 15, "too": [19, 34], "tool": [2, 3, 5, 8, 9, 16, 21, 28, 33, 34], "toolkit": [15, 18, 22], "top": [29, 32], "top_k": 34, "top_n": 23, "top_p": [13, 32, 33, 34], "top_p_valu": 34, "topic": [9, 10, 12, 13, 14, 23, 28, 34], "topn": [16, 26, 27], "torch": [15, 16, 29, 31], "total": [2, 34], "toward": [7, 15, 31], "trace": [14, 15], "track": 19, "trade": [19, 20, 24], "tradit": [3, 9, 14, 16, 24, 25, 28], "tradition": 2, "train": [6, 7, 8, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27, 29, 33], "train_data": 24, "train_korean_word2vec": 21, "train_test_split": [15, 27], "train_word2vec": [20, 24], "trajectori": 9, "transfer": 16, "transform": [1, 2, 3, 10, 11, 13, 14, 15, 19, 22, 24, 30], "transit": [7, 8, 16, 23, 24], "translat": [8, 15, 16, 23, 27, 29, 33], "transpar": [5, 9], "transpos": [29, 31], "travel": 34, "treasur": 34, "treat": 15, "treatment": 2, "tree": [15, 17, 26, 27, 34], "tree2conlltag": 27, "trello": 10, "tremend": 5, "trend": [1, 13], "tricki": 21, "trigram": [22, 23, 24], "trigram_count": 24, "trigram_perplex": 24, "trigram_prob": 24, "triu": 31, "truck": 26, "true": [15, 16, 19, 20, 21, 23, 24, 27], "truli": 9, "truncat": [15, 16], "trust": 5, "try": [17, 19, 24], "tsne": [17, 20, 21, 24, 26], "tune": [8, 13, 16, 19, 24, 25, 33, 34], "tupl": 24, "ture": 23, "turn": [2, 3], "tweet": 20, "two": [3, 26, 29, 30, 33], "txt": 16, "type": [7, 19, 24, 27, 33], "typic": [7, 15, 16, 19, 23, 27, 33, 34], "typographi": 19, "u": [4, 19, 25, 34], "uncas": [15, 16], "uncertainti": 9, "unchang": 21, "uncontrol": 5, "under": 1, "undergo": 5, "undergradu": 0, "underscor": 9, "understand": [1, 2, 3, 7, 8, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "understood": 34, "unexpect": [9, 33], "unforeseen": 5, "unicod": 20, "unicodedata": 20, "unifi": 9, "uniform": 34, "unigram": [22, 23, 24], "unigram_count": [23, 24], "unigram_prob": 24, "unintend": [4, 5], "unintention": 9, "uniqu": [2, 11, 17, 19, 21, 33], "unit": [19, 21, 33], "univers": 0, "unix": 33, "unknown": 34, "unlabel": 30, "unlik": [4, 8, 9, 16, 25], "unnorm": 30, "unpreced": [3, 5, 8, 16], "unrel": 26, "unseen": [16, 22, 24], "unsqueez": [29, 31], "unsupervis": 30, "until": [3, 7, 8, 26], "unwant": 34, "up": [3, 13, 15, 16, 17, 18, 25, 26, 27, 30, 32], "upcom": 28, "updat": [8, 26, 30], "upon": [17, 18, 20, 30, 34], "upper": [20, 21], "uppercas": 18, "urg": 9, "url": 19, "us": [1, 2, 4, 5, 6, 7, 8, 10, 11, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33], "usabl": 10, "usag": [1, 13, 15, 16, 19, 20, 21, 23, 24, 27, 32, 34], "user": [8, 10, 11, 17, 32, 33, 34], "user_input": 15, "usual": 19, "util": [1, 4, 10, 11, 13, 18, 27, 31, 32], "v": [18, 19, 21, 23, 24, 29, 31], "v_linear": 31, "va": [19, 20, 21], "vaccin": [2, 4, 5], "valid": 4, "vallei": [6, 7], "valu": [24, 29, 30, 32, 34], "valuabl": 0, "vanish": [8, 24, 29], "var": 17, "variabl": 33, "variant": [24, 29], "variat": 15, "varieti": [2, 30], "variou": [1, 2, 4, 6, 7, 8, 10, 13, 14, 15, 16, 18, 20, 21, 22, 24, 25, 26, 27, 30, 32, 33, 34], "vast": [2, 3, 16, 30], "vaswani": [8, 16, 28, 29, 31], "vbg": 17, "vbz": [15, 17], "ve": [15, 17, 19, 20, 21, 23, 24, 31], "vector": [13, 15, 16, 17, 20, 24, 26, 29, 30], "vector_s": [16, 17, 20, 21, 24, 26, 27], "verb": [17, 20], "verbos": [24, 27], "veri": [9, 15, 19], "versatil": [4, 16], "version": [2, 3, 7, 10, 30], "vertic": 34, "vi": 33, "via": 9, "video": 28, "view": 31, "villag": 34, "virtual": 6, "virus": 4, "visibl": 7, "vision": [4, 7, 8], "visit": 19, "visual": [1, 8, 13, 19, 20, 21, 24, 25, 28], "visualize_bigram": 23, "visualize_embed": [17, 24], "visualize_pos_tag": 21, "visualize_token": 19, "vocab": [24, 26], "vocab_s": [16, 24], "vocabulari": [15, 17, 19, 22, 23, 25, 26, 27], "voic": [5, 9], "vw_i": 29, "w": [23, 24, 27, 29], "w1": 23, "w2": 23, "w2v_model": [20, 21], "w_1": 29, "w_2": 29, "w_i": 29, "wa": [3, 4, 5, 6, 8, 9, 15, 20, 30, 33, 34], "waddl": 17, "wai": [2, 3, 4, 9, 15, 25, 34], "walk": [17, 31], "walkthrough": [28, 32], "walter": 7, "want": 30, "warren": 7, "wast": [4, 15], "watch": 16, "we": [2, 3, 4, 5, 9, 10, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34], "weak": [22, 27], "weapon": 5, "web": [1, 10, 11, 13, 19], "websit": 19, "week": [1, 10, 11, 13], "weekli": [1, 13, 28], "weight": [8, 15, 23, 24, 27, 30], "welcom": [1, 14, 17, 25, 28], "well": [23, 27], "went": 15, "were": [2, 3, 7, 8, 15, 29], "what": [15, 19, 33], "when": [5, 7, 15, 19, 20, 21, 24, 31, 32, 33, 34], "where": [4, 7, 9, 23, 24, 27, 30, 33, 34], "whether": [9, 30], "which": [2, 3, 4, 5, 6, 7, 8, 9, 15, 17, 19, 21, 22, 24, 29, 30, 31, 33], "while": [7, 8, 15, 21, 24, 27, 34], "whisper": 34, "white": 19, "who": [1, 34], "whose": 34, "why": [4, 15], "wide": [4, 8, 10, 14, 16, 30, 33], "widen": 5, "widespread": 3, "width": 19, "wife": 9, "win": 9, "wind": 21, "window": [16, 17, 20, 21, 24, 26, 27, 29], "wisdom": 34, "wise": [7, 8, 29], "with_label": [19, 21, 23], "within": [10, 15, 28, 29, 30, 32, 34], "without": [15, 16, 19, 24, 28, 29, 33], "wizard": 34, "woman": 16, "won": 20, "wonder": 34, "word": [1, 10, 11, 13, 14, 15, 22, 23, 31, 33, 34], "word1": 27, "word2": 27, "word2vec": [1, 13, 15, 16, 20, 21, 24], "word_class": 24, "word_freq": 19, "word_pair": 27, "word_to_id": 24, "word_token": [15, 17, 19, 20, 23, 24, 26, 27], "word_vector": [17, 20, 21, 24, 26, 27], "wordcloud": 19, "wordnet": [15, 19], "wordnetlemmat": [15, 19], "words_to_plot": [17, 24, 26], "work": [2, 4, 5, 6, 8, 9, 10, 13, 15, 19, 21, 23, 24, 27, 28, 31, 32, 33], "worker": [16, 24, 26, 27], "workflow": 4, "world": [1, 5, 10, 11, 13, 14, 15, 16, 20, 24, 25, 33, 34], "worldwid": 3, "worst": 15, "would": [9, 27, 34], "wrap": [13, 19], "write": [16, 22, 25, 31, 32, 33, 34], "written": 28, "wv": [16, 20, 21, 24, 26, 27], "www": 19, "w\u1d62": [23, 24, 27], "w\u1d62\u1d40w": 27, "w\u2081": 23, "w\u2081w\u2082": 23, "w\u2082": 23, "w\u2083": 23, "w\u2099": 23, "x": [2, 3, 17, 19, 20, 21, 24, 26, 27, 29, 30, 31], "x_test": [15, 27], "x_test_tfidf": 15, "x_test_vec": 15, "x_train": [15, 27], "x_train_tfidf": 15, "x_train_vec": 15, "xi": 30, "xlabel": [20, 21, 24, 26], "xor": 7, "xticklabel": 20, "xytext": [20, 21, 24], "x\u1d62\u2c7c": 27, "y": [17, 20, 21, 24, 26, 27, 30], "y_pred": [15, 27], "y_test": [15, 27], "y_train": [15, 27], "yann": 8, "year": [2, 3, 4, 14, 34], "yield": 2, "yj": [0, 17], "ylabel": [20, 21, 24, 26], "ylgnbu": 20, "york": [15, 27], "you": [10, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 31, 33, 34], "young": 34, "your": [11, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 31, 34], "yyyi": 12, "z": 19, "z_i": 34, "z_j": 34, "za": 19, "zero": [13, 14, 15, 23, 24, 29, 31], "zero_shot_classif": 16, "zip": [19, 20, 21], "\u00b2": 27, "\u03bb\u2081": 24, "\u03bb\u2081p": 24, "\u03bb\u2082": 24, "\u03bb\u2082p": 24, "\u03bb\u2083": 24, "\u03bb\u2083p": 24, "\u03c3\u1d62\u2c7c": 27, "\u1d62": 23, "\u2081": [23, 24], "\u2082": 23, "\u2082w\u1d62": 24, "\u2083": 23, "\u2c7c": 27, "\uac00\uc2e4\ub798\uc694": 21, "\uac10\uae30": 21, "\uac10\uae30\uc5d0": 21, "\uac11\ub2c8\ub2e4": 21, "\uac78\ub838\ub2e4": 21, "\uacf5\ubd80": 21, "\uacf5\ubd80\ub97c": 21, "\uacf5\ubd80\ud569\ub2c8\ub2e4": 21, "\uadf8\ub140\ub294": 21, "\uadf8\ub294": 21, "\ub098": 21, "\ub098\ub294": 21, "\ub098\ub294\ud559\uad50\uc5d0\uac14\ub2e4": 21, "\ub0a0\uc528\uac00": 21, "\ub294": 21, "\ub97c": 21, "\ub9db\uc788\ub294": 21, "\uba39\uc5c8\ub2e4": 21, "\uba39\uc5c8\uc2b5\ub2c8\ub2e4": 21, "\ubc30\uc6c1\ub2c8\ub2e4": 21, "\uc0ac\uacfc\ub97c": 21, "\uc0b0\ucc45": 21, "\uc548\ub155\ud558\uc138\uc694": 21, "\uc5d0\uac8c": 21, "\uc5f4\uc2ec\ud788": 21, "\uc624\ub298\uc740": 21, "\uc6b0\ub9ac\ub294": 21, "\uc74c\uc2dd\uc744": 21, "\uc88b\uc2b5\ub2c8\ub2e4": 21, "\uc88b\uc544\ud558\ub2e4": 21, "\uc88b\uc544\ud569\ub2c8\ub2e4": 21, "\ucc45": 21, "\ucc45\uc744": 21, "\ud559\uad50": 21, "\ud559\uad50\uc5d0": 21, "\ud559\uad50\uc5d0\uc11c": 21, "\ud55c\uad6d": 21, "\ud55c\uad6d\uc5b4": 21, "\ud55c\uad6d\uc5b4\ub97c": 21, "\ud55c\uad6d\uc5b4\uc790\uc5f0\uc5b4\ucc98\ub9ac": 21, "\ud569\ub2c8\ub2e4": 21}, "titles": ["Who made this book?", "Home", "Special Lecture - 2024 Nobel Prize in Chemistry", "Session 1 - Protein Structure Prediction Using Artificial Intelligence", "Session 2 - Computational Protein Design and De Novo Protein Engineering", "Session 3 - Insights from Interviews", "Special Lecture - 2024 Nobel Prize in Physics", "Session 1 - Foundational Discoveries in Machine Learning with Artificial Neural Networks", "Session 2 - Deep Learning Evolution and Advanced Neural Network Architectures", "Session 3 - Insights from Interviews", "Team Project", "NLP Project Proposal", "Week [n] Project Research Note", "Syllabus", "Week 1 - Introduction", "Week 1 Session 1 - Foundations and Evolution of NLP", "Week 1 Session 2 - The Revolution in Modern NLP", "Week 1 Lab - Introduction to NLP Basics", "Week 2 - Basics of Text Preprocessing", "Week 2 Session 1 - Text Preprocessing Fundamentals", "Week 2 Session 2 - Advanced Text Preprocessing and Representation", "Week 2 Session 3 - Korean Text Preprocessing and Tokenization", "Week 3 - Fundamentals of Language Models", "Week 3 Session 1 - Introduction to Language Models and N-grams", "Week 3 Session 2 - Advanced Statistical Language Models", "Week 4 - Word Embeddings", "Week 4 Session 1 - Introduction to Word Embeddings and Word2Vec", "Week 4 Session 2 -  Advanced Word Embeddings", "Week 5 - Transformers", "Week 5 Session 1 - Introduction to Transformers", "Week 5 Session 2 - BERT", "Week 5 Session 3 - Practical Implementation and Visualization of Transformers", "Week 6 - Understanding LLM APIs", "Week 6 Session 1 - Introduction to LLM APIs and OpenAI API Usage", "Week 6 Session 2 - Sampling Methods and Text Generation"], "titleterms": {"": [7, 12, 17], "1": [3, 7, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34], "1950": 15, "1980": 15, "2": [4, 8, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 33, 34], "2000": 15, "2010": 15, "2024": [2, 6], "3": [5, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 33, 34], "4": [10, 11, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 33, 34], "4o": 17, "5": [10, 11, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34], "6": [10, 11, 16, 19, 20, 21, 27, 31, 32, 33, 34], "7": [10, 11, 16, 19, 20, 21, 31, 33, 34], "8": [10, 11, 16, 19, 33, 34], "9": [10, 11, 16], "It": 19, "Its": 3, "On": 34, "The": [3, 4, 8, 16, 23, 26, 29, 30], "Their": 16, "about": [1, 9], "achiev": 12, "activ": [12, 28], "add": 23, "addit": [1, 13, 22, 32], "advanc": [8, 20, 24, 27, 31, 34], "advantag": [23, 26, 29], "ahead": [18, 22, 28], "ai": [3, 9], "algorithm": 27, "all": [19, 29], "alphafold": 3, "alphafold2": 3, "analogi": 27, "analysi": 21, "ann": 7, "api": [17, 32, 33, 34], "appendic": 11, "applic": [3, 4, 7, 8, 23, 25, 27, 31], "approach": 15, "architectur": [8, 26, 27, 29, 30], "artifici": [3, 7], "ascii": 20, "assembl": 31, "assign": [18, 22, 25, 28, 32, 34], "assumpt": 23, "attach": 12, "attent": [28, 29, 30, 31], "background": 11, "backoff": 24, "bag": 20, "base": [24, 27], "basic": [12, 15, 17, 18, 33], "behind": 26, "benefit": 5, "bert": [30, 31], "best": [19, 20, 21, 33], "bidirect": 31, "boltzmann": 7, "book": 0, "bow": 20, "broader": [4, 7], "build": 31, "calcul": 23, "call": 33, "capabl": 16, "case": 20, "cbow": 26, "challeng": [4, 5, 12, 15, 16, 21, 27], "changelog": 1, "charact": 20, "characterist": [11, 21], "chemistri": 2, "class": 24, "classif": 27, "clean": [19, 20], "cnn": 8, "code": [29, 31, 34], "combin": 34, "common": 34, "compar": [24, 27], "compon": [18, 22, 25, 29], "composit": 10, "comput": 4, "concept": [15, 27], "concern": 9, "conclus": [15, 16, 17, 19, 20, 21, 23, 24, 26, 27, 29, 30, 31, 33, 34], "consider": [5, 9, 24, 26], "content": [1, 28, 32], "contract": 20, "contribut": [1, 29], "control": 34, "convers": 19, "convolut": 8, "cours": [1, 13], "cross": 31, "current": 16, "dataset": 11, "date": 10, "de": 4, "debat": 9, "decod": [29, 31], "deconstruct": 30, "deep": [8, 15, 16], "definit": [15, 16, 23], "deliver": [11, 12], "demonstr": 17, "deploy": 9, "descript": 11, "design": 4, "detail": [11, 28], "develop": [11, 16], "diagram": [29, 31, 34], "direct": [8, 16, 24, 27], "discoveri": 7, "dissect": 29, "distribut": [11, 34], "document": 20, "dot": 29, "downstream": 27, "earli": 15, "effect": 34, "embed": [16, 17, 20, 21, 24, 25, 26, 27, 30], "emerg": 16, "emoji": 20, "emoticon": 20, "encod": [29, 31], "engin": 4, "entiti": [20, 27], "entropi": 24, "environ": [10, 34], "error": 34, "ethic": [5, 9], "evalu": [1, 10, 11, 13, 15, 22, 23, 27], "evolut": [8, 15, 16], "exampl": [16, 17, 29, 31, 34], "exercis": [17, 19, 20, 21, 24, 26, 27, 34], "expect": [11, 34], "experi": 34, "explan": 34, "explor": 34, "extract": 15, "extrins": 27, "fasttext": [25, 27], "featur": [11, 15, 27], "feed": [24, 29, 31], "few": 16, "final": 10, "fine": 30, "first": 33, "fold": 3, "formal": 23, "format": 34, "formul": 29, "forward": [24, 29, 31], "foundat": [7, 15], "frequenc": [20, 34], "from": [5, 9, 16, 31], "function": 31, "fundament": [19, 22], "futur": [8, 11, 16, 24, 27], "gener": [16, 17, 31, 34], "gensim": [17, 26, 27], "geoffrei": 7, "global": [25, 27], "glove": [25, 27], "goal": 12, "gpt": [17, 31], "gram": [22, 23, 24, 26], "hand": 34, "handl": [20, 23], "head": [29, 30, 31], "heatmap": 31, "hinton": 7, "histor": 15, "home": 1, "hopfield": 7, "how": 3, "i": 29, "idea": 26, "idf": 20, "impact": [3, 5, 7, 16], "implement": [22, 26, 27, 31], "implic": [4, 5, 7], "import": [3, 10, 19], "inform": 12, "initi": 9, "insight": [5, 9], "instruct": 34, "instructor": 0, "intellig": 3, "interpol": 24, "interpret": 31, "interview": [5, 9], "intrins": 27, "introduct": [3, 4, 5, 7, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33], "invers": 20, "issu": 34, "item": 12, "j": 7, "john": 7, "joon": 0, "json": 34, "k": 34, "katz": 24, "kei": [3, 4, 5, 7, 8, 9, 10, 11, 12, 18, 22, 24, 25, 27, 28, 29, 30, 32, 34], "korean": 21, "lab": 17, "languag": [15, 16, 21, 22, 23, 24, 33], "laplac": 23, "larg": [16, 33], "layer": 31, "learn": [1, 7, 8, 10, 12, 13, 15, 16, 18, 22, 25, 28, 32], "lectur": [1, 2, 6, 28, 32], "lee": 0, "lemmat": 19, "length": 34, "librari": [18, 31], "licens": 1, "limit": [23, 26, 29, 33], "linear": 24, "linguist": 9, "llm": [16, 32, 33], "look": [18, 22, 28], "lowercas": 19, "lstm": 8, "machin": 7, "made": 0, "make": 33, "map": 31, "markov": 23, "mask": 31, "materi": [1, 13], "mathemat": [29, 34], "matrix": 31, "maximum": 24, "mechan": [28, 29, 30, 31], "meet": [10, 12], "member": 12, "method": [10, 20, 34], "model": [15, 16, 22, 23, 24, 33], "modern": [15, 16], "modul": 31, "morpholog": 21, "multi": [29, 30, 31], "n": [12, 22, 23, 24], "name": [20, 27], "natur": 15, "need": [9, 29, 31], "ner": [20, 27], "network": [7, 8, 29, 31], "neural": [7, 8, 24], "neuron": 30, "next": [12, 34], "nlp": [11, 15, 16, 17], "nltk": [17, 18], "nobel": [2, 6, 9], "non": 20, "nonsens": 34, "normal": 18, "notabl": 12, "note": [1, 10, 12, 13, 28], "novo": 4, "nucleu": 34, "object": [1, 10, 11, 13, 17, 18, 22, 25, 28, 32], "ongo": 16, "openai": [17, 33, 34], "opportun": [5, 16], "option": [17, 31], "other": [12, 23], "outcom": 12, "outlin": 13, "output": [10, 34], "over": 29, "overview": [10, 11, 18, 22, 25, 29, 33, 34], "p": 34, "paper": 29, "paradigm": 16, "paramet": [33, 34], "part": [17, 20, 21], "penalti": 34, "percept": 5, "perform": 27, "perplex": 23, "person": 9, "perspect": 15, "phase": [10, 11], "physic": 6, "pipelin": 15, "plan": [11, 12], "platform": 4, "po": 20, "polici": 5, "posit": [29, 31], "potenti": [5, 11], "practic": [18, 19, 20, 21, 22, 24, 25, 27, 28, 31, 32, 33, 34], "pre": [30, 31], "predict": 3, "preprocess": [15, 18, 19, 20, 21], "prerequisit": [1, 13], "presenc": 34, "present": 15, "previou": [29, 34], "prize": [2, 6, 9], "probabl": [23, 34], "process": [4, 15, 26], "product": 29, "progress": [9, 10], "project": [1, 10, 11, 12], "prompt": 34, "propos": 11, "protein": [3, 4], "public": 5, "purpos": 16, "put": 19, "python": 27, "pytorch": 31, "queri": 30, "rate": 33, "reaction": 9, "read": 25, "recap": 34, "recognit": [20, 27], "recommend": 25, "recurr": 8, "refer": [11, 29, 31, 33], "reflect": 9, "regulatori": 5, "remov": [18, 19], "repetit": 34, "represent": [20, 25, 26, 27, 31], "requir": 10, "research": [9, 12], "resourc": [11, 22, 28, 32], "respons": 33, "revolut": [15, 16], "rise": [3, 8, 16], "risk": 5, "rnn": 29, "role": [10, 11], "rosetta": 4, "safeti": 9, "sampl": 34, "scale": 29, "scientif": 9, "score": 31, "scratch": 31, "self": [29, 31], "sentenc": 21, "sequenc": 34, "session": [3, 4, 5, 7, 8, 9, 15, 16, 19, 20, 21, 23, 24, 26, 27, 29, 30, 31, 33, 34], "set": [33, 34], "shift": 16, "shot": 16, "similar": 27, "simpl": [17, 24, 31], "simplifi": 30, "skip": [24, 26], "smooth": 23, "societ": 5, "solut": 12, "special": [2, 6, 20], "specif": 16, "speech": [17, 20, 21], "state": 16, "statist": [15, 22, 24], "stem": 19, "stop": [18, 19, 34], "structur": [3, 28], "student": 0, "subword": 27, "summari": [12, 34], "syllabu": 13, "tabl": 1, "tag": [17, 20, 21], "takeawai": [3, 4, 5, 7, 8, 9, 24, 34], "task": [16, 27, 31], "team": [10, 12], "technic": 12, "techniqu": [20, 23, 24], "technologi": 11, "temperatur": 34, "term": 20, "text": [15, 17, 18, 19, 20, 21, 27, 34], "tf": 20, "thi": 0, "togeth": 19, "token": [17, 18, 19, 21, 33], "tool": 10, "top": 34, "topic": [18, 22, 25, 31], "toward": 16, "tradit": [15, 26, 29], "train": [15, 26, 30, 31], "transform": [8, 16, 28, 29, 31], "translat": 31, "troubleshoot": 34, "tune": 30, "type": 23, "understand": [9, 32, 33, 34], "unseen": 23, "up": [33, 34], "us": [3, 17, 34], "usag": [31, 33], "vari": 34, "variant": 31, "vector": [25, 27], "view": 30, "visual": [17, 23, 26, 31, 34], "walkthrough": 31, "week": [12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "weekli": [10, 12], "who": 0, "word": [16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 30], "word2vec": [17, 25, 26, 27], "work": [3, 7], "you": 29, "young": 0, "your": 33, "zero": 16}})